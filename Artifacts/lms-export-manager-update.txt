from typing import Dict, List, Optional, Union, Any
from datetime import datetime
import json
import xml.etree.ElementTree as ET
import yaml
import logging
from pathlib import Path

class EnhancedLMSExportManager:
    """Enhanced manager for LMS exports with extended platform support"""
    
    def __init__(self):
        self.renderers = {
            'moodle': MoodleRenderer(),
            'schoology': SchoologyRenderer(),
            'blackboard': BlackboardRenderer(),
            'd2l': D2LRenderer(),
            'canvas': ExtendedCanvasRenderer(),
            'sakai': SakaiRenderer(),
            'itslearning': ItsLearningRenderer()
        }
        
        self.logger = logging.getLogger(__name__)
        self.setup_logging()
        
    def setup_logging(self):
        """Configure logging for export operations"""
        handler = logging.StreamHandler()
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        handler.setFormatter(formatter)
        self.logger.addHandler(handler)
        self.logger.setLevel(logging.INFO)

    def export_unit(
        self,
        unit_plan: Dict,
        platform: str,
        settings: Dict,
        export_format: str = 'json',
        output_dir: Optional[str] = None
    ) -> Union[Dict, str, Path]:
        """
        Export unit plan to specified LMS platform
        
        Args:
            unit_plan: Unit plan data
            platform: Target LMS platform
            settings: Export settings
            export_format: Output format ('json', 'xml', 'package')
            output_dir: Optional directory for exported files
            
        Returns:
            Union[Dict, str, Path]: Exported content or path to exported package
        """
        self.logger.info(f"Starting export to {platform} in {export_format} format")
        
        # Validate platform and format
        if platform not in self.renderers:
            raise ValueError(f"Unsupported LMS platform: {platform}")
            
        # Validate unit plan for platform
        issues = self.validate_unit(unit_plan, platform)
        if issues:
            self.logger.warning(f"Validation issues found for {platform}:")
            for issue in issues:
                self.logger.warning(f"- {issue}")
                
        # Apply platform-specific preprocessing
        processed_plan = self._preprocess_unit_plan(unit_plan, platform)
        
        # Render content using appropriate renderer
        renderer = self.renderers[platform]
        content = renderer.render_unit(processed_plan, settings)
        
        # Handle export format
        if export_format == 'package':
            return self._create_export_package(
                content,
                platform,
                output_dir or '.'
            )
        elif export_format == 'xml':
            return self._convert_to_xml(content, platform)
        else:
            return content
            
    def import_template(
        self,
        platform: str,
        template_name: str
    ) -> Dict:
        """
        Import platform-specific template
        
        Args:
            platform: LMS platform
            template_name: Name of template to import
            
        Returns:
            Dict: Template content
        """
        template_path = Path(__file__).parent / 'templates' / platform / f"{template_name}.json"
        
        try:
            with open(template_path) as f:
                template = json.load(f)
            return template
        except FileNotFoundError:
            raise ValueError(f"Template {template_name} not found for {platform}")
            
    def validate_unit(
        self,
        unit_plan: Dict,
        platform: str
    ) -> List[str]:
        """
        Validate unit plan against platform requirements
        
        Args:
            unit_plan: Unit plan to validate
            platform: Target platform
            
        Returns:
            List[str]: Validation issues
        """
        issues = []
        
        # Common validations
        if not unit_plan.get('title'):
            issues.append("Unit plan must have a title")
            
        if not unit_plan.get('objectives'):
            issues.append("Unit plan must have learning objectives")
            
        # Platform-specific validations
        if platform == 'd2l':
            issues.extend(self._validate_d2l(unit_plan))
        elif platform == 'canvas':
            issues.extend(self._validate_canvas(unit_plan))
        elif platform == 'sakai':
            issues.extend(self._validate_sakai(unit_plan))
        elif platform == 'itslearning':
            issues.extend(self._validate_itslearning(unit_plan))
            
        return issues
        
    def _validate_d2l(self, unit_plan: Dict) -> List[str]:
        """D2L-specific validations"""
        issues = []
        
        if not unit_plan.get('grade_level'):
            issues.append("D2L requires grade level specification")
            
        # Validate file types in activities
        for activity in unit_plan.get('activities', []):
            if activity.get('submission_type') == 'file':
                if not activity.get('allowed_file_types'):
                    issues.append(f"Activity '{activity['title']}' needs allowed file types")
                    
        return issues
        
    def _validate_canvas(self, unit_plan: Dict) -> List[str]:
        """Canvas-specific validations"""
        issues = []
        
        # Check for required grading categories
        if unit_plan.get('assessments'):
            if not unit_plan.get('grading_categories'):
                issues.append("Canvas requires grading categories for assessments")
                
        # Validate module requirements
        if not any(obj.get('bloom_level') for obj in unit_plan.get('objectives', [])):
            issues.append("Canvas recommends Bloom's taxonomy levels for objectives")
            
        return issues
        
    def _validate_sakai(self, unit_plan: Dict) -> List[str]:
        """Sakai-specific validations"""
        issues = []
        
        # Check tool availability
        required_tools = {'assignments', 'resources', 'tests'}
        available_tools = set(unit_plan.get('enabled_tools', []))
        missing_tools = required_tools - available_tools
        
        if missing_tools:
            issues.append(f"Required Sakai tools missing: {', '.join(missing_tools)}")
            
        return issues
        
    def _validate_itslearning(self, unit_plan: Dict) -> List[str]:
        """itslearning-specific validations"""
        issues = []
        
        # Check for required learning objective metadata
        for idx, objective in enumerate(unit_plan.get('objectives', [])):
            if not objective.get('taxonomy_level'):
                issues.append(f"Objective {idx + 1} missing taxonomy level")
                
        return issues
        
    def _preprocess_unit_plan(
        self,
        unit_plan: Dict,
        platform: str
    ) -> Dict:
        """
        Apply platform-specific preprocessing
        
        Args:
            unit_plan: Original unit plan
            platform: Target platform
            
        Returns:
            Dict: Processed unit plan
        """
        processed = unit_plan.copy()
        
        if platform == 'd2l':
            processed = self._preprocess_d2l(processed)
        elif platform == 'canvas':
            processed = self._preprocess_canvas(processed)
        elif platform == 'sakai':
            processed = self._preprocess_sakai(processed)
        elif platform == 'itslearning':
            processed = self._preprocess_itslearning(processed)
            
        return processed
        
    def _preprocess_d2l(self, unit_plan: Dict) -> Dict:
        """D2L-specific preprocessing"""
        # Add required metadata
        unit_plan['metadata'] = {
            'created': datetime.now().isoformat(),
            'schema_version': '1.0',
            'platform': 'd2l'
        }
        
        # Process activities
        for activity in unit_plan.get('activities', []):
            if 'completion_type' not in activity:
                activity['completion_type'] = 'automatic'
                
        return unit_plan
        
    def _preprocess_canvas(self, unit_plan: Dict) -> Dict:
        """Canvas-specific preprocessing"""
        # Add required settings
        unit_plan['settings'] = {
            'license': 'cc_by',
            'visibility': 'institution',
            **unit_plan.get('settings', {})
        }
        
        # Process objectives
        for objective in unit_plan.get('objectives', []):
            if 'bloom_level' not in objective:
                objective['bloom_level'] = self._infer_bloom_level(
                    objective.get('description', '')
                )
                
        return unit_plan
        
    def _preprocess_sakai(self, unit_plan: Dict) -> Dict:
        """Sakai-specific preprocessing"""
        # Enable required tools
        unit_plan['enabled_tools'] = list(set(
            unit_plan.get('enabled_tools', []) +
            ['assignments', 'resources', 'tests']
        ))
        
        # Add tool settings
        unit_plan['tool_settings'] = {
            'assignments': {'grade_scale': 'points'},
            'resources': {'allow_inline_preview': True},
            'tests': {'random_questions': False},
            **unit_plan.get('tool_settings', {})
        }
        
        return unit_plan
        
    def _preprocess_itslearning(self, unit_plan: Dict) -> Dict:
        """itslearning-specific preprocessing"""
        # Add required learning objective metadata
        for objective in unit_plan.get('objectives', []):
            if 'taxonomy_level' not in objective:
                objective['taxonomy_level'] = self._infer_taxonomy_level(
                    objective.get('description', '')
                )
                
        return unit_plan
        
    def _infer_bloom_level(self, description: str) -> str:
        """Infer Bloom's taxonomy level from objective description"""
        bloom_keywords = {
            'remember': ['recall', 'identify', 'list'],
            'understand': ['explain', 'describe', 'discuss'],
            'apply': ['use', 'implement', 'solve'],
            'analyze': ['analyze', 'compare', 'organize'],
            'evaluate': ['assess', 'critique', 'judge'],
            'create': ['design', 'develop', 'compose']
        }
        
        description = description.lower()
        for level, keywords in bloom_keywords.items():
            if any(keyword in description for keyword in keywords):
                return level
                
        return 'understand'  # Default level
        
    def _infer_taxonomy_level(self, description: str) -> str:
        """Infer taxonomy level for itslearning"""
        # Similar to Bloom's but with platform-specific levels
        return self._infer_bloom_level(description)
        
    def _create_export_package(
        self,
        content: Dict,
        platform: str,
        output_dir: str
    ) -> Path:
        """
        Create downloadable export package
        
        Args:
            content: Rendered content
            platform: Target platform
            output_dir: Output directory
            
        Returns:
            Path: Path to created package
        """
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        package_dir = Path(output_dir) / f"{platform}_export_{timestamp}"
        package_dir.mkdir(parents=True, exist_ok=True)
        
        # Save content file
        content_file = package_dir / 'content.json'
        with open(content_file, 'w') as f:
            json.dump(content, f, indent=2)
            
        # Create manifest
        manifest = {
            'platform': platform,
            'created': datetime.now().isoformat(),
            'files': ['content.json'],
            'schema_version': '1.0'
        }
        
        manifest_file = package_dir / 'manifest.json'
        with open(manifest_file, 'w') as f:
            json.dump(manifest, f, indent=2)
            
        self.logger.info(f"Created export package at {package_dir}")
        return package_dir

# Example usage
if __name__ == "__main__":
    # Initialize export manager
    export_manager = EnhancedLMSExportManager()
    
    # Sample unit plan
    unit_plan = {
        'title': 'Advanced Data Analysis',
        'grade_level': '11',
        'objectives': [
            {
                'description': 'Analyze complex datasets using statistical methods',
                'assessment_criteria': ['Accuracy', 'Methodology', 'Interpretation']
            }
        ],
        'activities': [
            {
                'title': 'Data Analysis Project',
                'description': 'Students will analyze real-world datasets',
                'submission_type': 'file',
                'allowed_file_types': ['.xlsx', '.csv', '.pdf']
            }
        ]
    }
    
    # Export settings
    settings = {
        'includeAssessments': True,
        'includeRubrics': True,
        'includeDifferentiation': True
    }
    
    # Try exporting to different platforms
    platforms = ['d2l', 'canvas', 'sakai', 'itslearning']
    
    for platform in platforms:
        try:
            # Validate first
            issues = export_manager.validate_unit(unit_plan, platform)
            if issues:
                print(f"\nValidation issues for {platform}:")
                for issue in issues:
                    print(f"- {issue}")
                    
            # Export as package
            package_path = export_manager.export_unit(
                unit_plan,
                platform,
                settings,
                export_format='package',
                output_dir='exports'
            )
            
            print(f"\nSuccessfully exported to {platform}")
            print(f"Package created at: {package_path}")
            
        except Exception as e:
            print(f"\nError exporting to {platform}: {e}")
