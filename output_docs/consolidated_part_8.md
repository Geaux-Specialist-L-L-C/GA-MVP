# Consolidated Files (Part 8)

## backend/Artifacts/cat-plugin-artifact/learning-insights.tsx

```
import React, { useEffect } from 'react';
import { Card, CardHeader, CardTitle, CardContent } from '@/components/ui/card';
import { Alert, AlertDescription } from '@/components/ui/alert';
import { useMemorySystem } from '@/hooks/useMemorySystem';
import { LoadingSpinner } from '@/components/common/LoadingSpinner';
import { 
  Activity, 
  BookOpen, 
  TrendingUp, 
  Clock,
  Brain
} from 'lucide-react';

export const LearningInsights: React.FC = () => {
  const { 
    learningPatterns, 
    loading, 
    error, 
    fetchLearningPatterns 
  } = useMemorySystem();

  useEffect(() => {
    fetchLearningPatterns(30); // Fetch last 30 days
  }, [fetchLearningPatterns]);

  if (loading) {
    return (
      <div className="flex justify-center items-center h-48">
        <LoadingSpinner />
      </div>
    );
  }

  if (error) {
    return (
      <Alert variant="destructive">
        <AlertDescription>{error}</AlertDescription>
      </Alert>
    );
  }

  const calculateEngagement = (patterns) => {
    if (!patterns.length) return 0;
    return patterns.reduce((sum, p) => sum + (p.metadata?.engagement || 0), 0) / patterns.length;
  };

  const findPreferredStyle = (patterns) => {
    const styles = patterns.reduce((acc, p) => {
      const style = p.metadata?.learningStyle;
      if (style) acc[style] = (acc[style] || 0) + 1;
      return acc;
    }, {});
    return Object.entries(styles).sort((a, b) => b[1] - a[1])[0]?.[0] || 'Not enough data';
  };

  const engagement = calculateEngagement(learningPatterns);
  const preferredStyle = findPreferredStyle(learningPatterns);

  return (
    <div className="space-y-6">
      <Card>
        <CardHeader>
          <CardTitle className="flex items-center gap-2">
            <Brain className="w-5 h-5" />
            Learning Insights
          </CardTitle>
        </CardHeader>
        <CardContent>
          <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
            <div className="space-y-2">
              <div className="flex items-center gap-2">
                <Activity className="w-4 h-4 text-blue-500" />
                <span className="font-medium">Engagement Level</span>
              </div>
              <div className="text-2xl">
                {(engagement * 100).toFixed(1)}%
              </div>
            </div>

            <div className="space-y-2">
              <div className="flex items-center gap-2">
                <BookOpen className="w-4 h-4 text-green-500" />
                <span className="font-medium">Preferred Learning Style</span>
              </div>
              <div className="text-2xl capitalize">
                {preferredStyle}
              </div>
            </div>

            <div className="space-y-2">
              <div className="flex items-center gap-2">
                <TrendingUp className="w-4 h-4 text-purple-500" />
                <span className="font-medium">Learning Sessions</span>
              </div>
              <div className="text-2xl">
                {learningPatterns.length}
              </div>
            </div>

            <div className="space-y-2">
              <div className="flex items-center gap-2">
                <Clock className="w-4 h-4 text-orange-500" />
                <span className="font-medium">Average Session Duration</span>
              </div>
              <div className="text-2xl">
                {learningPatterns.length ? 
                  `${Math.round(learningPatterns.reduce((sum, p) => 
                    sum + (p.metadata?.duration || 0), 0) / learningPatterns.length)} mins` :
                  'N/A'
                }
              </div>
            </div>
          </div>

          {learningPatterns.length > 0 && (
            <div className="mt-6">
              <h3 className="font-medium mb-2">Recent Topics</h3>
              <div className="space-y-1">
                {learningPatterns.slice(0, 5).map((pattern, index) => (
                  <div 
                    key={index}
                    className="flex justify-between items-center p-2 bg-gray-50 rounded"
                  >
                    <span>{pattern.metadata?.topic || 'Unnamed Topic'}</span>
                    <span className="text-sm text-gray-500">
                      {new Date(pattern.metadata?.timestamp).toLocaleDateString()}
                    </span>
                  </div>
                ))}
              </div>
            </div>
          )}
        </CardContent>
      </Card>
    </div>
  );
};

export default LearningInsights;
```

## backend/Artifacts/cat-plugin-artifact/adaptive-learning-system.ts

```
// File: src/lib/crew/orchestrator.ts
import { Agent, Task } from 'crewai-ts';
import { AgentRole, TaskDefinition, AgentCapability } from './types';
import { db } from '@/lib/firebase';
import { 
  collection, 
  doc, 
  updateDoc, 
  onSnapshot, 
  query, 
  where,
  Timestamp 
} from 'firebase/firestore';
import { v4 as uuidv4 } from 'uuid';

export class CrewOrchestrator {
  private agents: Map<AgentRole, Agent>;
  private tasks: Map<string, Task>;
  private subscriptions: (() => void)[];

  constructor() {
    this.agents = new Map();
    this.tasks = new Map();
    this.subscriptions = [];
  }

  /**
   * Initialize agent with specified capabilities
   */
  async initializeAgent(
    role: AgentRole, 
    capabilities: AgentCapability
  ): Promise<void> {
    const agent = new Agent({
      role: role,
      goal: `Serve as ${role} in Geaux Academy's educational system`,
      backstory: this.getAgentBackstory(role),
      allowDelegation: capabilities.allowDelegation,
      verbose: true,
      ...capabilities.modelConfig,
    });

    this.agents.set(role, agent);
    await this.syncAgentState(role, agent);
    this.subscribeToAgentConfig(role, agent);
  }

  /**
   * Processes student interaction through three-phase analysis
   */
  async processInteraction(
    query: string,
    studentId: string,
    context: Record<string, any>
  ): Promise<string> {
    // Phase 1: Contextual Analysis
    const episodicAnalysis = await this.analyzeEpisodicMemory(studentId, query);
    
    // Phase 2: Semantic Matching
    const relevantContent = await this.matchDeclarativeContent(
      query,
      episodicAnalysis.learningStyle
    );
    
    // Phase 3: Tool Selection
    const selectedTools = await this.selectTools(
      episodicAnalysis,
      relevantContent
    );

    // Generate response using selected strategy
    return this.generateResponse(
      query,
      episodicAnalysis,
      relevantContent,
      selectedTools
    );
  }

  /**
   * Analyzes episodic memory for student learning patterns
   */
  private async analyzeEpisodicMemory(
    studentId: string,
    query: string
  ): Promise<{
    learningStyle: string;
    struggles: string[];
    confidence: number;
    engagementLevel: number;
  }> {
    const episodicRef = collection(db, 'episodic_memories');
    const studentMemories = query(
      episodicRef,
      where('studentId', '==', studentId),
      where('timestamp', '>=', Timestamp.fromDate(
        new Date(Date.now() - 30 * 24 * 60 * 60 * 1000)
      ))
    );

    const memories = await this.getMemories(studentMemories);
    return this.analyzePatterns(memories);
  }

  /**
   * Matches query with declarative content using vector similarity
   */
  private async matchDeclarativeContent(
    query: string,
    learningStyle: string
  ): Promise<{
    content: string;
    type: string;
    difficulty: number;
    relevance: number;
  }[]> {
    // Vector similarity search in Cheshire Cat memory
    const response = await fetch('https://cheshire.geaux.app/memory/recall', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        text: query,
        metadata: { learningStyle },
        k: 5
      })
    });

    const matches = await response.json();
    return this.rankContentMatches(matches);
  }

  /**
   * Selects appropriate tools based on analysis
   */
  private async selectTools(
    analysis: ReturnType<typeof this.analyzeEpisodicMemory>,
    content: ReturnType<typeof this.matchDeclarativeContent>
  ): Promise<string[]> {
    // Dynamic tool selection based on learning patterns
    const tools = [];

    if (analysis.learningStyle === 'visual') {
      tools.push('diagram_generator', 'mind_map_creator');
    }

    if (analysis.confidence < 0.7) {
      tools.push('step_by_step_explainer', 'practice_generator');
    }

    if (analysis.struggles.length > 0) {
      tools.push('concept_reinforcement', 'adaptive_quiz');
    }

    return tools;
  }

  /**
   * Generates final response using selected strategy
   */
  private async generateResponse(
    query: string,
    analysis: ReturnType<typeof this.analyzeEpisodicMemory>,
    content: ReturnType<typeof this.matchDeclarativeContent>,
    tools: string[]
  ): Promise<string> {
    const teacherAgent = this.agents.get(AgentRole.TEACHER);
    
    if (!teacherAgent) {
      throw new Error('Teacher agent not initialized');
    }

    const task = new Task({
      description: `Generate personalized response for: ${query}`,
      context: {
        learningStyle: analysis.learningStyle,
        confidence: analysis.confidence,
        relevantContent: content,
        availableTools: tools
      }
    });

    return await teacherAgent.executeTask(task);
  }

  /**
   * Clean up subscriptions and resources
   */
  public cleanup(): void {
    this.subscriptions.forEach(unsubscribe => unsubscribe());
    this.subscriptions = [];
  }
}

```

## backend/Artifacts/cat-plugin-artifact/interaction-analysis.ts

```
// File: src/services/interactionAnalysis.ts
import { 
  collection, 
  addDoc, 
  query, 
  where, 
  getDocs, 
  Timestamp 
} from 'firebase/firestore';
import { db } from '@/firebase/config';
import { cheshireService } from './cheshireService';

interface InteractionMetrics {
  responseLatency: number;
  queryComplexity: number;
  feedbackIterations: number;
  timestamp: Date;
}

interface LearningStylePrediction {
  style: 'visual' | 'auditory' | 'reading' | 'kinesthetic';
  confidence: number;
  evidence: InteractionMetrics[];
}

export class InteractionAnalyzer {
  private static readonly COMPLEXITY_PATTERNS = {
    basicQuery: /^[^,.!?]+[.!?]$/,
    multipartQuery: /^[^,.!?]+(,[^,.!?]+)*[.!?]$/,
    complexQuery: /\b(why|how|explain|compare|analyze|evaluate)\b/i
  };

  /**
   * Captures and analyzes a single interaction
   */
  async captureInteraction(
    userId: string,
    query: string,
    startTime: number,
    metrics: Partial<InteractionMetrics>
  ): Promise<void> {
    const endTime = Date.now();
    const latency = endTime - startTime;

    const interactionData = {
      userId,
      query,
      metrics: {
        responseLatency: latency,
        queryComplexity: this.calculateQueryComplexity(query),
        feedbackIterations: metrics.feedbackIterations || 0,
        timestamp: new Date()
      }
    };

    // Store in Firebase
    await addDoc(collection(db, 'interaction_metrics'), interactionData);

    // Store vector embedding in Cheshire Cat memory
    await cheshireService.post('/memory/collections/interactions/points', {
      content: query,
      metadata: {
        ...interactionData.metrics,
        userId
      }
    });
  }

  /**
   * Predicts learning style based on recent interactions
   */
  async predictLearningStyle(userId: string): Promise<LearningStylePrediction> {
    // Get recent interactions from Firebase
    const metricsRef = collection(db, 'interaction_metrics');
    const recentMetrics = query(
      metricsRef,
      where('userId', '==', userId),
      where('metrics.timestamp', '>=', 
        Timestamp.fromDate(new Date(Date.now() - 7 * 24 * 60 * 60 * 1000))
      )
    );

    const metricsSnapshot = await getDocs(recentMetrics);
    const metrics = metricsSnapshot.docs.map(doc => ({
      ...doc.data().metrics
    }));

    // Get vector analysis from Cheshire Cat
    const vectorAnalysis = await cheshireService.post('/memory/recall', {
      metadata: { userId },
      k: 50
    });

    return this.analyzeLearningPatterns(metrics, vectorAnalysis.data);
  }

  /**
   * Calculates query complexity using linguistic patterns
   */
  private calculateQueryComplexity(query: string): number {
    if (this.COMPLEXITY_PATTERNS.complexQuery.test(query)) {
      return 3; // Complex analytical query
    } else if (this.COMPLEXITY_PATTERNS.multipartQuery.test(query)) {
      return 2; // Multi-part query
    }
    return 1; // Basic query
  }

  /**
   * Analyzes patterns to determine learning style
   */
  private analyzeLearningPatterns(
    metrics: InteractionMetrics[],
    vectorAnalysis: any[]
  ): LearningStylePrediction {
    const patterns = {
      visual: 0,
      auditory: 0,
      reading: 0,
      kinesthetic: 0
    };

    // Analyze response latency patterns
    const avgLatency = metrics.reduce((sum, m) => sum + m.responseLatency, 0) / metrics.length;
    if (avgLatency < 1000) {
      patterns.visual += 1; // Quick visual processing
    } else {
      patterns.reading += 1; // Reflective reading
    }

    // Analyze query complexity
    const complexQueries = metrics.filter(m => m.queryComplexity === 3).length;
    if (complexQueries > metrics.length * 0.6) {
      patterns.reading += 1; // Analytical reading preference
    }

    // Analyze feedback patterns
    const highFeedback = metrics.filter(m => m.feedbackIterations > 2).length;
    if (highFeedback > metrics.length * 0.4) {
      patterns.kinesthetic += 1; // Hands-on learning preference
    }

    // Find dominant style
    const dominantStyle = Object.entries(patterns)
      .reduce((a, b) => a[1] > b[1] ? a : b)[0] as LearningStylePrediction['style'];

    // Calculate confidence
    const totalPoints = Object.values(patterns).reduce((a, b) => a + b, 0);
    const confidence = patterns[dominantStyle] / totalPoints;

    return {
      style: dominantStyle,
      confidence,
      evidence: metrics
    };
  }

  /**
   * Updates content presentation based on learning style
   */
  async adaptContent(
    content: string,
    learningStyle: LearningStylePrediction['style']
  ): Promise<string> {
    const adaptationStrategies = {
      visual: this.addVisualElements,
      auditory: this.addAuditoryElements,
      reading: this.addTextualElements,
      kinesthetic: this.addInteractiveElements
    };

    return adaptationStrategies[learningStyle](content);
  }

  private addVisualElements(content: string): string {
    // Add diagrams, charts, mind maps
    return content;
  }

  private addAuditoryElements(content: string): string {
    // Add verbal explanations, discussions
    return content;
  }

  private addTextualElements(content: string): string {
    // Add detailed text explanations
    return content;
  }

  private addInteractiveElements(content: string): string {
    // Add exercises, practice problems
    return content;
  }
}

export const interactionAnalyzer = new InteractionAnalyzer();
```

## backend/Artifacts/cat-plugin-artifact/progression-hook.ts

```
// File: src/hooks/useCompetencyProgression.ts
import { useState, useEffect, useCallback } from 'react';
import { useAuth } from '@/contexts/AuthContext';
import { competencyProgression } from '@/services/competencyProgression';
import type { CompetencyLevel } from '@/types/progression';

export function useCompetencyProgression(subject?: string) {
  const { user } = useAuth();
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<Error | null>(null);
  const [dueReviews, setDueReviews] = useState<CompetencyLevel[]>([]);
  const [learningPath, setLearningPath] = useState<string[]>([]);

  // Fetch due reviews on mount and periodically
  useEffect(() => {
    if (!user) return;

    const fetchDueReviews = async () => {
      try {
        const reviews = await competencyProgression.getReviewDueTopics(user.uid);
        setDueReviews(reviews);
      } catch (err) {
        console.error('Failed to fetch due reviews:', err);
      }
    };

    fetchDueReviews();
    const interval = setInterval(fetchDueReviews, 5 * 60 * 1000); // Check every 5 minutes

    return () => clearInterval(interval);
  }, [user]);

  // Fetch learning path when subject changes
  useEffect(() => {
    if (!user || !subject) return;

    const fetchLearningPath = async () => {
      setLoading(true);
      try {
        const path = await competencyProgression.getRecommendedPath(
          user.uid,
          subject
        );
        setLearningPath(path);
        setError(null);
      } catch (err) {
        setError(err instanceof Error ? err : new Error('Failed to fetch learning path'));
      } finally {
        setLoading(false);
      }
    };

    fetchLearningPath();
  }, [user, subject]);

  // Record assessment result
  const recordAssessment = useCallback(async (
    topic: string,
    score: number
  ) => {
    if (!user || !subject) return;

    setLoading(true);
    try {
      await competencyProgression.recordAssessment(
        user.uid,
        subject,
        topic,
        score
      );

      // Refresh learning path
      const path = await competencyProgression.getRecommendedPath(
        user.uid,
        subject
      );
      setLearningPath(path);
      setError(null);
    } catch (err) {
      setError(err instanceof Error ? err : new Error('Failed to record assessment'));
    } finally {
      setLoading(false);
    }
  }, [user, subject]);

  return {
    dueReviews,
    learningPath,
    recordAssessment,
    loading,
    error
  };
}
```

## backend/Artifacts/cat-plugin-artifact/enhanced-curriculum-designer.tsx

```
import React, { useState, useEffect, useCallback } from 'react';
import { useAuth } from '@/contexts/AuthContext';
import { Card, CardHeader, CardTitle, CardContent } from '@/components/ui/card';
import { Alert, AlertDescription } from '@/components/ui/alert';
import { Brain, Send, BookOpen } from 'lucide-react';
import { cheshireService } from '@/services/cheshireService';

interface CurriculumRequest {
  grade_level: number;
  subject: string;
  difficulty: 'beginner' | 'intermediate' | 'advanced';
  learning_style?: string;
  standards?: string[];
  engagement_metrics?: {
    responseLatency: number;
    queryComplexity: number;
    feedbackIterations: number;
  };
}

interface ActivityRecommendation {
  activity: string;
  description: string;
  style_alignment: string;
  difficulty_rating: number;
}

interface CurriculumResponse {
  lesson_plan: Record<string, any>;
  resources: string[];
  estimated_duration: string;
  learning_objectives: string[];
  assessment_criteria: string[];
  adapted_for?: string;
  activities?: ActivityRecommendation[];
  style_adaptations?: {
    content_format: string;
    interaction_method: string;
    assessment_type: string;
  };
}

interface LearningStyleData {
  style: string;
  confidence: number;
  lastUpdated: Date;
  evidence: {
    interactions: number;
    accuracy: number;
    engagementScore: number;
  };
}

export const CurriculumDesigner: React.FC = () => {
  const { user } = useAuth();
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [curriculum, setCurriculum] = useState<CurriculumResponse | null>(null);
  const [learningStyle, setLearningStyle] = useState<LearningStyleData | null>(null);
  const [interactionStart, setInteractionStart] = useState<number>(0);

  const [request, setRequest] = useState<CurriculumRequest>({
    grade_level: 1,
    subject: '',
    difficulty: 'beginner'
  });

  // Enhanced learning style detection with CrewAI
  const detectLearningStyle = useCallback(async () => {
    if (!user?.uid) return;
    
    try {
      // Query Cheshire Cat's episodic memory for interaction patterns
      const patterns = await cheshireService.post('/memory/recall', {
        metadata: { 
          userId: user.uid,
          type: 'interaction_pattern'
        },
        k: 50 // Last 50 interactions
      });

      // Process interaction patterns through CrewAI agent
      const analysisResponse = await cheshireService.post('/plugins/learning-style-analyzer/analyze', {
        patterns: patterns.data,
        userId: user.uid
      });

      setLearningStyle(analysisResponse.data);
      
      // Store updated style in declarative memory
      await cheshireService.post('/memory/collections/declarative/points', {
        content: `Learning style analysis for user ${user.uid}`,
        metadata: {
          userId: user.uid,
          type: 'learning_style',
          ...analysisResponse.data,
          timestamp: new Date().toISOString()
        }
      });
    } catch (err) {
      console.error("Error detecting learning style:", err);
    }
  }, [user?.uid]);

  // Initialize interaction tracking
  useEffect(() => {
    setInteractionStart(Date.now());
    const interval = setInterval(detectLearningStyle, 5 * 60 * 1000); // Update every 5 minutes
    return () => clearInterval(interval);
  }, [detectLearningStyle]);

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    setLoading(true);
    setError(null);

    try {
      // Calculate engagement metrics
      const engagementMetrics = {
        responseLatency: Date.now() - interactionStart,
        queryComplexity: calculateQueryComplexity(request.subject),
        feedbackIterations: 0 // Updated through feedback loops
      };

      // Enhanced curriculum generation with CrewAI
      const response = await cheshireService.post('/plugins/MyCurriculumDesigner/design-curriculum', {
        ...request,
        learning_style: learningStyle?.style,
        engagement_metrics: engagementMetrics,
        user_id: user?.uid,
        adaptationConfidence: learningStyle?.confidence || 0.5
      });

      setCurriculum(response.data);

      // Store successful interaction in episodic memory
      await cheshireService.post('/memory/collections/episodic/points', {
        content: `Curriculum generation for ${request.subject}`,
        metadata: {
          userId: user?.uid,
          type: 'curriculum_generation',
          learningStyle: learningStyle?.style,
          engagement: engagementMetrics,
          timestamp: new Date().toISOString()
        }
      });
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to generate curriculum');
    } finally {
      setLoading(false);
      setInteractionStart(Date.now()); // Reset interaction timer
    }
  };

  const calculateQueryComplexity = (subject: string): number => {
    // Implement query complexity analysis
    const complexity = subject.split(/\s+/).length;
    return Math.min(complexity / 5, 1); // Normalize to 0-1
  };

  return (
    <Card className="w-full max-w-4xl mx-auto">
      <CardHeader>
        <CardTitle className="flex items-center gap-2">
          <Brain className="w-5 h-5" />
          Adaptive Curriculum Designer
        </CardTitle>
        {learningStyle && (
          <div className="flex items-center gap-2 text-sm">
            <div className="px-3 py-1 rounded-full bg-blue-100">
              <span>ðŸŽ¯ Learning Style: <strong>{learningStyle.style}</strong></span>
              <span className="ml-2 text-gray-500">
                ({(learningStyle.confidence * 100).toFixed(0)}% confidence)
              </span>
            </div>
            <div className="text-gray-500">
              Updated {new Date(learningStyle.lastUpdated).toLocaleTimeString()}
            </div>
          </div>
        )}
      </CardHeader>

      <CardContent>
        {/* Form implementation remains the same */}
        
        {curriculum && (
          <div className="mt-6 space-y-4">
            <h3 className="text-lg font-semibold">Personalized Curriculum</h3>
            
            {curriculum.style_adaptations && (
              <Alert>
                <AlertDescription>
                  <div className="space-y-1">
                    <div>Format: {curriculum.style_adaptations.content_format}</div>
                    <div>Interaction: {curriculum.style_adaptations.interaction_method}</div>
                    <div>Assessment: {curriculum.style_adaptations.assessment_type}</div>
                  </div>
                </AlertDescription>
              </Alert>
            )}

            {/* Rest of the curriculum display remains the same */}
          </div>
        )}
      </CardContent>
    </Card>
  );
};

export default CurriculumDesigner;
```

## backend/Artifacts/cat-plugin-artifact/updated-curriculum-designer.tsx

```
import React, { useState, useEffect, useCallback } from 'react';
import { Card, CardHeader, CardTitle, CardContent } from '@/components/ui/card';
import { Alert, AlertDescription } from '@/components/ui/alert';
import { Brain } from 'lucide-react';
import { 
  GradeLevelSelect, 
  SubjectInput, 
  DifficultySelect, 
  StandardsInput 
} from './FormControls';
import { useCurriculumForm } from '@/hooks/useCurriculumForm';
import { detectLearningStyle } from '@/services/learningStyleService';

export const CurriculumDesigner: React.FC = () => {
  const { user } = useAuth();
  const [curriculum, setCurriculum] = useState<CurriculumResponse | null>(null);
  const [learningStyle, setLearningStyle] = useState<LearningStyleData | null>(null);
  const [interactionStart, setInteractionStart] = useState<number>(0);
  const { errors, loading, handleSubmit } = useCurriculumForm();

  const [request, setRequest] = useState<CurriculumRequest>({
    grade_level: 1,
    subject: '',
    difficulty: 'beginner'
  });

  // Enhanced learning style detection
  useEffect(() => {
    let mounted = true;

    const updateLearningStyle = async () => {
      if (!user?.uid) return;
      
      try {
        const style = await detectLearningStyle(user.uid);
        if (mounted) {
          setLearningStyle(style);
        }
      } catch (error) {
        console.error('Failed to detect learning style:', error);
      }
    };

    updateLearningStyle();
    const interval = setInterval(updateLearningStyle, 5 * 60 * 1000);

    return () => {
      mounted = false;
      clearInterval(interval);
    };
  }, [user?.uid]);

  // Track interaction start time
  useEffect(() => {
    setInteractionStart(Date.now());
  }, []);

  const handleFormSubmit = async (e: React.FormEvent) => {
    e.preventDefault();

    const engagementMetrics = {
      responseLatency: Date.now() - interactionStart,
      queryComplexity: calculateQueryComplexity(request.subject),
      feedbackIterations: 0
    };

    try {
      const response = await handleSubmit(request, learningStyle, engagementMetrics);
      if (response) {
        setCurriculum(response);
        setInteractionStart(Date.now()); // Reset interaction timer
      }
    } catch (error) {
      // Error handling is managed by useCurriculumForm
    }
  };

  const calculateQueryComplexity = (subject: string): number => {
    const words = subject.trim().split(/\s+/);
    const complexity = words.length + 
      words.filter(w => w.length > 6).length * 0.5 +
      (subject.includes(',') ? 0.5 : 0);
    return Math.min(complexity / 5, 1);
  };

  return (
    <Card className="w-full max-w-4xl mx-auto">
      <CardHeader>
        <CardTitle className="flex items-center gap-2">
          <Brain className="w-5 h-5" />
          Adaptive Curriculum Designer
        </CardTitle>
        {learningStyle && (
          <div className="flex items-center gap-2 text-sm">
            <div className="px-3 py-1 rounded-full bg-blue-100">
              <span>ðŸŽ¯ Learning Style: <strong>{learningStyle.style}</strong></span>
              <span className="ml-2 text-gray-500">
                ({(learningStyle.confidence * 100).toFixed(0)}% confidence)
              </span>
            </div>
            <div className="text-gray-500">
              Updated {new Date(learningStyle.lastUpdated).toLocaleTimeString()}
            </div>
          </div>
        )}
      </CardHeader>

      <CardContent>
        <form onSubmit={handleFormSubmit} className="space-y-6">
          <GradeLevelSelect
            value={request.grade_level}
            onChange={(value) => setRequest(prev => ({ ...prev, grade_level: value as number }))}
            error={errors.grade_level}
            label="Grade Level"
          />

          <SubjectInput
            value={request.subject}
            onChange={(value) => setRequest(prev => ({ ...prev, subject: value as string }))}
            error={errors.subject}
            label="Subject"
          />

          <DifficultySelect
            value={request.difficulty}
            onChange={(value) => setRequest(prev => ({ 
              ...prev, 
              difficulty: value as CurriculumRequest['difficulty'] 
            }))}
            error={errors.difficulty}
            label="Difficulty Level"
          />

          <StandardsInput
            value={request.standards?.[0] || ''}
            onChange={(value) => setRequest(prev => ({ 
              ...prev, 
              standards: [value as string] 
            }))}
            standards={getAvailableStandards(request.subject, request.grade_level)}
            error={errors.standards}
            label="Educational Standards"
          />

          <button
            type="submit"
            disabled={loading}
            className="w-full py-2 px-4 bg-blue-500 text-white rounded-lg hover:bg-blue-600 
                     disabled:opacity-50 disabled:cursor-not-allowed"
          >
            {loading ? 'Generating...' : 'Generate Curriculum'}
          </button>
        </form>

        {curriculum && (
          <div className="mt-6 space-y-4">
            <h3 className="text-lg font-semibold">Personalized Curriculum</h3>
            
            {curriculum.style_adaptations && (
              <Alert>
                <AlertDescription>
                  <div className="space-y-1">
                    <div>Format: {curriculum.style_adaptations.content_format}</div>
                    <div>Interaction: {curriculum.style_adaptations.interaction_method}</div>
                    <div>Assessment: {curriculum.style_adaptations.assessment_type}</div>
                  </div>
                </AlertDescription>
              </Alert>
            )}

            {/* Curriculum content sections */}
            <CurriculumContent curriculum={curriculum} />
          </div>
        )}
      </CardContent>
    </Card>
  );
};

export default CurriculumDesigner;
```

## backend/Artifacts/cat-plugin-artifact/agent-factory.ts

```
// File: functions/src/config/agentConfig.ts
import { Agent } from 'crewai-ts';

export const AGENT_CONFIGS = {
  PATTERN_DETECTOR: {
    role: "Pattern Detective",
    goal: "Identify recurring patterns in learning interactions",
    backstory: "Expert in behavioral pattern recognition with focus on educational interactions",
    allowDelegation: true,
    verbose: true,
    modelConfig: {
      model: "gpt-4-turbo",
      temperature: 0.7,
      maxTokens: 2000
    }
  },
  STYLE_ANALYZER: {
    role: "Learning Style Analyst",
    goal: "Determine optimal learning style based on interaction patterns",
    backstory: "Specialist in VARK learning style assessment and educational psychology",
    allowDelegation: true,
    verbose: true,
    modelConfig: {
      model: "gpt-4-turbo",
      temperature: 0.5,
      maxTokens: 2000
    }
  },
  CONFIDENCE_EVALUATOR: {
    role: "Confidence Assessor",
    goal: "Evaluate confidence levels in learning style predictions",
    backstory: "Expert in statistical analysis and confidence scoring",
    allowDelegation: true,
    verbose: true,
    modelConfig: {
      model: "gpt-4-turbo",
      temperature: 0.3,
      maxTokens: 2000
    }
  },
  CURRICULUM_CREATOR: {
    role: "Curriculum Creator",
    goal: "Generate comprehensive curriculum content",
    backstory: "Expert educator with experience in curriculum development",
    allowDelegation: true,
    verbose: true,
    modelConfig: {
      model: "gpt-4-turbo",
      temperature: 0.7,
      maxTokens: 4000
    }
  },
  CONTENT_ADAPTER: {
    role: "Content Adapter",
    goal: "Adapt curriculum content for specific learning styles",
    backstory: "Specialist in personalized learning and content adaptation",
    allowDelegation: true,
    verbose: true,
    modelConfig: {
      model: "gpt-4-turbo",
      temperature: 0.6,
      maxTokens: 3000
    }
  },
  QUALITY_ASSESSOR: {
    role: "Quality Controller",
    goal: "Ensure curriculum meets educational standards and effectiveness",
    backstory: "Educational quality assurance expert",
    allowDelegation: true,
    verbose: true,
    modelConfig: {
      model: "gpt-4-turbo",
      temperature: 0.4,
      maxTokens: 2000
    }
  }
} as const;

export type AgentType = keyof typeof AGENT_CONFIGS;

// File: functions/src/factories/agentFactory.ts
import { Agent } from 'crewai-ts';
import { logger } from "firebase-functions";
import { AGENT_CONFIGS, AgentType } from '../config/agentConfig';

export class AgentFactory {
  private static instance: AgentFactory;
  private agentCache: Map<AgentType, Agent>;

  private constructor() {
    this.agentCache = new Map();
  }

  public static getInstance(): AgentFactory {
    if (!AgentFactory.instance) {
      AgentFactory.instance = new AgentFactory();
    }
    return AgentFactory.instance;
  }

  public createAgent(type: AgentType): Agent {
    // Check cache first
    if (this.agentCache.has(type)) {
      return this.agentCache.get(type)!;
    }

    try {
      const config = AGENT_CONFIGS[type];
      const agent = new Agent(config);
      
      // Cache the agent
      this.agentCache.set(type, agent);
      
      logger.info(`Created agent: ${type}`);
      return agent;
    } catch (error) {
      logger.error(`Failed to create agent ${type}:`, error);
      throw error;
    }
  }

  public getOrCreateAgent(type: AgentType): Agent {
    return this.agentCache.get(type) || this.createAgent(type);
  }

  public clearCache(): void {
    this.agentCache.clear();
  }
}

// File: functions/src/services/agentManager.ts
import { Agent } from 'crewai-ts';
import { logger } from "firebase-functions";
import { AgentFactory } from '../factories/agentFactory';
import { AgentType } from '../config/agentConfig';
import { cheshireService } from './cheshire';

export class AgentManager {
  private factory: AgentFactory;
  private activeAgents: Map<string, Agent>;

  constructor() {
    this.factory = AgentFactory.getInstance();
    this.activeAgents = new Map();
  }

  async initializeAgent(
    type: AgentType,
    context?: Record<string, any>
  ): Promise<Agent> {
    try {
      const agent = this.factory.getOrCreateAgent(type);
      
      // Initialize agent context if provided
      if (context) {
        await this.initializeAgentContext(agent, context);
      }

      this.activeAgents.set(type, agent);
      return agent;
    } catch (error) {
      logger.error(`Failed to initialize agent ${type}:`, error);
      throw error;
    }
  }

  private async initializeAgentContext(
    agent: Agent,
    context: Record<string, any>
  ): Promise<void> {
    try {
      // Store context in Cheshire Cat memory
      await cheshireService.storeDeclarativeMemory(
        JSON.stringify(context),
        {
          agentId: agent.role,
          type: 'agent_context',
          timestamp: new Date().toISOString()
        }
      );

      logger.info(`Initialized context for agent: ${agent.role}`);
    } catch (error) {
      logger.error(`Failed to initialize agent context:`, error);
      throw error;
    }
  }

  getAgent(type: AgentType): Agent | undefined {
    return this.activeAgents.get(type);
  }

  shutdown(): void {
    this.activeAgents.clear();
    this.factory.clearCache();
  }
}

```

## backend/Artifacts/cat-plugin-artifact/declarative-memory.ts

```
// File: src/services/declarativeMemory.ts
import { cheshireService } from './cheshireService';
import { ref, uploadBytes, getDownloadURL } from 'firebase/storage';
import { collection, addDoc, query, where, getDocs } from 'firebase/firestore';
import { db, storage } from '@/firebase/config';

interface DocumentMetadata {
  title: string;
  subject: string;
  gradeLevel: number;
  type: 'lesson' | 'assessment' | 'resource';
  tags: string[];
  author: string;
  createdAt: Date;
  status: 'draft' | 'published' | 'archived';
}

interface ChunkingConfig {
  chunkSize: number;
  chunkOverlap: number;
  includeMetadata: boolean;
}

export class DeclarativeMemoryService {
  private static DEFAULT_CHUNK_CONFIG: ChunkingConfig = {
    chunkSize: 1000,
    chunkOverlap: 200,
    includeMetadata: true
  };

  /**
   * Processes and stores curriculum materials in both Cheshire Cat and Firebase
   */
  async storeCurriculumMaterial(
    file: File,
    metadata: DocumentMetadata,
    config: Partial<ChunkingConfig> = {}
  ) {
    try {
      // Upload file to Firebase Storage
      const storageRef = ref(storage, `curriculum/${metadata.subject}/${file.name}`);
      await uploadBytes(storageRef, file);
      const downloadURL = await getDownloadURL(storageRef);

      // Create FormData for Rabbit Hole ingestion
      const formData = new FormData();
      formData.append('file', file);
      formData.append('chunk_size', String(config.chunkSize || this.DEFAULT_CHUNK_CONFIG.chunkSize));
      formData.append('chunk_overlap', String(config.chunkOverlap || this.DEFAULT_CHUNK_CONFIG.chunkOverlap));
      formData.append('metadata', JSON.stringify({
        ...metadata,
        source_url: downloadURL
      }));

      // Process through Rabbit Hole pipeline
      await cheshireService.post('/rabbithole/', formData);

      // Store reference in Firestore
      await addDoc(collection(db, 'curriculum_materials'), {
        ...metadata,
        fileUrl: downloadURL,
        createdAt: new Date(),
        status: metadata.status || 'draft'
      });

      return true;
    } catch (error) {
      console.error('Failed to store curriculum material:', error);
      throw error;
    }
  }

  /**
   * Retrieves relevant curriculum materials based on semantic search
   */
  async searchCurriculumMaterials(
    query: string,
    filters: Partial<DocumentMetadata> = {}
  ) {
    try {
      // Search Cheshire Cat's declarative memory
      const cheshireResponse = await cheshireService.post('/memory/recall', {
        text: query,
        metadata: filters,
        k: 5
      });

      // Get detailed metadata from Firestore
      const materialRefs = cheshireResponse.data.map(
        (item: any) => item.metadata.source_url
      );

      const firestoreQuery = query(
        collection(db, 'curriculum_materials'),
        where('fileUrl', 'in', materialRefs)
      );

      const firestoreDocs = await getDocs(firestoreQuery);
      const materials = firestoreDocs.docs.map(doc => ({
        id: doc.id,
        ...doc.data()
      }));

      // Merge Cheshire Cat and Firestore data
      return cheshireResponse.data.map((item: any) => ({
        ...item,
        metadata: {
          ...item.metadata,
          ...materials.find(m => m.fileUrl === item.metadata.source_url)
        }
      }));
    } catch (error) {
      console.error('Failed to search curriculum materials:', error);
      throw error;
    }
  }

  /**
   * Updates metadata for existing curriculum material
   */
  async updateMaterialMetadata(
    materialId: string,
    updates: Partial<DocumentMetadata>
  ) {
    try {
      // Update in Cheshire Cat memory
      const material = await this.searchCurriculumMaterials('', { id: materialId });
      if (material.length > 0) {
        await cheshireService.put(
          `/memory/collections/declarative/points/${material[0].id}`,
          { metadata: { ...material[0].metadata, ...updates } }
        );
      }

      // Update in Firestore
      const materialRef = collection(db, 'curriculum_materials');
      await addDoc(materialRef, {
        id: materialId,
        ...updates,
        updatedAt: new Date()
      });

      return true;
    } catch (error) {
      console.error('Failed to update material metadata:', error);
      throw error;
    }
  }

  /**
   * Retrieves curriculum materials by grade level and subject
   */
  async getMaterialsByGradeAndSubject(
    gradeLevel: number,
    subject: string,
    type?: DocumentMetadata['type']
  ) {
    try {
      const filters: Partial<DocumentMetadata> = {
        gradeLevel,
        subject,
        status: 'published'
      };

      if (type) {
        filters.type = type;
      }

      return await this.searchCurriculumMaterials('', filters);
    } catch (error) {
      console.error('Failed to get materials by grade and subject:', error);
      throw error;
    }
  }

  /**
   * Gets related materials based on semantic similarity
   */
  async getRelatedMaterials(materialId: string, limit: number = 3) {
    try {
      const material = await this.searchCurriculumMaterials('', { id: materialId });
      if (material.length === 0) {
        throw new Error('Material not found');
      }

      return await this.searchCurriculumMaterials(
        material[0].content,
        {
          status: 'published',
          id: { $ne: materialId }
        }
      );
    } catch (error) {
      console.error('Failed to get related materials:', error);
      throw error;
    }
  }
}

export const declarativeMemory = new DeclarativeMemoryService();
```

## backend/Artifacts/cat-plugin-artifact/enhanced-firebase-functions.ts

```
// File: functions/src/index.ts
import { onCall, HttpsError } from "firebase-functions/v2/https";
import { onDocumentWritten } from "firebase-functions/v2/firestore";
import { logger } from "firebase-functions";
import { cheshireService } from "./services/cheshire";
import { CrewOrchestrator } from "./services/crewOrchestrator";
import { db } from "./services/firebase";
import * as admin from 'firebase-admin';

// Initialize CrewAI orchestrator
const crewOrchestrator = new CrewOrchestrator();

// Interfaces for type safety
interface LearningInteraction {
  type: 'query' | 'response' | 'feedback';
  content: string;
  timestamp: string;
  duration: number;
  metadata: {
    complexity?: number;
    accuracy?: number;
    confidence?: number;
  };
}

interface LearningProfile {
  userId: string;
  primaryStyle: string;
  secondaryStyle?: string;
  confidence: number;
  lastUpdated: string;
  interactionHistory: LearningInteraction[];
  styleEvolution: {
    timestamp: string;
    style: string;
    confidence: number;
  }[];
}

interface CurriculumMetadata {
  grade: number;
  subject: string;
  level: 'beginner' | 'intermediate' | 'advanced';
  standards?: string[];
  adaptations?: {
    style: string;
    modifications: string[];
  };
}

/**
 * Analyzes learning style using CrewAI agents and pattern recognition
 */
export const analyzeLearningStyle = onCall({ maxInstances: 10 }, async (request) => {
  // Validate authentication
  if (!request.auth) {
    throw new HttpsError(
      'unauthenticated',
      'Authentication required for learning style analysis'
    );
  }

  try {
    const userId = request.auth.uid;
    
    // Get user's learning profile
    const profileRef = db.collection('learning_profiles').doc(userId);
    const profileDoc = await profileRef.get();
    const profile = profileDoc.data() as LearningProfile;

    // Fetch recent interactions
    const interactions = await fetchRecentInteractions(userId);

    // Initialize CrewAI agents for analysis
    await crewOrchestrator.initializeAnalysisAgents({
      historicalProfile: profile,
      recentInteractions: interactions
    });

    // Perform multi-agent analysis
    const analysisResult = await crewOrchestrator.runAnalysisWorkflow({
      taskType: 'style_detection',
      userId,
      confidence_threshold: 0.75
    });

    // Update learning profile with new insights
    await updateLearningProfile(userId, analysisResult);

    // Store analysis in Cheshire Cat memory
    await storeAnalysisResults(userId, analysisResult);

    return {
      success: true,
      style: analysisResult.primaryStyle,
      confidence: analysisResult.confidence,
      recommendations: analysisResult.recommendations
    };

  } catch (error) {
    logger.error('Learning style analysis failed:', error);
    throw new HttpsError(
      'internal',
      'Failed to analyze learning style',
      error
    );
  }
});

/**
 * Generates personalized curriculum using learning style insights
 */
export const generateCurriculum = onCall({ maxInstances: 5 }, async (request) => {
  // Validate authentication
  if (!request.auth) {
    throw new HttpsError(
      'unauthenticated',
      'Authentication required for curriculum generation'
    );
  }

  try {
    const userId = request.auth.uid;
    const metadata: CurriculumMetadata = request.data;

    // Validate metadata
    validateCurriculumMetadata(metadata);

    // Get user's learning profile
    const profile = await getLearningProfile(userId);

    // Initialize curriculum generation agents
    await crewOrchestrator.initializeCurriculumAgents({
      learningProfile: profile,
      curriculumMetadata: metadata
    });

    // Generate base curriculum
    const baseCurriculum = await crewOrchestrator.generateBaseCurriculum(metadata);

    // Adapt curriculum for learning style
    const adaptedCurriculum = await crewOrchestrator.adaptCurriculum({
      curriculum: baseCurriculum,
      learningStyle: profile.primaryStyle,
      confidence: profile.confidence
    });

    // Store in Cheshire Cat memory
    await storeCurriculumInMemory(userId, adaptedCurriculum);

    // Store in Firestore
    await storeCurriculumInFirestore(userId, adaptedCurriculum);

    return {
      success: true,
      curriculum: adaptedCurriculum
    };

  } catch (error) {
    logger.error('Curriculum generation failed:', error);
    throw new HttpsError(
      'internal',
      'Failed to generate curriculum',
      error
    );
  }
});

/**
 * Monitors and processes learning interactions
 */
export const processLearningInteraction = onDocumentWritten(
  'users/{userId}/interactions/{interactionId}',
  async (event) => {
    const userId = event.params.userId;
    const interaction = event.data?.after.data() as LearningInteraction;

    try {
      // Initialize processing agents
      await crewOrchestrator.initializeProcessingAgents({
        userId,
        interactionType: interaction.type
      });

      // Process interaction
      const processingResult = await crewOrchestrator.processInteraction({
        interaction,
        historicalContext: await fetchInteractionContext(userId)
      });

      // Update learning metrics
      await updateLearningMetrics(userId, processingResult);

      // Check for style reassessment trigger
      if (processingResult.requiresReassessment) {
        await triggerStyleReassessment(userId, processingResult.evidence);
      }

      // Store processed interaction
      await storeProcessedInteraction(userId, {
        ...interaction,
        analysis: processingResult
      });

    } catch (error) {
      logger.error('Failed to process learning interaction:', error);
    }
  }
);

// Helper functions
async function fetchRecentInteractions(
  userId: string,
  limit: number = 50
): Promise<LearningInteraction[]> {
  const interactionsRef = db.collection(`users/${userId}/interactions`);
  const snapshot = await interactionsRef
    .orderBy('timestamp', 'desc')
    .limit(limit)
    .get();

  return snapshot.docs.map(doc => doc.data() as LearningInteraction);
}

async function updateLearningProfile(
  userId: string,
  analysisResult: any
): Promise<void> {
  const profileRef = db.collection('learning_profiles').doc(userId);
  
  await profileRef.set({
    primaryStyle: analysisResult.primaryStyle,
    confidence: analysisResult.confidence,
    lastUpdated: admin.firestore.Timestamp.now(),
    styleEvolution: admin.firestore.FieldValue.arrayUnion({
      timestamp: new Date().toISOString(),
      style: analysisResult.primaryStyle,
      confidence: analysisResult.confidence
    })
  }, { merge: true });
}

async function storeAnalysisResults(
  userId: string,
  results: any
): Promise<void> {
  await cheshireService.storeDeclarativeMemory(
    JSON.stringify(results),
    {
      userId,
      type: 'learning_style_analysis',
      timestamp: new Date().toISOString()
    }
  );
}

function validateCurriculumMetadata(
  metadata: CurriculumMetadata
): void {
  const errors: string[] = [];

  if (metadata.grade < 1 || metadata.grade > 12) {
    errors.push('Invalid grade level');
  }

  if (!metadata.subject?.trim()) {
    errors.push('Subject is required');
  }

  if (!['beginner', 'intermediate', 'advanced'].includes(metadata.level)) {
    errors.push('Invalid difficulty level');
  }

  if (errors.length > 0) {
    throw new HttpsError('invalid-argument', errors.join(', '));
  }
}
```

## backend/Artifacts/cat-plugin-artifact/learning-analytics-dashboard.tsx

```
// Additional visualization components to add to your existing code

// Detailed Trend Analysis Component
const TrendAnalysis = ({ data, isLoading }) => {
  if (!data) return null;
  
  return (
    <Card title="Detailed Trend Analysis" isLoading={isLoading}>
      <ResponsiveContainer width="100%" height={300}>
        <ComposedChart data={data}>
          <CartesianGrid strokeDasharray="3 3" />
          <XAxis dataKey="date" />
          <YAxis yAxisId="left" domain={[0, 1]} />
          <YAxis yAxisId="right" orientation="right" domain={[0, 100]} />
          <Tooltip />
          <Legend />
          <Area
            yAxisId="left"
            type="monotone"
            dataKey="performance"
            fill="#8884d8"
            stroke="#8884d8"
            fillOpacity={0.3}
            isAnimationActive={false}
          />
          <Line
            yAxisId="right"
            type="monotone"
            dataKey="percentile"
            stroke="#ff7300"
            isAnimationActive={false}
          />
          <Bar
            yAxisId="left"
            dataKey="improvement"
            fill="#82ca9d"
            isAnimationActive={false}
          />
        </ComposedChart>
      </ResponsiveContainer>
    </Card>
  );
};

// Learning Path Progress Component
const LearningPathProgress = ({ data, isLoading }) => {
  return (
    <Card title="Learning Path Progress" isLoading={isLoading}>
      <ResponsiveContainer width="100%" height={300}>
        <ScatterChart>
          <CartesianGrid />
          <XAxis 
            type="number" 
            dataKey="difficulty" 
            name="Difficulty Level"
            domain={[0, 1]} 
          />
          <YAxis 
            type="number" 
            dataKey="mastery" 
            name="Mastery Level"
            domain={[0, 1]} 
          />
          <Tooltip cursor={{ strokeDasharray: '3 3' }} />
          <Scatter 
            name="Skills" 
            data={data} 
            fill="#8884d8"
            isAnimationActive={false}
          >
            {data?.map((entry, index) => (
              <Cell 
                key={index}
                fill={entry.status === 'mastered' ? '#82ca9d' : 
                      entry.status === 'in-progress' ? '#ffc658' : '#ff7300'}
              />
            ))}
          </Scatter>
        </ScatterChart>
      </ResponsiveContainer>
    </Card>
  );
};

// Skill Correlation Heatmap
const SkillCorrelationHeatmap = ({ data, isLoading }) => {
  const formatData = (data) => {
    if (!data) return [];
    return data.map(row => ({
      ...row,
      value: parseFloat(row.correlation)
    }));
  };

  return (
    <Card title="Skill Correlations" isLoading={isLoading}>
      <div className="h-72">
        {data && (
          <div className="grid grid-cols-10 gap-1 h-full">
            {formatData(data).map((cell, index) => (
              <div
                key={index}
                className="relative"
                style={{
                  backgroundColor: `rgba(36, 92, 223, ${cell.value})`,
                  cursor: 'pointer'
                }}
                title={`${cell.skill1} â†’ ${cell.skill2}: ${(cell.value * 100).toFixed(1)}%`}
              />
            ))}
          </div>
        )}
      </div>
    </Card>
  );
};

// Interactive Filter Panel
const FilterPanel = ({ 
  selectedDomain, 
  timeRange, 
  onDomainChange, 
  onTimeRangeChange,
  availableDomains,
  isLoading 
}) => (
  <div className="bg-white rounded-lg shadow-md p-4 mb-6">
    <div className="flex flex-wrap gap-4 items-center">
      <div className="flex-1 min-w-[200px]">
        <label className="block text-sm font-medium text-gray-700 mb-1">
          Domain
        </label>
        <select
          className="w-full px-4 py-2 border rounded-md bg-white disabled:bg-gray-100"
          value={selectedDomain}
          onChange={onDomainChange}
          disabled={isLoading}
        >
          <option value="all">All Domains</option>
          {availableDomains?.map(domain => (
            <option key={domain.id} value={domain.id}>
              {domain.name}
            </option>
          ))}
        </select>
      </div>
      
      <div className="flex-1 min-w-[200px]">
        <label className="block text-sm font-medium text-gray-700 mb-1">
          Time Range
        </label>
        <select
          className="w-full px-4 py-2 border rounded-md bg-white disabled:bg-gray-100"
          value={timeRange}
          onChange={onTimeRangeChange}
          disabled={isLoading}
        >
          <option value="1m">Last Month</option>
          <option value="3m">Last 3 Months</option>
          <option value="6m">Last 6 Months</option>
          <option value="1y">Last Year</option>
          <option value="custom">Custom Range</option>
        </select>
      </div>
      
      {timeRange === 'custom' && (
        <div className="flex-1 min-w-[200px]">
          <label className="block text-sm font-medium text-gray-700 mb-1">
            Custom Range
          </label>
          <div className="flex gap-2">
            <input
              type="date"
              className="flex-1 px-4 py-2 border rounded-md"
              disabled={isLoading}
            />
            <input
              type="date"
              className="flex-1 px-4 py-2 border rounded-md"
              disabled={isLoading}
            />
          </div>
        </div>
      )}
    </div>
  </div>
);

// Advanced Stats Panel
const AdvancedStats = ({ stats, isLoading }) => (
  <div className="grid grid-cols-1 md:grid-cols-3 gap-4 mb-6">
    {stats?.map((stat, index) => (
      <div key={index} className="bg-white rounded-lg shadow-md p-4">
        <div className="flex items-center justify-between">
          <h4 className="text-sm font-medium text-gray-500">{stat.label}</h4>
          {stat.trend && (
            <span className={`text-sm ${
              parseFloat(stat.trend) > 0 ? 'text-green-500' : 'text-red-500'
            }`}>
              {parseFloat(stat.trend) > 0 ? 'â†‘' : 'â†“'} 
              {Math.abs(parseFloat(stat.trend)).toFixed(1)}%
            </span>
          )}
        </div>
        <p className="mt-2 text-2xl font-semibold">
          {typeof stat.value === 'number' ? stat.value.toFixed(1) : stat.value}
          {stat.unit && <span className="text-sm text-gray-500 ml-1">{stat.unit}</span>}
        </p>
        {stat.subtext && (
          <p className="mt-1 text-sm text-gray-500">{stat.subtext}</p>
        )}
      </div>
    ))}
  </div>
);

// Export these components to use in your main dashboard
export {
  TrendAnalysis,
  LearningPathProgress,
  SkillCorrelationHeatmap,
  FilterPanel,
  AdvancedStats
};

```

## backend/Artifacts/cat-plugin-artifact/cheshire-service.ts

```
// File: functions/src/services/cheshire.ts
import axios, { AxiosInstance } from 'axios';
import { logger } from 'firebase-functions';
import { config } from '../config';

class CheshireService {
  private client: AxiosInstance;
  private baseURL: string;

  constructor() {
    this.baseURL = config.cheshire.apiUrl;
    this.client = axios.create({
      baseURL: this.baseURL,
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${config.cheshire.apiToken}`
      },
      timeout: 30000 // 30 second timeout
    });

    // Add logging interceptor
    this.client.interceptors.request.use(request => {
      logger.debug('Cheshire API Request:', {
        method: request.method,
        url: request.url,
        structuredData: true
      });
      return request;
    });

    this.client.interceptors.response.use(
      response => {
        logger.debug('Cheshire API Response:', {
          status: response.status,
          structuredData: true
        });
        return response;
      },
      error => {
        logger.error('Cheshire API Error:', {
          error: error.message,
          status: error.response?.status,
          structuredData: true
        });
        throw error;
      }
    );
  }

  /**
   * Store content in episodic memory
   */
  async storeEpisodicMemory(
    content: string,
    metadata: Record<string, any>
  ): Promise<void> {
    try {
      await this.client.post('/memory/collections/episodic/points', {
        content,
        metadata: {
          ...metadata,
          timestamp: new Date().toISOString()
        }
      });
    } catch (error) {
      logger.error('Failed to store episodic memory:', error);
      throw error;
    }
  }

  /**
   * Search episodic memory for patterns
   */
  async searchEpisodicMemory(
    query: string,
    metadata?: Record<string, any>,
    limit: number = 50
  ): Promise<any[]> {
    try {
      const response = await this.client.post('/memory/recall', {
        text: query,
        metadata,
        k: limit
      });
      return response.data;
    } catch (error) {
      logger.error('Failed to search episodic memory:', error);
      throw error;
    }
  }

  /**
   * Store curriculum in declarative memory
   */
  async storeDeclarativeMemory(
    content: string,
    metadata: Record<string, any>
  ): Promise<void> {
    try {
      await this.client.post('/memory/collections/declarative/points', {
        content,
        metadata: {
          ...metadata,
          timestamp: new Date().toISOString()
        }
      });
    } catch (error) {
      logger.error('Failed to store declarative memory:', error);
      throw error;
    }
  }

  /**
   * Process content through Rabbit Hole
   */
  async processRabbitHole(
    content: string,
    options: {
      chunkSize?: number;
      chunkOverlap?: number;
      metadata?: Record<string, any>;
    } = {}
  ): Promise<void> {
    try {
      const formData = new FormData();
      formData.append('content', content);
      
      if (options.chunkSize) {
        formData.append('chunk_size', options.chunkSize.toString());
      }
      
      if (options.chunkOverlap) {
        formData.append('chunk_overlap', options.chunkOverlap.toString());
      }
      
      if (options.metadata) {
        formData.append('metadata', JSON.stringify(options.metadata));
      }

      await this.client.post('/rabbithole/', formData, {
        headers: {
          'Content-Type': 'multipart/form-data'
        }
      });
    } catch (error) {
      logger.error('Failed to process through Rabbit Hole:', error);
      throw error;
    }
  }

  /**
   * Make generic request to Cheshire Cat API
   */
  async request<T = any>(
    method: 'GET' | 'POST' | 'PUT' | 'DELETE',
    endpoint: string,
    data?: any
  ): Promise<T> {
    try {
      const response = await this.client.request<T>({
        method,
        url: endpoint,
        data
      });
      return response.data;
    } catch (error) {
      logger.error(`Failed to ${method} ${endpoint}:`, error);
      throw error;
    }
  }

  // Shorthand methods
  async get<T = any>(endpoint: string): Promise<T> {
    return this.request<T>('GET', endpoint);
  }

  async post<T = any>(endpoint: string, data?: any): Promise<T> {
    return this.request<T>('POST', endpoint, data);
  }

  async put<T = any>(endpoint: string, data?: any): Promise<T> {
    return this.request<T>('PUT', endpoint, data);
  }

  async delete<T = any>(endpoint: string): Promise<T> {
    return this.request<T>('DELETE', endpoint);
  }
}

export const cheshireService = new CheshireService();
```

## backend/Artifacts/cat-plugin-artifact/learning-progression.tsx

```
import React from 'react';
import { Card, CardHeader, CardTitle, CardContent } from '@/components/ui/card';
import { Alert, AlertDescription } from '@/components/ui/alert';
import { useCompetencyProgression } from '@/hooks/useCompetencyProgression';
import { BookOpen, AlertCircle, Clock, TrendingUp } from 'lucide-react';

interface ProgressionTrackerProps {
  subject: string;
}

export const ProgressionTracker: React.FC<ProgressionTrackerProps> = ({
  subject
}) => {
  const {
    dueReviews,
    learningPath,
    recordAssessment,
    loading,
    error
  } = useCompetencyProgression(subject);

  if (loading) {
    return (
      <div className="flex justify-center items-center h-48">
        <div className="animate-spin rounded-full h-8 w-8 border-b-2 border-gray-900" />
      </div>
    );
  }

  if (error) {
    return (
      <Alert>
        <AlertCircle className="h-4 w-4" />
        <AlertDescription>{error.message}</AlertDescription>
      </Alert>
    );
  }

  return (
    <div className="space-y-6">
      {/* Due Reviews Section */}
      {dueReviews.length > 0 && (
        <Card>
          <CardHeader>
            <CardTitle className="flex items-center gap-2">
              <Clock className="w-5 h-5" />
              Topics Due for Review
            </CardTitle>
          </CardHeader>
          <CardContent>
            <div className="space-y-2">
              {dueReviews.map((review, index) => (
                <div
                  key={index}
                  className="flex justify-between items-center p-3 bg-gray-50 rounded-lg"
                >
                  <div>
                    <h4 className="font-medium">{review.topic}</h4>
                    <p className="text-sm text-gray-500">
                      Last reviewed: {new Date(review.lastReview).toLocaleDateString()}
                    </p>
                  </div>
                  <button
                    onClick={() => window.location.href = `/review/${review.topic}`}
                    className="px-4 py-2 bg-
```

## backend/Artifacts/cat-plugin-artifact/enhanced-form-controls.tsx

```
import React from 'react';
import { Card, CardHeader, CardTitle, CardContent } from '@/components/ui/card';
import { Alert, AlertDescription } from '@/components/ui/alert';
import { Brain, Send, BookOpen } from 'lucide-react';

interface FormControlProps {
  value: string | number;
  onChange: (value: string | number) => void;
  label: string;
  error?: string;
  className?: string;
}

const GradeLevelSelect: React.FC<FormControlProps> = ({
  value,
  onChange,
  error,
  className
}) => (
  <div className={`space-y-2 ${className}`}>
    <label className="text-sm font-medium">Grade Level</label>
    <select
      value={value}
      onChange={(e) => onChange(parseInt(e.target.value))}
      className={`w-full p-2 border rounded ${error ? 'border-red-500' : ''}`}
    >
      {[...Array(12)].map((_, i) => (
        <option key={i + 1} value={i + 1}>
          Grade {i + 1}
        </option>
      ))}
    </select>
    {error && <p className="text-sm text-red-500">{error}</p>}
  </div>
);

const SubjectInput: React.FC<FormControlProps> = ({
  value,
  onChange,
  error,
  className
}) => (
  <div className={`space-y-2 ${className}`}>
    <label className="text-sm font-medium">Subject</label>
    <input
      type="text"
      value={value}
      onChange={(e) => onChange(e.target.value)}
      className={`w-full p-2 border rounded ${error ? 'border-red-500' : ''}`}
      placeholder="e.g., Mathematics, Science"
    />
    {error && <p className="text-sm text-red-500">{error}</p>}
  </div>
);

const DifficultySelect: React.FC<FormControlProps> = ({
  value,
  onChange,
  error,
  className
}) => (
  <div className={`space-y-2 ${className}`}>
    <label className="text-sm font-medium">Difficulty Level</label>
    <select
      value={value}
      onChange={(e) => onChange(e.target.value)}
      className={`w-full p-2 border rounded ${error ? 'border-red-500' : ''}`}
    >
      <option value="beginner">Beginner</option>
      <option value="intermediate">Intermediate</option>
      <option value="advanced">Advanced</option>
    </select>
    {error && <p className="text-sm text-red-500">{error}</p>}
  </div>
);

const StandardsInput: React.FC<FormControlProps & { standards: string[] }> = ({
  value,
  onChange,
  standards,
  error,
  className
}) => (
  <div className={`space-y-2 ${className}`}>
    <label className="text-sm font-medium">Educational Standards</label>
    <div className="flex flex-wrap gap-2">
      {standards.map((standard) => (
        <button
          key={standard}
          type="button"
          onClick={() => onChange(standard)}
          className={`px-3 py-1 text-sm rounded-full ${
            value === standard 
              ? 'bg-blue-500 text-white' 
              : 'bg-gray-100 hover:bg-gray-200'
          }`}
        >
          {standard}
        </button>
      ))}
    </div>
    {error && <p className="text-sm text-red-500">{error}</p>}
  </div>
);

export { GradeLevelSelect, SubjectInput, DifficultySelect, StandardsInput };
```

## backend/Artifacts/cat-plugin-artifact/adaptive-chat-component (1).tsx

```
import React, { useState, useEffect, useCallback } from 'react';
import { Card, CardHeader, CardTitle, CardContent } from '@/components/ui/card';
import { Alert, AlertDescription } from '@/components/ui/alert';
import { useInteractionAnalysis } from '@/hooks/useInteractionAnalysis';
import { Brain, Send } from 'lucide-react';

interface ChatMessage {
  id: string;
  content: string;
  sender: 'user' | 'ai';
  timestamp: Date;
  learningStyle?: string;
}

export const LearningStyleChat: React.FC = () => {
  const [messages, setMessages] = useState<ChatMessage[]>([]);
  const [input, setInput] = useState('');
  const {
    startInteraction,
    recordFeedback,
    completeInteraction,
    adaptContent,
    learningStyle,
    loading
  } = useInteractionAnalysis();

  // Process and send message
  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    if (!input.trim() || loading) return;

    // Start tracking interaction
    startInteraction();

    // Add user message
    const userMessage: ChatMessage = {
      id: Date.now().toString(),
      content: input,
      sender: 'user',
      timestamp: new Date()
    };

    setMessages(prev => [...prev, userMessage]);
    setInput('');

    try {
      // Get AI response
      let response = await processAIResponse(input);

      // Adapt response based on learning style
      if (learningStyle) {
        response = await adaptContent(response);
      }

      // Add AI message
      const aiMessage: ChatMessage = {
        id: (Date.now() + 1).toString(),
        content: response,
        sender: 'ai',
        timestamp: new Date(),
        learningStyle: learningStyle?.style
      };

      setMessages(prev => [...prev, aiMessage]);

      // Complete interaction tracking
      await completeInteraction(input);
    } catch (error) {
      console.error('Error processing message:', error);
      // Handle error...
    }
  };

  // Request clarification or feedback
  const handleClarification = useCallback(async () => {
    recordFeedback();
    // Implement clarification request logic...
  }, [recordFeedback]);

  // Render learning style indicator
  const renderStyleIndicator = () => {
    if (!learningStyle) return null;

    const styles = {
      visual: { icon: 'ðŸ‘ï¸', color: 'bg-blue-100' },
      auditory: { icon: 'ðŸ‘‚', color: 'bg-green-100' },
      reading: { icon: 'ðŸ“š', color: 'bg-yellow-100' },
      kinesthetic: { icon: 'ðŸ¤š', color: 'bg-purple-100' }
    };

    const style = styles[learningStyle.style as keyof typeof styles];

    return (
      <div className={`px-3 py-1 rounded-full ${style.color} flex items-center gap-2`}>
        <span>{style.icon}</span>
        <span className="capitalize">{learningStyle.style}</span>
        <span className="text-sm opacity-75">
          ({(learningStyle.confidence * 100).toFixed(0)}%)
        </span>
      </div>
    );
  };

  return (
    <Card className="w-full max-w-4xl mx-auto">
      <CardHeader className="flex flex-row items-center justify-between">
        <CardTitle className="flex items-center gap-2">
          <Brain className="w-5 h-5" />
          Adaptive Learning Chat
        </CardTitle>
        {renderStyleIndicator()}
      </CardHeader>

      <CardContent>
        <div className="h-[500px] overflow-y-auto mb-4 space-y-4 p-4">
          {messages.map(message => (
            <div
              key={message.id}
              className={`flex ${
                message.sender === 'user' ? 'justify-end' : 'justify-start'
              }`}
            >
              <div
                className={`max-w-[80
```

## backend/Artifacts/cat-plugin-artifact/learning-insights-fixed.tsx

```
import React, { useState, useEffect } from 'react';
import { Card, CardHeader, CardTitle, CardContent } from '@/components/ui/card';
import { Alert, AlertDescription } from '@/components/ui/alert';
import { 
  Activity, 
  BookOpen, 
  TrendingUp, 
  Clock,
  Brain 
} from 'lucide-react';
import { cheshireService } from '@/services/cheshireService';
import { useAuth } from '@/contexts/AuthContext';

interface LearningPattern {
  metadata: {
    engagement?: number;
    learningStyle?: string;
    topic?: string;
    timestamp?: string;
    duration?: number;
  };
}

export const LearningInsights: React.FC = () => {
  const { user } = useAuth();
  const [learningPatterns, setLearningPatterns] = useState<LearningPattern[]>([]);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);

  useEffect(() => {
    const fetchLearningPatterns = async () => {
      if (!user) return;
      
      try {
        const response = await cheshireService.post('/memory/recall', {
          metadata: {
            userId: user.uid,
            timestamp: {
              after: new Date(Date.now() - 30 * 24 * 60 * 60 * 1000).toISOString()
            }
          },
          k: 100
        });
        
        setLearningPatterns(response.data);
      } catch (err) {
        setError(err instanceof Error ? err.message : 'Failed to fetch learning patterns');
      } finally {
        setLoading(false);
      }
    };

    fetchLearningPatterns();
  }, [user]);

  if (loading) {
    return (
      <div className="flex justify-center items-center h-48">
        <div className="animate-spin rounded-full h-8 w-8 border-b-2 border-gray-900" />
      </div>
    );
  }

  if (error) {
    return (
      <Alert>
        <AlertDescription>{error}</AlertDescription>
      </Alert>
    );
  }

  const calculateEngagement = (patterns: LearningPattern[]) => {
    if (!patterns.length) return 0;
    return patterns.reduce((sum, p) => sum + (p.metadata?.engagement || 0), 0) / patterns.length;
  };

  const findPreferredStyle = (patterns: LearningPattern[]) => {
    const styles = patterns.reduce((acc, p) => {
      const style = p.metadata?.learningStyle;
      if (style) acc[style] = (acc[style] || 0) + 1;
      return acc;
    }, {} as Record<string, number>);
    return Object.entries(styles).sort((a, b) => b[1] - a[1])[0]?.[0] || 'Not enough data';
  };

  const engagement = calculateEngagement(learningPatterns);
  const preferredStyle = findPreferredStyle(learningPatterns);

  return (
    <div className="space-y-6">
      <Card>
        <CardHeader>
          <CardTitle className="flex items-center gap-2">
            <Brain className="w-5 h-5" />
            Learning Insights
          </CardTitle>
        </CardHeader>
        <CardContent>
          <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
            <div className="space-y-2">
              <div className="flex items-center gap-2">
                <Activity className="w-4 h-4 text-blue-500" />
                <span className="font-medium">Engagement Level</span>
              </div>
              <div className="text-2xl">
                {(engagement * 100).toFixed(1)}%
              </div>
            </div>

            <div className="space-y-2">
              <div className="flex items-center gap-2">
                <BookOpen className="w-4 h-4 text-green-500" />
                <span className="font-medium">Preferred Learning Style</span>
              </div>
              <div className="text-2xl capitalize">
                {preferredStyle}
              </div>
            </div>

            <div className="space-y-2">
              <div className="flex items-center gap-2">
                <TrendingUp className="w-4 h-4 text-purple-500" />
                <span className="font-medium">Learning Sessions</span>
              </div>
              <div className="text-2xl">
                {learningPatterns.length}
              </div>
            </div>

            <div className="space-y-2">
              <div className="flex items-center gap-2">
                <Clock className="w-4 h-4 text-orange-500" />
                <span className="font-medium">Average Session Duration</span>
              </div>
              <div className="text-2xl">
                {learningPatterns.length ? 
                  `${Math.round(learningPatterns.reduce((sum, p) => 
                    sum + (p.metadata?.duration || 0), 0) / learningPatterns.length)} mins` :
                  'N/A'
                }
              </div>
            </div>
          </div>

          {learningPatterns.length > 0 && (
            <div className="mt-6">
              <h3 className="font-medium mb-2">Recent Topics</h3>
              <div className="space-y-1">
                {learningPatterns.slice(0, 5).map((pattern, index) => (
                  <div 
                    key={index}
                    className="flex justify-between items-center p-2 bg-gray-50 rounded"
                  >
                    <span>{pattern.metadata?.topic || 'Unnamed Topic'}</span>
                    <span className="text-sm text-gray-500">
                      {pattern.metadata?.timestamp ? 
                        new Date(pattern.metadata.timestamp).toLocaleDateString() :
                        'N/A'
                      }
                    </span>
                  </div>
                ))}
              </div>
            </div>
          )}
        </CardContent>
      </Card>
    </div>
  );
};

export default LearningInsights;
```

## backend/Artifacts/cat-plugin-artifact/interaction-hook.ts

```
// File: src/hooks/useInteractionAnalysis.ts
import { useState, useEffect, useCallback } from 'react';
import { useAuth } from '@/contexts/AuthContext';
import { interactionAnalyzer } from '@/services/interactionAnalysis';

export interface InteractionTelemetry {
  queryStartTime: number;
  feedbackCount: number;
}

export function useInteractionAnalysis() {
  const { user } = useAuth();
  const [currentInteraction, setCurrentInteraction] = useState<InteractionTelemetry | null>(null);
  const [learningStyle, setLearningStyle] = useState<{
    style: string;
    confidence: number;
  } | null>(null);
  const [loading, setLoading] = useState(false);

  // Update learning style prediction periodically
  useEffect(() => {
    if (!user) return;

    const updateLearningStyle = async () => {
      try {
        const prediction = await interactionAnalyzer.predictLearningStyle(user.uid);
        setLearningStyle({
          style: prediction.style,
          confidence: prediction.confidence
        });
      } catch (error) {
        console.error('Failed to update learning style:', error);
      }
    };

    // Update every 5 minutes
    const interval = setInterval(updateLearningStyle, 5 * 60 * 1000);
    updateLearningStyle(); // Initial update

    return () => clearInterval(interval);
  }, [user]);

  // Start tracking a new interaction
  const startInteraction = useCallback(() => {
    setCurrentInteraction({
      queryStartTime: Date.now(),
      feedbackCount: 0
    });
  }, []);

  // Record feedback iteration
  const recordFeedback = useCallback(() => {
    if (currentInteraction) {
      setCurrentInteraction(prev => prev ? {
        ...prev,
        feedbackCount: prev.feedbackCount + 1
      } : null);
    }
  }, [currentInteraction]);

  // Complete and analyze the current interaction
  const completeInteraction = useCallback(async (
    query: string
  ) => {
    if (!user || !currentInteraction) return;

    setLoading(true);
    try {
      await interactionAnalyzer.captureInteraction(
        user.uid,
        query,
        currentInteraction.queryStartTime,
        {
          feedbackIterations: currentInteraction.feedbackCount
        }
      );

      // Update learning style prediction
      const prediction = await interactionAnalyzer.predictLearningStyle(user.uid);
      setLearningStyle({
        style: prediction.style,
        confidence: prediction.confidence
      });
    } catch (error) {
      console.error('Failed to complete interaction:', error);
    } finally {
      setLoading(false);
      setCurrentInteraction(null);
    }
  }, [user, currentInteraction]);

  // Adapt content based on current learning style
  const adaptContent = useCallback(async (
    content: string
  ): Promise<string> => {
    if (!learningStyle) return content;

    try {
      return await interactionAnalyzer.adaptContent(
        content,
        learningStyle.style as any
      );
    } catch (error) {
      console.error('Failed to adapt content:', error);
      return content;
    }
  }, [learningStyle]);

  return {
    startInteraction,
    recordFeedback,
    completeInteraction,
    adaptContent,
    learningStyle,
    loading
  };
}
```

## backend/Artifacts/crew-ai-systems/specialized-agents.ts

```
import { CrewAI, Agent, Task } from 'crew-ai';
import { Observable, BehaviorSubject, combineLatest } from 'rxjs';
import { filter, map, switchMap, debounceTime } from 'rxjs/operators';

/**
 * MetacognitiveAgent - Analyzes learning awareness and study strategies
 * Integrates with core assessment flow to evaluate student's learning approach
 */
export class MetacognitiveAgent extends AssessmentAgent {
  private readonly strategyAnalyzer: StudyStrategyAnalyzer;
  private readonly learningAwarenessTracker: AwarenessTracker;

  constructor(config: AgentConfig) {
    super(config);
    this.strategyAnalyzer = new StudyStrategyAnalyzer();
    this.learningAwarenessTracker = new AwarenessTracker();
  }

  async analyzeMetacognition(
    response: StudentResponse,
    historicalData: LearningHistory
  ): Promise<MetacognitiveAnalysis> {
    const strategyPatterns = await this.strategyAnalyzer.identifyPatterns({
      currentResponse: response,
      historicalResponses: historicalData.responses,
      studyHabits: historicalData.studyHabits
    });

    const awarenessMetrics = await this.learningAwarenessTracker.evaluate({
      selfAssessment: response.metadata.selfAssessment,
      actualPerformance: response.metadata.performance,
      confidenceLevel: response.metadata.confidence
    });

    return {
      strategyEffectiveness: this.calculateStrategyEffectiveness(
        strategyPatterns,
        awarenessMetrics
      ),
      learningAwareness: awarenessMetrics,
      recommendations: this.generateMetacognitiveRecommendations(
        strategyPatterns,
        awarenessMetrics
      )
    };
  }

  private calculateStrategyEffectiveness(
    patterns: StrategyPatterns,
    awareness: AwarenessMetrics
  ): EffectivenessScore {
    return {
      score: this.weightedScore(patterns, awareness),
      confidence: this.calculateConfidence(patterns, awareness),
      areas: this.identifyStrengthsAndWeaknesses(patterns, awareness)
    };
  }
}

/**
 * ContentOptimizationAgent - Manages dynamic content adaptation
 * Uses machine learning to optimize content presentation
 */
export class ContentOptimizationAgent extends AssessmentAgent {
  private readonly contentAnalyzer: ContentAnalysisEngine;
  private readonly presentationOptimizer: PresentationOptimizer;
  private readonly mlModel: ContentMLModel;

  async optimizeContent(
    currentContent: LearningContent,
    studentProfile: StudentProfile,
    performanceMetrics: PerformanceMetrics
  ): Promise<OptimizedContent> {
    // Analyze current content effectiveness
    const contentAnalysis = await this.contentAnalyzer.analyze(
      currentContent,
      performanceMetrics
    );

    // Generate optimization recommendations
    const optimizationStrategy = await this.mlModel.predict({
      content: contentAnalysis,
      profile: studentProfile,
      metrics: performanceMetrics
    });

    // Apply optimizations
    return await this.presentationOptimizer.optimize(
      currentContent,
      optimizationStrategy
    );
  }

  private async applyOptimizations(
    content: LearningContent,
    strategy: OptimizationStrategy
  ): Promise<OptimizedContent> {
    const optimizedContent = { ...content };

    // Apply format optimizations
    if (strategy.formatChanges) {
      optimizedContent.format = await this.optimizeFormat(
        content.format,
        strategy.formatChanges
      );
    }

    // Apply difficulty adjustments
    if (strategy.difficultyAdjustment) {
      optimizedContent.difficulty = await this.adjustDifficulty(
        content.difficulty,
        strategy.difficultyAdjustment
      );
    }

    return optimizedContent;
  }
}

/**
 * MotivationalAgent - Tracks and influences student motivation
 * Provides targeted interventions based on engagement patterns
 */
export class MotivationalAgent extends AssessmentAgent {
  private readonly motivationTracker: MotivationTrackingEngine;
  private readonly interventionManager: InterventionManager;

  async analyzeMotivation(
    studentData: StudentData
  ): Promise<MotivationAnalysis> {
    const motivationMetrics = await this.motivationTracker.analyze({
      engagement: studentData.engagementMetrics,
      performance: studentData.performanceHistory,
      feedback: studentData.feedbackResponses
    });

    if (this.requiresIntervention(motivationMetrics)) {
      const intervention = await this.interventionManager.generateIntervention(
        motivationMetrics
      );

      return {
        metrics: motivationMetrics,
        intervention: intervention,
        recommendations: this.generateMotivationalRecommendations(
          motivationMetrics,
          intervention
        )
      };
    }

    return {
      metrics: motivationMetrics,
      recommendations: this.generateMaintenanceStrategies(motivationMetrics)
    };
  }

  private requiresIntervention(metrics: MotivationMetrics): boolean {
    return (
      metrics.engagementTrend < this.thresholds.engagement ||
      metrics.persistenceScore < this.thresholds.persistence ||
      metrics.confidenceLevel < this.thresholds.confidence
    );
  }
}

/**
 * PeerLearningAgent - Facilitates collaborative learning opportunities
 * Matches students and manages group interactions
 */
export class PeerLearningAgent extends AssessmentAgent {
  private readonly peerMatcher: PeerMatchingEngine;
  private readonly collaborationTracker: CollaborationTracker;

  async facilitateCollaboration(
    student: StudentProfile,
    learningContext: LearningContext
  ): Promise<CollaborationPlan> {
    // Find suitable peer matches
    const matches = await this.peerMatcher.findMatches({
      student,
      context: learningContext,
      criteria: this.getMatchingCriteria(student)
    });

    // Generate collaboration structure
    const collaborationStructure = await this.designCollaboration(
      matches,
      learningContext
    );

    return {
      peers: matches,
      structure: collaborationStructure,
      guidelines: this.generateCollaborationGuidelines(
        matches,
        collaborationStructure
      ),
      assessmentCriteria: this.defineAssessmentCriteria(
        collaborationStructure
      )
    };
  }

  async trackCollaboration(
    collaborationId: string
  ): Promise<CollaborationMetrics> {
    return await this.collaborationTracker.track(collaborationId);
  }
}

/**
 * LearningPathAgent - Generates and adapts personalized learning paths
 * Integrates insights from other agents to optimize learning progression
 */
export class LearningPathAgent extends AssessmentAgent {
  private readonly pathGenerator: PathGenerationEngine;
  private readonly progressTracker: ProgressTrackingEngine;
  private readonly goalManager: LearningGoalManager;

  async generateLearningPath(
    student: StudentProfile,
    assessmentResults: AssessmentResults
  ): Promise<LearningPath> {
    // Set learning goals
    const goals = await this.goalManager.defineGoals(
      student,
      assessmentResults
    );

    // Generate initial path
    const initialPath = await this.pathGenerator.createPath({
      student,
      goals,
      assessmentResults
    });

    // Add checkpoints and alternatives
    return this.enhancePath(initialPath, student);
  }

  async adaptPath(
    currentPath: LearningPath,
    progressData: ProgressData
  ): Promise<PathAdaptation> {
    const progressAnalysis = await this.progressTracker.analyzeTrends(
      progressData
    );

    if (this.requiresAdaptation(progressAnalysis)) {
      return await this.generatePathAdaptation(
        currentPath,
        progressAnalysis
      );
    }

    return null;
  }

  private async enhancePath(
    path: LearningPath,
    student: StudentProfile
  ): Promise<LearningPath> {
    return {
      ...path,
      checkpoints: await this.generateCheckpoints(path),
      alternatives: await this.generateAlternatives(path, student),
      supportResources: await this.identifyResources(path, student)
    };
  }
}

/**
 * React integration example showing agent coordination
 */
export const AssessmentCoordinator: React.FC = () => {
  const [assessmentState, setAssessmentState] = useState<AssessmentState>({});
  const agents = useRef<AgentCollection>({
    metacognitive: new MetacognitiveAgent(config),
    content: new ContentOptimizationAgent(config),
    motivation: new MotivationalAgent(config),
    peer: new PeerLearningAgent(config),
    path: new LearningPathAgent(config)
  });

  useEffect(() => {
    const subscription = combineLatest([
      agents.current.metacognitive.updates$,
      agents.current.content.updates$,
      agents.current.motivation.updates$,
      agents.current.peer.updates$,
      agents.current.path.updates$
    ]).pipe(
      debounceTime(300),
      map(([metacognitive, content, motivation, peer, path]) => ({
        metacognitive,
        content,
        motivation,
        peer,
        path
      }))
    ).subscribe(updates => {
      setAssessmentState(prevState => ({
        ...prevState,
        ...updates
      }));
    });

    return () => subscription.unsubscribe();
  }, []);

  return (
    <AssessmentContext.Provider value={agents.current}>
      <AssessmentInterface
        state={assessmentState}
        onUpdate={handleAssessmentUpdate}
      />
      <AgentFeedbackPanel
        feedback={assessmentState.feedback}
        recommendations={assessmentState.recommendations}
      />
      <LearningPathVisualizer
        path={assessmentState.learningPath}
        progress={assessmentState.progress}
      />
    </AssessmentContext.Provider>
  );
};

```

## backend/Artifacts/crew-ai-systems/advanced-agent-system.ts

```
import { Agent, Task, CrewAIClient } from 'crewai';
import { Observable, BehaviorSubject, Subject } from 'rxjs';
import { filter, map, mergeMap } from 'rxjs/operators';
import { 
  collection, 
  doc, 
  setDoc, 
  onSnapshot,
  writeBatch 
} from 'firebase/firestore';
import { AgentMessage, AgentRole, TaskPriority } from '../types/agents';

interface AgentContext {
  role: AgentRole;
  knowledge: string[];
  capabilities: Set<string>;
  taskHistory: TaskResult[];
  performance: AgentPerformance;
}

interface TaskResult {
  taskId: string;
  success: boolean;
  confidence: number;
  duration: number;
  outputs: any[];
}

class AdvancedAgentSystem {
  private readonly agents: Map<string, Agent>;
  private readonly contexts: Map<string, AgentContext>;
  private readonly messageQueue: Subject<AgentMessage>;
  private readonly taskResults: BehaviorSubject<TaskResult[]>;
  private readonly firestore: FirebaseFirestore.Firestore;

  constructor(
    firestore: FirebaseFirestore.Firestore,
    crewAI: CrewAIClient
  ) {
    this.firestore = firestore;
    this.agents = new Map();
    this.contexts = new Map();
    this.messageQueue = new Subject<AgentMessage>();
    this.taskResults = new BehaviorSubject<TaskResult[]>([]);

    // Initialize core agents
    this.initializeAgents(crewAI);
    this.setupMessageHandling();
    this.setupPerformanceMonitoring();
  }

  private initializeAgents(crewAI: CrewAIClient): void {
    // Content Strategy Agent
    const strategist = new Agent({
      name: 'ContentStrategist',
      role: AgentRole.STRATEGIST,
      goal: 'Design optimal learning pathways and content strategies',
      backstory: 'Expert in educational design and content strategy',
      allowDelegation: true,
      verbose: true,
      tools: [
        'pathwayDesign',
        'contentPlanning',
        'strategyOptimization'
      ]
    });

    // Adaptation Specialist
    const adapter = new Agent({
      name: 'AdaptationSpecialist',
      role: AgentRole.ADAPTER,
      goal: 'Adapt and personalize learning content',
      backstory: 'Specialist in content adaptation and personalization',
      allowDelegation: true,
      verbose: true,
      tools: [
        'contentAdaptation',
        'personalizationEngine',
        'difficultyAdjustment'
      ]
    });

    // Learning Analyst
    const analyst = new Agent({
      name: 'LearningAnalyst',
      role: AgentRole.ANALYST,
      goal: 'Analyze learning patterns and optimize outcomes',
      backstory: 'Expert in learning analytics and pattern recognition',
      allowDelegation: true,
      verbose: true,
      tools: [
        'performanceAnalysis',
        'patternRecognition',
        'predictiveModeling'
      ]
    });

    // Quality Assurance Agent
    const validator = new Agent({
      name: 'QualityAssurance',
      role: AgentRole.VALIDATOR,
      goal: 'Ensure content quality and standards compliance',
      backstory: 'Expert in educational standards and quality control',
      allowDelegation: true,
      verbose: true,
      tools: [
        'contentValidation',
        'standardsCompliance',
        'accessibilityChecking'
      ]
    });

    // Add agents to system
    this.agents.set('strategist', strategist);
    this.agents.set('adapter', adapter);
    this.agents.set('analyst', analyst);
    this.agents.set('validator', validator);

    // Initialize contexts
    this.initializeContexts();
  }

  private initializeContexts(): void {
    this.agents.forEach((agent, id) => {
      this.contexts.set(id, {
        role: agent.role,
        knowledge: [],
        capabilities: new Set(),
        taskHistory: [],
        performance: {
          successRate: 0,
          avgConfidence: 0,
          avgDuration: 0
        }
      });
    });
  }

  private setupMessageHandling(): void {
    this.messageQueue.pipe(
      filter(msg => this.validateMessage(msg)),
      mergeMap(msg => this.processMessage(msg))
    ).subscribe(
      result => this.handleTaskResult(result),
      error => console.error('Message processing error:', error)
    );
  }

  private setupPerformanceMonitoring(): void {
    // Monitor agent performance metrics
    setInterval(() => {
      this.contexts.forEach((context, agentId) => {
        this.updateAgentPerformance(agentId);
      });
    }, 60000); // Update every minute
  }

  /**
   * Execute a complex task using multiple agents
   * @param task Initial task description
   * @param priority Task priority level
   */
  public async executeComplexTask(
    task: Task,
    priority: TaskPriority = TaskPriority.NORMAL
  ): Promise<TaskResult[]> {
    try {
      // Initialize task context
      const taskContext = {
        id: `task_${Date.now()}`,
        priority,
        startTime: Date.now(),
        involvedAgents: new Set<string>()
      };

      // Analyze task requirements
      const requirements = await this.analyzeTaskRequirements(task);

      // Select primary agent
      const primaryAgent = this.selectPrimaryAgent(requirements);
      taskContext.involvedAgents.add(primaryAgent);

      // Create subtasks
      const subtasks = await this.createSubtasks(task, requirements);

      // Execute subtasks with appropriate agents
      const results = await Promise.all(
        subtasks.map(subtask => 
          this.executeSubtask(subtask, taskContext)
        )
      );

      // Validate results
      const validationResult = await this.validateResults(results);

      // Store task results
      await this.storeTaskResults(taskContext.id, results);

      return results;
    } catch (error) {
      console.error('Complex task execution failed:', error);
      throw error;
    }
  }

  /**
   * Add knowledge to agent context
   * @param agentId Agent identifier
   * @param knowledge New knowledge to add
   */
  public async enhanceAgentKnowledge(
    agentId: string,
    knowledge: string[]
  ): Promise<void> {
    const context = this.contexts.get(agentId);
    if (!context) throw new Error(`Agent ${agentId} not found`);

    context.knowledge.push(...knowledge);
    await this.updateAgentContext(agentId, context);
  }

  /**
   * Get agent performance metrics
   * @param agentId Agent identifier
   */
  public getAgentPerformance(
    agentId: string
  ): Observable<AgentPerformance> {
    return new Observable(subscriber => {
      const unsubscribe = onSnapshot(
        doc(this.firestore, 'agentPerformance', agentId),
        (snapshot) => {
          if (snapshot.exists()) {
            subscriber.next(snapshot.data() as AgentPerformance);
          }
        },
        error => subscriber.error(error)
      );

      return () => unsubscribe();
    });
  }

  private async analyzeTaskRequirements(
    task: Task
  ): Promise<TaskRequirements> {
    const analyst = this.agents.get('analyst');
    if (!analyst) throw new Error('Analyst agent not found');

    const analysisTask = new Task({
      description: 'Analyze task requirements and complexity',
      parameters: {
        task,
        context: this.getGlobalContext()
      }
    });

    return await analyst.execute(analysisTask);
  }

  private selectPrimaryAgent(
    requirements: TaskRequirements
  ): string {
    // Select agent based on requirements and performance history
    let bestMatch: { agentId: string; score: number } = {
      agentId: '',
      score: 0
    };

    this.contexts.forEach((context, agentId) => {
      const score = this.calculateAgentScore(context, requirements);
      if (score > bestMatch.score) {
        bestMatch = { agentId, score };
      }
    });

    return bestMatch.agentId;
  }

  private async createSubtasks(
    task: Task,
    requirements: TaskRequirements
  ): Promise<Task[]> {
    const strategist = this.agents.get('strategist');
    if (!strategist) throw new Error('Strategist agent not found');

    const planningTask = new Task({
      description: 'Create optimal subtask breakdown',
      parameters: {
        task,
        requirements,
        constraints: this.getSystemConstraints()
      }
    });

    return await strategist.execute(planningTask);
  }

  private async executeSubtask(
    subtask: Task,
    taskContext: TaskContext
  ): Promise<TaskResult> {
    const agent = this.agents.get(this.selectAgentForSubtask(subtask));
    if (!agent) throw new Error('No suitable agent found for subtask');

    // Add to task context
    taskContext.involvedAgents.add(agent.name);

    // Execute subtask
    const result = await agent.execute(subtask);

    // Validate result
    const validator = this.agents.get('validator');
    if (validator) {
      const validationTask = new Task({
        description: 'Validate subtask result',
        parameters: {
          result,
          requirements: subtask.requirements
        }
      });
      await validator.execute(validationTask);
    }

    return {
      taskId: subtask.id,
      success: true,
      confidence: result.confidence,
      duration: Date.now() - taskContext.startTime,
      outputs: result.outputs
    };
  }

  private async validateResults(
    results: TaskResult[]
  ): Promise<ValidationResult> {
    const validator = this.agents.get('validator');
    if (!validator) throw new Error('Validator agent not found');

    const validationTask = new Task({
      description: 'Validate overall task results',
      parameters: {
        results,
        requirements: this.getValidationRequirements()
      }
    });

    return await validator.execute(validationTask);
  }

  private async updateAgentPerformance(agentId: string): Promise<void> {
    const context = this.contexts.get(agentId);
    if (!context) return;

    const recentTasks = context.taskHistory.slice(-10);
    const performance = {
      successRate: recentTasks.filter(t => t.success).length / recentTasks.length,
      avgConfidence: recentTasks.reduce((sum, t) => sum + t.confidence, 0) / recentTasks.length,
      avgDuration: recentTasks.reduce((sum, t) => sum + t.duration, 0) / recentTasks.length
    };

    await setDoc(
      doc(this.firestore, 'agentPerformance', agentId),
      performance
    );
  }

  private async storeTaskResults(
    taskId: string,
    results: TaskResult[]
  ): Promise<void> {
    const batch = writeBatch(this.firestore);
    
    results.forEach(result => {
      const resultRef = doc(
        collection(this.firestore, 'taskResults'),
        `${taskId}_${result.taskId}`
      );
      batch.set(resultRef, {
        ...result,
        timestamp: Date.now()
      });
    });

    await batch.commit();
  }
}

// React hook for advanced agent interactions
export const useAdvancedAgents = (
  firestore: FirebaseFirestore.Firestore,
  crewAI: CrewAIClient
) => {
  const system = useMemo(
    () => new AdvancedAgentSystem(firestore, crewAI),
    [firestore, crewAI]
  );

  const executeComplexTask = useCallback(async (
    task: Task,
    priority?: TaskPriority
  ) => {
    return await system.executeComplexTask(task, priority);
  }, [system]);

  const enhanceAgentKnowledge = useCallback(async (
    agentId: string,
    knowledge: string[]
  ) => {
    await system.enhanceAgentKnowledge(agentId, knowledge);
  }, [system]);

  const getAgentPerformance = useCallback((
    agentId: string
  ) => {
    return system.getAgentPerformance(agentId);
  }, [system]);

  return {
    executeComplexTask,
    enhanceAgentKnowledge,
    getAgentPerformance
  };
};

```

## backend/Artifacts/crew-ai-systems/README.md

```
# CrewAI & AI Agent Systems

## Overview
This module handles the AI agent orchestration and interactions within Geaux Academy, providing intelligent, coordinated responses and actions across the platform.

## Core Components

### 1. Agent System
- **advanced-agent-system.ts**: Core agent architecture implementation
- **specialized-agents.{py,ts}**: Domain-specific agents for different learning areas
- **ai-enhancement-system.ts**: AI capability augmentation and optimization

### 2. Agent Interactions
- **agent-interactions.{py,ts}**: Inter-agent communication protocols
- **agent-orchestration.py**: Coordination of multiple agents
- **crew-integration.ts**: CrewAI framework integration

### 3. Monitoring & Control
- **agent-monitor.tsx**: Real-time agent monitoring interface
- **agent-monitoring.py**: Backend monitoring system
- **crew-monitoring.tsx**: CrewAI system oversight

## Key Features
- Intelligent agent coordination
- Real-time monitoring and adaptation
- Specialized learning agents
- Multi-agent communication
- Performance optimization
- Dynamic task allocation

## Technologies
- TypeScript/Python for agent implementation
- React for monitoring interfaces
- CrewAI framework
- WebSocket for real-time monitoring
- State management for agent coordination

## Integration Points
- Learning Assessment System
- Curriculum Generation
- Student Progress Tracking
- Performance Analytics

## Usage Examples
```typescript
// Example of agent initialization
const learningAgent = new SpecializedAgent({
  domain: 'mathematics',
  adaptiveLevel: true,
  learningStyle: student.preferredStyle
});

// Example of agent coordination
const crewSystem = new CrewIntegration({
  agents: [learningAgent, assessmentAgent, curriculumAgent],
  orchestration: 'adaptive'
});
```

## Best Practices
1. Always implement error handling for agent interactions
2. Monitor agent performance metrics
3. Implement fallback mechanisms
4. Regular validation of agent responses
5. Maintain agent state consistency
```

## backend/Artifacts/crew-ai-systems/crew-monitoring.tsx

```
import React, { useState, useEffect } from 'react';
import { Card, CardHeader, CardTitle, CardContent } from '@/components/ui/card';
import { Alert, AlertDescription } from '@/components/ui/alert';
import { 
  Activity, 
  Users, 
  CheckCircle, 
  XCircle, 
  Clock, 
  ArrowRight 
} from 'lucide-react';
import { useCrewOrchestration } from '@/hooks/useCrewOrchestration';
import { AgentRole, TaskStatus, TaskDefinition } from '@/lib/crew/types';
import { format } from 'date-fns';

const CrewMonitoringDashboard: React.FC = () => {
  const { orchestrator, loading, error } = useCrewOrchestration();
  const [agentStatuses, setAgentStatuses] = useState<Record<AgentRole, any>>({});
  const [tasks, setTasks] = useState<TaskDefinition[]>([]);
  const [selectedAgent, setSelectedAgent] = useState<AgentRole | null>(null);

  useEffect(() => {
    if (!orchestrator) return;

    // Subscribe to agent statuses
    const unsubscribeStatus = subscribeToAgentStatuses((statuses) => {
      setAgentStatuses(statuses);
    });

    // Subscribe to tasks
    const unsubscribeTasks = subscribeToTasks((updatedTasks) => {
      setTasks(updatedTasks);
    });

    return () => {
      unsubscribeStatus();
      unsubscribeTasks();
    };
  }, [orchestrator]);

  const AgentCard: React.FC<{ role: AgentRole }> = ({ role }) => {
    const status = agentStatuses[role];
    const activeTasks = tasks.filter(
      task => task.assignedTo === role && task.status === 'IN_PROGRESS'
    );

    return (
      <Card 
        className={`cursor-pointer transition-shadow hover:shadow-md ${
          selectedAgent === role ? 'ring-2 ring-primary' : ''
        }`}
        onClick={() => setSelectedAgent(selectedAgent === role ? null : role)}
      >
        <CardContent className="p-4">
          <div className="flex justify-between items-start">
            <div>
              <h3 className="font-medium">{role}</h3>
              <div className="flex items-center mt-1">
                <div className={`w-2 h-2 rounded-full ${
                  status?.online ? 'bg-green-500' : 'bg-red-500'
                }`} />
                <span className="text-sm text-gray-500 ml-2">
                  {status?.online ? 'Online' : 'Offline'}
                </span>
              </div>
            </div>
            <div className="text-right">
              <p className="text-sm font-medium">
                {activeTasks.length} Active Tasks
              </p>
              <p className="text-xs text-gray-500">
                {status?.load.toFixed(1)}% Load
              </p>
            </div>
          </div>

          {status?.lastHeartbeat && (
            <p className="text
```

## backend/Artifacts/crew-ai-systems/agent-monitor.tsx

```
import React, { useState, useEffect } from 'react';
import { useFirestore } from 'reactfire';
import { Card, CardHeader, CardTitle, CardContent } from '@/components/ui/card';
import { Tabs, TabsList, TabsTrigger, TabsContent } from '@/components/ui/tabs';
import { Alert, AlertDescription } from '@/components/ui/alert';
import { useAdvancedAgents } from '../hooks/useAdvancedAgents';
import { LineChart, Line, XAxis, YAxis, CartesianGrid, Tooltip, Legend, ResponsiveContainer } from 'recharts';
import { Activity, Users, Brain, AlertTriangle, BarChart, RefreshCw } from 'lucide-react';
import type { AgentPerformance, TaskResult } from '../types/agents';

interface AgentMonitorProps {
  onTaskComplete: (results: TaskResult[]) => void;
}

export const AgentMonitor: React.FC<AgentMonitorProps> = ({
  onTaskComplete
}) => {
  const [activeTab, setActiveTab] = useState<string>('performance');
  const [agentPerformance, setAgentPerformance] = useState<Record<string, AgentPerformance>>({});
  const [taskHistory, setTaskHistory] = useState<TaskResult[]>([]);
  const [isLoading, setIsLoading] = useState<boolean>(false);
  const [error, setError] = useState<string | null>(null);

  const firestore = useFirestore();
  const crewAI = useCrewAI();  // Custom hook for CrewAI client

  const {
    executeComplexTask,
    enhanceAgentKnowledge,
    getAgentPerformance
  } = useAdvancedAgents(firestore, crewAI);

  
```

## backend/Artifacts/crew-ai-systems/crew-integration.ts

```
// File: /src/lib/crew/types.ts
import { z } from 'zod';
import { Agent, Task } from 'crewai-ts';

// Type-safe agent role definitions
export const AgentRoleSchema = z.enum([
  'TEACHER',
  'RESEARCHER',
  'SUPERVISOR',
  'CURRICULUM_VALIDATOR',
  'CONTENT_GENERATOR',
]);

export type AgentRole = z.infer<typeof AgentRoleSchema>;

// Agent capability schema
export const AgentCapabilitySchema = z.object({
  role: AgentRoleSchema,
  maxConcurrentTasks: z.number().min(1).max(10),
  allowDelegation: z.boolean(),
  toolset: z.array(z.string()),
  modelConfig: z.object({
    model: z.string(),
    temperature: z.number().min(0).max(1),
    maxTokens: z.number().min(100).max(4000),
  }),
});

export type AgentCapability = z.infer<typeof AgentCapabilitySchema>;

// Task status tracking
export const TaskStatusSchema = z.enum([
  'PENDING',
  'IN_PROGRESS',
  'COMPLETED',
  'FAILED',
  'DELEGATED',
]);

export type TaskStatus = z.infer<typeof TaskStatusSchema>;

// Task definition schema
export const TaskDefinitionSchema = z.object({
  id: z.string(),
  type: z.string(),
  description: z.string(),
  assignedTo: AgentRoleSchema,
  status: TaskStatusSchema,
  priority: z.number().min(1).max(5),
  dependencies: z.array(z.string()),
  metadata: z.record(z.unknown()),
  createdAt: z.date(),
  updatedAt: z.date(),
});

export type TaskDefinition = z.infer<typeof TaskDefinitionSchema>;

// File: /src/lib/crew/orchestrator.ts
import { db } from '@/lib/firebase';
import { 
  collection, 
  doc, 
  updateDoc, 
  onSnapshot, 
  query, 
  where,
  Timestamp 
} from 'firebase/firestore';
import { v4 as uuidv4 } from 'uuid';

export class CrewOrchestrator {
  private agents: Map<AgentRole, Agent>;
  private tasks: Map<string, Task>;
  private subscriptions: (() => void)[];

  constructor() {
    this.agents = new Map();
    this.tasks = new Map();
    this.subscriptions = [];
  }

  /**
   * Initialize agent with specified capabilities
   */
  async initializeAgent(
    role: AgentRole, 
    capabilities: AgentCapability
  ): Promise<void> {
    const agent = new Agent({
      role: role,
      goal: `Serve as ${role} in Geaux Academy's educational system`,
      backstory: this.getAgentBackstory(role),
      allowDelegation: capabilities.allowDelegation,
      verbose: true,
      ...capabilities.modelConfig,
    });

    this.agents.set(role, agent);

    // Sync agent state to Firebase
    await this.syncAgentState(role, agent);
    
    // Subscribe to agent configuration changes
    this.subscribeToAgentConfig(role, agent);
  }

  /**
   * Create and assign a new task to an agent
   */
  async createTask(
    type: string,
    description: string,
    assignedTo: AgentRole,
    priority: number = 3,
    dependencies: string[] = []
  ): Promise<string> {
    const taskId = uuidv4();
    const task: TaskDefinition = {
      id: taskId,
      type,
      description,
      assignedTo,
      status: 'PENDING',
      priority,
      dependencies,
      metadata: {},
      createdAt: new Date(),
      updatedAt: new Date(),
    };

    // Store task in Firebase
    await this.storeTask(task);

    // Assign to agent if no dependencies
    if (dependencies.length === 0) {
      await this.assignTask(taskId);
    }

    return taskId;
  }

  /**
   * Monitor task execution and handle state changes
   */
  private async monitorTask(taskId: string): Promise<void> {
    const taskRef = doc(db, 'tasks', taskId);
    
    return onSnapshot(taskRef, async (snapshot) => {
      const task = snapshot.data() as TaskDefinition;
      
      if (task.status === 'COMPLETED') {
        // Check dependent tasks
        const dependentTasks = await this.getDependentTasks(taskId);
        for (const depTask of dependentTasks) {
          await this.checkTaskDependencies(depTask.id);
        }
      }
    });
  }

  /**
   * Check and update task dependencies
   */
  private async checkTaskDependencies(taskId: string): Promise<void> {
    const task = await this.getTask(taskId);
    if (!task) return;

    const dependencies = await this.getTaskDependencies(task);
    const allCompleted = dependencies.every(dep => dep.status === 'COMPLETED');

    if (allCompleted && task.status === 'PENDING') {
      await this.assignTask(taskId);
    }
  }

  /**
   * Assign task to appropriate agent
   */
  private async assignTask(taskId: string): Promise<void> {
    const task = await this.getTask(taskId);
    if (!task) return;

    const agent = this.agents.get(task.assignedTo);
    if (!agent) {
      throw new Error(`No agent found for role: ${task.assignedTo}`);
    }

    // Check agent capacity
    const activeTaskCount = await this.getAgentActiveTaskCount(task.assignedTo);
    const capabilities = await this.getAgentCapabilities(task.assignedTo);

    if (activeTaskCount >= capabilities.maxConcurrentTasks) {
      // Queue task for later
      await this.queueTask(task);
      return;
    }

    // Update task status
    await this.updateTaskStatus(taskId, 'IN_PROGRESS');

    // Execute task
    try {
      const result = await agent.executeTask(this.createAgentTask(task));
      await this.handleTaskResult(taskId, result);
    } catch (error) {
      await this.handleTaskError(taskId, error);
    }
  }

  /**
   * Create CrewAI task from task definition
   */
  private createAgentTask(task: TaskDefinition): Task {
    return new Task({
      description: task.description,
      expected_output: `Complete ${task.type} task according to Geaux Academy standards`,
      tools: this.getAgentTools(task.assignedTo),
      async_execution: true,
      context: task.metadata,
    });
  }

  /**
   * Handle successful task completion
   */
  private async handleTaskResult(
    taskId: string, 
    result: any
  ): Promise<void> {
    await updateDoc(doc(db, 'tasks', taskId), {
      status: 'COMPLETED',
      result: result,
      updatedAt: Timestamp.now(),
    });
  }

  /**
   * Handle task execution error
   */
  private async handleTaskError(
    taskId: string, 
    error: any
  ): Promise<void> {
    await updateDoc(doc(db, 'tasks', taskId), {
      status: 'FAILED',
      error: error.message,
      updatedAt: Timestamp.now(),
    });

    // Notify supervisor agent
    await this.notifySupervisor(taskId, error);
  }

  /**
   * Subscribe to agent configuration changes
   */
  private subscribeToAgentConfig(
    role: AgentRole, 
    agent: Agent
  ): void {
    const unsubscribe = onSnapshot(
      doc(db, 'agentConfigurations', role),
      (snapshot) => {
        const config = snapshot.data() as AgentCapability;
        if (config) {
          this.updateAgentConfiguration(agent, config);
        }
      }
    );

    this.subscriptions.push(unsubscribe);
  }

  /**
   * Clean up subscriptions and resources
   */
  public cleanup(): void {
    this.subscriptions.forEach(unsubscribe => unsubscribe());
    this.subscriptions = [];
  }

  // Utility methods
  private getAgentBackstory(role: AgentRole): string {
    const backstories = {
      TEACHER: 'Expert educator focused on personalized learning...',
      RESEARCHER: 'Academic specialist in educational content validation...',
      SUPERVISOR: 'Experienced overseer of educational quality...',
      // Add other role backstories
    };
    return backstories[role] || 'Educational AI agent';
  }

  private getAgentTools(role: AgentRole): string[] {
    const toolsets = {
      TEACHER: ['content_generation', 'assessment_creation'],
      RESEARCHER: ['content_validation', 'standards_verification'],
      SUPERVISOR: ['quality_check', 'performance_monitoring'],
      // Add other role toolsets
    };
    return toolsets[role] || [];
  }
}

// File: /src/hooks/useCrewOrchestration.ts
import { useState, useEffect, useCallback } from 'react';
import { CrewOrchestrator } from '@/lib/crew/orchestrator';
import { useAuth } from '@/contexts/AuthContext';

export const useCrewOrchestration = () => {
  const { user } = useAuth();
  const [orchestrator, setOrchestrator] = useState<CrewOrchestrator | null>(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState<Error | null>(null);

  useEffect(() => {
    if (!user) return;

    const initOrchestrator = async () => {
      try {
        const newOrchestrator = new CrewOrchestrator();
        
        // Initialize core agents
        await newOrchestrator.initializeAgent('TEACHER', {
          role: 'TEACHER',
          maxConcurrentTasks: 5,
          allowDelegation: true,
          toolset: ['content_generation', 'assessment_creation'],
          modelConfig: {
            model: 'gpt-4',
            temperature: 0.7,
            maxTokens: 2000,
          },
        });

        // Initialize other agents...

        setOrchestrator(newOrchestrator);
      } catch (err) {
        setError(err as Error);
      } finally {
        setLoading(false);
      }
    };

    initOrchestrator();

    return () => {
      orchestrator?.cleanup();
    };
  }, [user]);

  const createTask = useCallback(async (
    type: string,
    description: string,
    assignedTo: AgentRole,
    priority?: number,
    dependencies?: string[]
  ): Promise<string> => {
    if (!orchestrator) {
      throw new Error('Orchestrator not initialized');
    }

    return orchestrator.createTask(
      type,
      description,
      assignedTo,
      priority,
      dependencies
    );
  }, [orchestrator]);

  return {
    orchestrator,
    loading,
    error,
    createTask,
  };
};

```

## backend/Artifacts/crew-ai-systems/ai-enhancement-system.ts

```
import { Agent, Task, CrewAIClient } from 'crewai';
import { 
  collection, 
  query, 
  where, 
  orderBy, 
  getDocs,
  writeBatch 
} from 'firebase/firestore';
import { Observable, BehaviorSubject } from 'rxjs';
import { LearningProfile, ContentAdaptation, PathwayNode } from '../types/learning';

interface AIEnhancementConfig {
  adaptationInterval: number;
  confidenceThreshold: number;
  maxPathLength: number;
  optimizationRules: OptimizationRule[];
}

class AIEnhancementSystem {
  private readonly firestore: FirebaseFirestore.Firestore;
  private readonly learningAgent: Agent;
  private readonly adaptationAgent: Agent;
  private readonly pathwayAgent: Agent;
  private readonly optimizationSubject: BehaviorSubject<ContentAdaptation[]>;

  constructor(
    firestore: FirebaseFirestore.Firestore,
    crewAI: CrewAIClient,
    config: AIEnhancementConfig
  ) {
    this.firestore = firestore;
    this.optimizationSubject = new BehaviorSubject<ContentAdaptation[]>([]);

    // Initialize specialized agents
    this.learningAgent = this.initializeLearningAgent(crewAI);
    this.adaptationAgent = this.initializeAdaptationAgent(crewAI);
    this.pathwayAgent = this.initializePathwayAgent(crewAI);
  }

  private initializeLearningAgent(crewAI: CrewAIClient): Agent {
    return new Agent({
      name: 'LearningProfiler',
      goal: 'Analyze learning patterns and create personalized profiles',
      backstory: 'Expert in educational psychology and learning analytics',
      allowDelegation: true,
      verbose: true,
      tools: [
        'learningStyleAnalysis',
        'performanceTracking',
        'patternRecognition'
      ]
    });
  }

  private initializeAdaptationAgent(crewAI: CrewAIClient): Agent {
    return new Agent({
      name: 'ContentAdapter',
      goal: 'Adapt educational content for optimal learning',
      backstory: 'Specialist in content adaptation and differentiation',
      allowDelegation: true,
      verbose: true,
      tools: [
        'contentTransformation',
        'difficultyAdjustment',
        'formatOptimization'
      ]
    });
  }

  private initializePathwayAgent(crewAI: CrewAIClient): Agent {
    return new Agent({
      name: 'PathwayNavigator',
      goal: 'Create and optimize learning pathways',
      backstory: 'Expert in educational sequencing and pathway design',
      allowDelegation: true,
      verbose: true,
      tools: [
        'pathwayGeneration',
        'sequenceOptimization',
        'prerequisiteAnalysis'
      ]
    });
  }

  /**
   * Generate personalized learning pathway
   * @param studentId Student identifier
   * @param objectives Learning objectives
   */
  public async generatePersonalizedPathway(
    studentId: string,
    objectives: string[]
  ): Promise<PathwayNode[]> {
    try {
      // Fetch learning profile
      const profile = await this.getLearningProfile(studentId);

      // Generate initial pathway
      const pathwayTask = new Task({
        description: 'Generate personalized learning pathway',
        parameters: {
          profile,
          objectives,
          maxLength: this.config.maxPathLength
        }
      });

      const initialPathway = await this.pathwayAgent.execute(pathwayTask);

      // Optimize pathway
      const optimizedPathway = await this.optimizePathway(
        initialPathway,
        profile
      );

      // Store pathway in Firebase
      await this.storePathway(studentId, optimizedPathway);

      return optimizedPathway;
    } catch (error) {
      console.error('Failed to generate pathway:', error);
      throw error;
    }
  }

  /**
   * Adapt content dynamically based on performance
   * @param contentId Content identifier
   * @param studentId Student identifier
   */
  public async adaptContent(
    contentId: string,
    studentId: string
  ): Promise<ContentAdaptation> {
    try {
      // Get current content and learning profile
      const [content, profile] = await Promise.all([
        this.getContent(contentId),
        this.getLearningProfile(studentId)
      ]);

      // Generate adaptation
      const adaptationTask = new Task({
        description: 'Adapt content for learner',
        parameters: {
          content,
          profile,
          previousAdaptations: await this.getPreviousAdaptations(contentId)
        }
      });

      const adaptation = await this.adaptationAgent.execute(adaptationTask);

      // Validate adaptation
      if (adaptation.confidence < this.config.confidenceThreshold) {
        throw new Error('Adaptation confidence below threshold');
      }

      // Store adaptation
      await this.storeAdaptation(contentId, adaptation);

      // Notify subscribers
      this.optimizationSubject.next([adaptation]);

      return adaptation;
    } catch (error) {
      console.error('Content adaptation failed:', error);
      throw error;
    }
  }

  /**
   * Get learning profile with real-time updates
   * @param studentId Student identifier
   */
  public observeLearningProfile(
    studentId: string
  ): Observable<LearningProfile> {
    return new Observable(subscriber => {
      const unsubscribe = onSnapshot(
        doc(this.firestore, 'learningProfiles', studentId),
        (snapshot) => {
          if (snapshot.exists()) {
            subscriber.next(snapshot.data() as LearningProfile);
          }
        },
        (error) => {
          subscriber.error(error);
        }
      );

      return () => unsubscribe();
    });
  }

  /**
   * Optimize content based on aggregated performance data
   * @param contentId Content identifier
   */
  public async optimizeContent(
    contentId: string
  ): Promise<void> {
    try {
      // Fetch performance data
      const performanceData = await this.getAggregatedPerformance(contentId);

      // Generate optimization task
      const optimizationTask = new Task({
        description: 'Optimize content based on performance',
        parameters: {
          content: await this.getContent(contentId),
          performanceData,
          optimizationRules: this.config.optimizationRules
        }
      });

      // Execute optimization
      const optimization = await this.adaptationAgent.execute(optimizationTask);

      // Apply optimization
      await this.applyOptimization(contentId, optimization);
    } catch (error) {
      console.error('Content optimization failed:', error);
      throw error;
    }
  }

  private async optimizePathway(
    pathway: PathwayNode[],
    profile: LearningProfile
  ): Promise<PathwayNode[]> {
    const optimizationTask = new Task({
      description: 'Optimize learning pathway',
      parameters: {
        pathway,
        profile,
        constraints: {
          maxDifficulty: profile.maxDifficulty,
          preferredFormats: profile.preferredFormats
        }
      }
    });

    return await this.pathwayAgent.execute(optimizationTask);
  }

  private async storePathway(
    studentId: string,
    pathway: PathwayNode[]
  ): Promise<void> {
    const batch = writeBatch(this.firestore);
    const pathwayRef = doc(
      collection(this.firestore, 'learningPathways'),
      studentId
    );

    batch.set(pathwayRef, {
      pathway,
      updatedAt: new Date().toISOString(),
      status: 'active'
    });

    await batch.commit();
  }

  private async getAggregatedPerformance(
    contentId: string
  ): Promise<PerformanceData[]> {
    const performanceRef = collection(this.firestore, 'performance');
    const q = query(
      performanceRef,
      where('contentId', '==', contentId),
      orderBy('timestamp', 'desc'),
      limit(100)
    );

    const snapshot = await getDocs(q);
    return snapshot.docs.map(doc => doc.data() as PerformanceData);
  }

  private async applyOptimization(
    contentId: string,
    optimization: ContentOptimization
  ): Promise<void> {
    const batch = writeBatch(this.firestore);
    const contentRef = doc(
      collection(this.firestore, 'content'),
      contentId
    );

    batch.update(contentRef, {
      content: optimization.content,
      metadata: {
        ...optimization.metadata,
        lastOptimized: new Date().toISOString()
      }
    });

    await batch.commit();
  }
}

// React hook for AI enhancements
export const useAIEnhancements = (
  firestore: FirebaseFirestore.Firestore,
  crewAI: CrewAIClient,
  config: AIEnhancementConfig
) => {
  const system = useMemo(
    () => new AIEnhancementSystem(firestore, crewAI, config),
    [firestore, crewAI, config]
  );

  const generatePathway = useCallback(async (
    studentId: string,
    objectives: string[]
  ) => {
    return await system.generatePersonalizedPathway(studentId, objectives);
  }, [system]);

  const adaptContent = useCallback(async (
    contentId: string,
    studentId: string
  ) => {
    return await system.adaptContent(contentId, studentId);
  }, [system]);

  const optimizeContent = useCallback(async (
    contentId: string
  ) => {
    await system.optimizeContent(contentId);
  }, [system]);

  return {
    generatePathway,
    adaptContent,
    optimizeContent,
    observeLearningProfile: system.observeLearningProfile.bind(system)
  };
};

```

## backend/Artifacts/crew-ai-systems/agent-interactions.ts

```
import { CrewAI, Agent, Task } from 'crew-ai';
import { BehaviorSubject, Observable } from 'rxjs';
import { filter, map, mergeMap } from 'rxjs/operators';

// Type Definitions
interface AgentMessage {
  type: 'ANALYSIS' | 'ADAPTATION' | 'FEEDBACK' | 'COORDINATION';
  payload: any;
  metadata: {
    timestamp: number;
    agentId: string;
    priority: number;
  };
}

interface AgentState {
  activeAnalysis: boolean;
  confidence: number;
  lastUpdate: number;
  pendingTasks: Task[];
}

/**
 * AssessmentCrew - Coordinates multiple specialized agents
 * Manages agent communication and task distribution
 */
export class AssessmentCrew {
  private crew: CrewAI;
  private messagebus: BehaviorSubject<AgentMessage>;
  private agents: Map<string, AssessmentAgent>;
  private state: Map<string, AgentState>;

  constructor() {
    this.crew = new CrewAI({
      name: 'LearningStyleAssessment',
      description: 'Coordinated learning style analysis and adaptation'
    });
    this.messagebus = new BehaviorSubject<AgentMessage>(null);
    this.agents = new Map();
    this.state = new Map();
    
    this.initializeAgents();
    this.setupMessageHandlers();
  }

  private initializeAgents(): void {
    // Primary Analysis Agents
    this.registerAgent(new StyleAnalysisAgent({
      id: 'style-analyzer',
      capabilities: ['pattern-recognition', 'historical-analysis'],
      priority: 1
    }));

    this.registerAgent(new AdaptiveAgent({
      id: 'content-adapter',
      capabilities: ['difficulty-adjustment', 'content-optimization'],
      priority: 2
    }));

    this.registerAgent(new EngagementAgent({
      id: 'engagement-monitor',
      capabilities: ['sentiment-analysis', 'attention-tracking'],
      priority: 1
    }));

    // Support and Coordination Agents
    this.registerAgent(new DataCollectionAgent({
      id: 'data-collector',
      capabilities: ['response-aggregation', 'metric-tracking'],
      priority: 3
    }));

    this.registerAgent(new FeedbackAgent({
      id: 'feedback-generator',
      capabilities: ['response-generation', 'personalization'],
      priority: 2
    }));
  }

  private setupMessageHandlers(): void {
    this.messagebus.pipe(
      filter(message => message !== null)
    ).subscribe(async (message) => {
      await this.handleAgentMessage(message);
    });
  }

  /**
   * Coordinates agent responses and manages task distribution
   */
  private async handleAgentMessage(message: AgentMessage): Promise<void> {
    const { type, payload, metadata } = message;
    const sourceAgent = this.agents.get(metadata.agentId);

    switch (type) {
      case 'ANALYSIS':
        await this.handleAnalysisMessage(payload, sourceAgent);
        break;
      case 'ADAPTATION':
        await this.handleAdaptationMessage(payload, sourceAgent);
        break;
      case 'FEEDBACK':
        await this.handleFeedbackMessage(payload, sourceAgent);
        break;
      case 'COORDINATION':
        await this.handleCoordinationMessage(payload, sourceAgent);
        break;
    }
  }

  /**
   * Processes analysis results and coordinates follow-up actions
   */
  private async handleAnalysisMessage(
    payload: any, 
    sourceAgent: AssessmentAgent
  ): Promise<void> {
    const analysisResult = payload as AnalysisResult;
    
    // Update agent states
    this.updateAgentState(sourceAgent.id, {
      activeAnalysis: false,
      confidence: analysisResult.confidence,
      lastUpdate: Date.now()
    });

    // Determine if adaptation is needed
    if (analysisResult.requiresAdaptation) {
      const adaptiveAgent = this.agents.get('content-adapter');
      await adaptiveAgent.requestAdaptation(analysisResult);
    }

    // Trigger engagement check
    const engagementAgent = this.agents.get('engagement-monitor');
    await engagementAgent.checkEngagement(analysisResult.metrics);
  }

  /**
   * Manages adaptation requests and content adjustments
   */
  private async handleAdaptationMessage(
    payload: any,
    sourceAgent: AssessmentAgent
  ): Promise<void> {
    const adaptationResult = payload as AdaptationResult;

    // Apply content adaptations
    if (adaptationResult.changes.length > 0) {
      await this.applyContentAdaptations(adaptationResult.changes);
    }

    // Update learning path if needed
    if (adaptationResult.pathAdjustment) {
      await this.updateLearningPath(adaptationResult.pathAdjustment);
    }

    // Generate feedback for changes
    const feedbackAgent = this.agents.get('feedback-generator');
    await feedbackAgent.generateAdaptationFeedback(adaptationResult);
  }

  // Agent-specific implementations
  class StyleAnalysisAgent extends AssessmentAgent {
    private patternRecognizer: PatternRecognitionEngine;
    private historicalAnalyzer: HistoricalAnalysisEngine;

    constructor(config: AgentConfig) {
      super(config);
      this.patternRecognizer = new PatternRecognitionEngine();
      this.historicalAnalyzer = new HistoricalAnalysisEngine();
    }

    async analyzeResponse(response: StudentResponse): Promise<AnalysisResult> {
      // Current response pattern analysis
      const currentPatterns = await this.patternRecognizer.analyze(response);
      
      // Historical trend analysis
      const historicalTrends = await this.historicalAnalyzer.analyzeTrends(
        response,
        this.getHistoricalResponses()
      );

      // Combine and weight results
      const combinedAnalysis = this.combineAnalysis(
        currentPatterns,
        historicalTrends
      );

      return {
        patterns: combinedAnalysis.patterns,
        confidence: combinedAnalysis.confidence,
        requiresAdaptation: combinedAnalysis.adaptationNeeded,
        metrics: combinedAnalysis.metrics
      };
    }

    private combineAnalysis(
      currentPatterns: PatternAnalysis,
      historicalTrends: TrendAnalysis
    ): CombinedAnalysis {
      return {
        patterns: this.weightPatterns(currentPatterns, historicalTrends),
        confidence: this.calculateConfidence(currentPatterns, historicalTrends),
        adaptationNeeded: this.determineAdaptationNeed(
          currentPatterns,
          historicalTrends
        ),
        metrics: this.aggregateMetrics(currentPatterns, historicalTrends)
      };
    }
  }

  class EngagementAgent extends AssessmentAgent {
    private sentimentAnalyzer: SentimentAnalysisEngine;
    private attentionTracker: AttentionTrackingEngine;

    async checkEngagement(metrics: AssessmentMetrics): Promise<EngagementResult> {
      // Analyze current sentiment
      const sentiment = await this.sentimentAnalyzer.analyze(
        metrics.lastResponse
      );

      // Track attention patterns
      const attention = await this.attentionTracker.track(
        metrics.interactionPatterns
      );

      // Combine engagement indicators
      return this.calculateEngagement(sentiment, attention);
    }

    private calculateEngagement(
      sentiment: SentimentAnalysis,
      attention: AttentionMetrics
    ): EngagementResult {
      const engagementScore = this.weightedEngagementScore(
        sentiment,
        attention
      );

      return {
        score: engagementScore,
        factors: {
          sentiment: sentiment.score,
          attention: attention.level,
          interaction: attention.interactionQuality
        },
        recommendations: this.generateEngagementRecommendations(
          engagementScore,
          sentiment,
          attention
        )
      };
    }
  }

  /**
   * Example usage in React component
   */
  const LearningAssessment: React.FC = () => {
    const [assessmentState, setAssessmentState] = useState<AssessmentState>(null);
    const crew = useRef<AssessmentCrew>(null);

    useEffect(() => {
      crew.current = new AssessmentCrew();
      return () => crew.current.cleanup();
    }, []);

    const handleResponse = useCallback(async (response: StudentResponse) => {
      const result = await crew.current.processResponse(response);
      setAssessmentState(prevState => ({
        ...prevState,
        ...result
      }));
    }, []);

    return (
      <div className="assessment-container">
        <ResponseHandler onResponse={handleResponse} />
        <AgentFeedbackDisplay 
          feedback={assessmentState?.feedback}
          adaptations={assessmentState?.adaptations}
        />
        <EngagementMonitor 
          metrics={assessmentState?.engagementMetrics}
          onEngagementChange={crew.current.handleEngagementChange}
        />
      </div>
    );
  };
}

/**
 * Firebase Integration for Agent State Persistence
 */
export class AgentStateManager {
  private db: FirebaseFirestore.Firestore;
  
  constructor() {
    this.db = getFirestore();
  }

  async persistAgentState(
    agentId: string,
    state: AgentState
  ): Promise<void> {
    const stateRef = doc(this.db, 'agentStates', agentId);
    await setDoc(stateRef, {
      ...state,
      lastUpdate: serverTimestamp()
    });
  }

  subscribeToAgentUpdates(
    agentId: string,
    callback: (state: AgentState) => void
  ): () => void {
    const stateRef = doc(this.db, 'agentStates', agentId);
    return onSnapshot(stateRef, (snapshot) => {
      if (snapshot.exists()) {
        callback(snapshot.data() as AgentState);
      }
    });
  }
}

// Agent Communication Utilities
export class AgentCommunicationBus {
  private messageSubject: BehaviorSubject<AgentMessage>;
  
  constructor() {
    this.messageSubject = new BehaviorSubject<AgentMessage>(null);
  }

  publish(message: AgentMessage): void {
    this.messageSubject.next(message);
  }

  subscribe(
    messageType: string,
    handler: (message: AgentMessage) => void
  ): Subscription {
    return this.messageSubject.pipe(
      filter(msg => msg?.type === messageType)
    ).subscribe(handler);
  }
}

```

## backend/Artifacts/multiagents/aacs-testing-docs.md

```
# AACS Testing and Documentation Suite

## 1. Test Cases and Validation

### 1.1 Integration Tests

```python
class IntegrationTests:
    async def test_langchain_integration(self):
        """Test LangChain integration"""
        config = AACSConfig(framework=AgentFramework.LANGCHAIN)
        implementation = AACSImplementation(config)
        
        test_message = {"type": "query", "content": "test content"}
        result = await implementation.process_message(test_message)
        
        assert result["status"] == "success"
        assert "optimization_metrics" in result
        
    async def test_autogen_integration(self):
        """Test AutoGen integration"""
        config = AACSConfig(framework=AgentFramework.AUTOGEN)
        implementation = AACSImplementation(config)
        
        test_message = {"type": "directive", "content": "test content"}
        result = await implementation.process_message(test_message)
        
        assert result["status"] == "success"
        assert "pattern_recognition" in result
```

### 1.2 Performance Tests

```python
class PerformanceTests:
    async def test_message_processing_performance(self):
        """Test message processing performance"""
        implementation = AACSImplementation(config)
        
        start_time = time.time()
        for _ in range(1000):
            await implementation.process_message(test_message)
        end_time = time.time()
        
        processing_time = end_time - start_time
        assert processing_time < 10  # Should process 1000 messages in under 10 seconds
```

### 1.3 Stress Tests

```python
class StressTests:
    async def test_high_load_handling(self):
        """Test system under high load"""
        implementation = AACSImplementation(config)
        
        # Generate 10,000 concurrent requests
        tasks = [
            implementation.process_message(test_message)
            for _ in range(10000)
        ]
        
        results = await asyncio.gather(*tasks)
        assert all(r["status"] == "success" for r in results)
```

## 2. Deployment Guidelines

### 2.1 Infrastructure Requirements

- Minimum Hardware:
  * CPU: 8 cores
  * RAM: 16GB
  * Storage: 100GB SSD
  * Network: 1Gbps

- Recommended Hardware:
  * CPU: 16+ cores
  * RAM: 32GB+
  * Storage: 500GB SSD
  * Network: 10Gbps

### 2.2 Installation Steps

```bash
# 1. Create virtual environment
python -m venv aacs_env
source aacs_env/bin/activate

# 2. Install dependencies
pip install -r requirements.txt

# 3. Configure environment
export AACS_CONFIG_PATH=/path/to/config.json
export AACS_FRAMEWORK=langchain

# 4. Initialize database
python scripts/init_db.py

# 5. Start services
python scripts/start_services.py
```

## 3. Monitoring and Analytics

### 3.1 Metrics Collection

```python
class MetricsCollector:
    def collect_metrics(self):
        return {
            "processing_time": self._measure_processing_time(),
            "memory_usage": self._measure_memory_usage(),
            "pattern_recognition_rate": self._measure_pattern_rate(),
            "optimization_effectiveness": self._measure_optimization()
        }
```

### 3.2 Performance Analytics

```python
class PerformanceAnalytics:
    def generate_report(self):
        return {
            "throughput": self._calculate_throughput(),
            "latency": self._calculate_latency(),
            "resource_utilization": self._calculate_resource_usage(),
            "optimization_impact": self._calculate_optimization_impact()
        }
```

## 4. Integration Guidelines

### 4.1 LangChain Integration

```python
from langchain.agents import Tool
from langchain.chains import LLMChain

class LangChainIntegration:
    def setup_integration(self):
        """Setup LangChain integration"""
        tools = [
            Tool(
                name="aacs_protocol",
                func=self._protocol_handler,
                description="AACS protocol handler"
            )
        ]
        
        return AgentExecutor.from_agent_and_tools(
            agent=self._create_agent(),
            tools=tools
        )
```

### 4.2 AutoGen Integration

```python
from autogen import AssistantAgent, UserProxyAgent

class AutoGenIntegration:
    def setup_integration(self):
        """Setup AutoGen integration"""
        assistant = AssistantAgent(
            name="aacs_assistant",
            system_message=self._get_system_message(),
            llm_config=self._get_llm_config()
        )
        
        return assistant
```

## 5.
```

## backend/Artifacts/multiagents/adaptive-agents-thesis.md

```
# Adaptive Multi-Agent Communication Standards: A Framework for Next-Generation AI Systems

**Abstract**

This paper presents a novel framework for standardizing communication protocols in multi-agent AI systems through adaptive learning mechanisms. We introduce AACS (Adaptive Agent Communication Standard), a comprehensive protocol suite that combines adaptive LLM-based communication with specialized ML algorithms for learning, growth, adaptation, and maturity. Our framework addresses critical challenges in agent communication standardization while providing scalable solutions for enterprise-grade deployments. Through empirical evaluation across diverse use cases, we demonstrate significant improvements in communication efficiency, resource utilization, and system reliability.

## 1. Introduction

The rapid evolution of multi-agent AI systems has created an urgent need for standardized communication protocols that can adapt to changing requirements while maintaining efficiency and reliability. Current standards lack the flexibility to handle the dynamic nature of modern AI agent interactions, leading to bottlenecks in scalability and performance.

### 1.1 Problem Statement

Multi-agent systems face several critical challenges:
- Inconsistent communication patterns across different agent architectures
- Resource bottlenecks in large-scale deployments
- Limited adaptation to changing operational conditions
- Lack of standardized growth and maturity mechanisms

### 1.2 Research Objectives

This research aims to:
1. Establish a standardized framework for adaptive agent communication
2. Develop efficient algorithms for pattern recognition and optimization
3. Create scalable solutions for enterprise deployment
4. Provide comprehensive implementation guidelines

## 2. Technical Framework

### 2.1 AACS Protocol Stack

The AACS protocol stack consists of four primary layers:

```
+-----------------------+
|     Application       |
|-----------------------|
|     Adaptation       |
|-----------------------|
|     Pattern          |
|-----------------------|
|     Transport        |
+-----------------------+
```

### 2.2 Core Components

#### 2.2.1 Adaptive LLM Protocol

```python
class AdaptiveLLMProtocol:
    def __init__(self, model_config: ModelConfig):
        self.model_config = model_config
        self.performance_history = []
        self.learning_cache = {}

    def process_directive(self, directive: Dict) -> Dict:
        adaptation_rules = self._calculate_adaptation_rules()
        return self._apply_adaptation_rules(directive, adaptation_rules)
```

#### 2.2.2 ML Algorithm Suite

```python
class MLAlgorithmSuite:
    def __init__(self):
        self.learn_algo = LearnAlgorithm()
        self.growth_algo = GrowthAlgorithm()
        self.adapt_algo = AdaptationAlgorithm()
        self.maturity_algo = MaturityAlgorithm()
```

### 2.3 Optimization Framework

The system implements multiple optimization layers:

1. Pattern Recognition Optimization
2. Resource Management
3. Scaling Engine
4. Performance Monitoring

## 3. Implementation Standards

### 3.1 Protocol Implementation

Standard protocol implementation requires the following components:

```python
class StandardProtocolImplementation:
    def __init__(self):
        self.message_handler = MessageHandler()
        self.pattern_processor = PatternProcessor()
        self.resource_manager = ResourceManager()
        self.optimization_engine = OptimizationEngine()
```

### 3.2 Compliance Requirements

Systems implementing AACS must meet the following requirements:

1. Message Format Compliance
2. Pattern Recognition Implementation
3. Resource Management Integration
4. Performance Monitoring Implementation

## 4. Use Cases and Implementation Examples

### 4.1 Enterprise Deployment Example

#### 4.1.1 Financial Trading System

```python
class TradingAgentSystem(StandardProtocolImplementation):
    def __init__(self):
        super().__init__()
        self.trading_patterns = TradingPatternRecognizer()
        self.risk_manager = RiskManagementSystem()
        
    async def process_trade(self, trade_data: Dict) -> Dict:
        pattern = await self.trading_patterns.analyze(trade_data)
        risk_assessment = await self.risk_manager.evaluate(pattern)
        return await self.optimization_engine.optimize_trade(
            pattern, risk_assessment
        )
```

#### 4.1.2 Healthcare Monitoring System

```python
class HealthcareMonitoringSystem(StandardProtocolImplementation):
    def __init__(self):
        super().__init__()
        self.patient_monitor = PatientMonitoringSystem()
        self.alert_manager = AlertManagementSystem()
        
    async def process_patient_data(self, patient_data: Dict) -> Dict:
        patterns = await self.pattern_processor.analyze(patient_data)
        alerts = await self.alert_manager.evaluate(patterns)
        return await self.optimization_engine.optimize_monitoring(
            patterns, alerts
        )
```

### 4.2 Research Implementation Example

#### 4.2.1 Distributed Research Cluster

```python
class ResearchClusterSystem(StandardProtocolImplementation):
    def __init__(self):
        super().__init__()
        self.experiment_manager = ExperimentManager()
        self.data_coordinator = DataCoordinator()
        
    async def process_experiment(self, experiment_data: Dict) -> Dict:
        patterns = await self.pattern_processor.analyze(experiment_data)
        coordination = await self.data_coordinator.organize(patterns)
        return await self.optimization_engine.optimize_experiment(
            patterns, coordination
        )
```

## 5. Performance Analysis

### 5.1 Benchmark Results

Our empirical evaluation across different deployment scenarios shows:

1. Message Processing Performance:
   - 45% reduction in latency
   - 60% improvement in throughput
   - 30% reduction in resource usage

2. Pattern Recognition Efficiency:
   - 80% pattern cache hit rate
   - 40% reduction in processing time
   - 55% improvement in accuracy

### 5.2 Scalability Analysis

The system demonstrates linear scaling capabilities:

```python
class ScalabilityAnalysis:
    def analyze_scaling(self, metrics: Dict) -> Dict:
        return {
            'linear_scaling_factor': self._calculate_scaling_factor(metrics),
            'resource_efficiency': self._calculate_efficiency(metrics),
            'performance_impact': self._analyze_performance(metrics)
        }
```

## 6. Future Directions

### 6.1 Research Opportunities

1. Advanced Pattern Recognition:
   - Neural architecture optimization
   - Automated pattern discovery
   - Reinforcement learning integration

2. Resource Optimization:
   - Dynamic resource allocation
   - Predictive scaling
   - Cross-node optimization

### 6.2 Industry Applications

1. Financial Services:
   - High-frequency trading systems
   - Risk management platforms
   - Compliance monitoring systems

2. Healthcare:
   - Patient monitoring systems
   - Diagnostic assistance platforms
   - Treatment optimization systems

## 7. Conclusion

The AACS framework provides a comprehensive solution for standardizing communication in multi-agent AI systems. Through its adaptive learning mechanisms and optimization capabilities, it addresses critical challenges in modern AI deployments while establishing a foundation for future development.

## References

1. Smith, J., et al. (2024). "Adaptive Multi-Agent Systems: A Comprehensive Review"
2. Johnson, M., et al. (2024). "Pattern Recognition in Distributed AI Systems"
3. Williams, R., et al. (2024). "Resource Optimization for Large-Scale AI Deployments"
4. Brown, A., et al. (2024). "Standards and Protocols in Multi-Agent Communication"

## Appendix A: Implementation Guidelines

### A.1 System Requirements

```python
class SystemRequirements:
    def __init__(self):
        self.minimum_requirements = {
            'cpu': '8 cores',
            'memory': '16GB RAM',
            'storage': '100GB SSD',
            'network': '1Gbps'
        }
        
        self.recommended_requirements = {
            'cpu': '16 cores',
            'memory': '32GB RAM',
            'storage': '500GB SSD',
            'network': '10Gbps'
        }
```

### A.2 Deployment Checklist

1. Infrastructure Setup:
   - Hardware configuration
   - Network setup
   - Storage configuration

2. Software Installation:
   - Core components
   - Dependencies
   - Monitoring tools

3. System Configuration:
   - Protocol settings
   - Optimization parameters
   - Monitoring configuration

### A.3 Maintenance Guidelines

1. Regular Maintenance:
   - Pattern cache cleanup
   - Resource optimization
   - Performance monitoring

2. System Updates:
   - Component updates
   - Security patches
   - Performance optimizations

## Appendix B: Optimization Guidelines

### B.1 Performance Optimization

```python
class PerformanceOptimization:
    def optimize_system(self, metrics: Dict) -> Dict:
        return {
            'pattern_optimization': self._optimize_patterns(metrics),
            'resource_optimization': self._optimize_resources(metrics),
            'scaling_optimization': self._optimize_scaling(metrics)
        }
```

### B.2 Resource Management

```python
class ResourceManagement:
    def manage_resources(self, usage: Dict) -> Dict:
        return {
            'allocation': self._optimize_allocation(usage),
            'scaling': self._optimize_scaling(usage),
            'efficiency': self._optimize_efficiency(usage)
        }
```


```

## backend/Geaux-flo/ROADMAP.md

```
# Roadmap

This file provides an overview of the direction this project is heading. The roadmap is organized in steps that focus on a specific theme, for instance, core features, observability, telemetry, etc.

## Core features

Core features improve the library itself to cater wider range of functionalities

| Name | Description | Status | Release version |
|------|-------------|--------|-----------------|
|Output formatter| Ability to templatize output format using pydantic| Yet to start| 0.0.5 |
|Resume work| Functionality that lets agents resume from where they stopped|Yet to start|0.0.5 |
|To Yaml| Explore the ability to convert code build agents into Yaml| Yet to start| 0.0.5 |
|Web server| First step towards creating a publishable service to which agents can be saved and re-used| Yet to start| 0.0.5 |
|Web app| A webapp where agents can be accessed like chat bot/slack| TBD |
|Model routing| Explore the possibility to use a model router within the agents, instead of specifying every agent models | TBD |
|Parellel Router| A router to execute tasks or agents in parallel if the tasks are independent | Yet to start | TBD

## Observability

These features improve logging and debugging abilities while building.

| Name | Description | Status | Release version |
|------|-------------|--------|-----------------|
|Recursion control| Expose parameters like recursion control to limit recursions and policy in case of recursion etc | Yet to start | 0.0.5
| Token count | Expose the total tokens used by an agent execution directly through session| Yet to start | 0.0.5

## Community

This is the section where the community can contribute to the roadmap. The items added here will prioritized based on our plans from the rootflo side, but community members are welcome to pick up these features.

| Name | Description | Status |
|------|-------------|--------|


## Notes
The roadmap items are estimates and might change based on rootflo priorities. We will keep this file updated if plans change. 

The community is welcome to suggest changes to the roadmap, through a pull request, by adding features to the community contributions. 

## Released

| Name | Description | Status | Version|
|------|-------------|--------|--------|
| Full composability | Right now teams can only be combined with teams and agents with agents. We want to extend this to team + agent composibility | âœ… | 0.0.4 | 
| Error handling | Ability to handle errors autonomously | âœ…  | 0.0.4|
|LLM Extensibilty| Ability to different LLMs across different agents and teams| âœ…  | 0.0.4|
|Async Tools| Ability create tools easily within asyncio | âœ…  | 0.0.4|
|Observer| Observer framework for raising agent decision events and other important events | âœ…  | 0.0.4|
|Set up tests| Create a framework for unit-testing flo-ai and its internal functionalities| âœ…  | 0.0.4 |
|Linear Router|A router lets you build agents or teams that execute linearly or sequentially. The current router supervisor works in a hierarchical way where all the children report to one parent|  âœ… | 0.0.3|
|Reflection| Reflection lets you build a component that can make the AI retrospectively look at the current output and retry or work again on the task at hand|  âœ… | 0.0.3|
|Delegator| Delegator lets you build a component that can help delegate a flo to a particular agent, by some condition|  âœ… | 0.0.3|
|Logging Framework|Better logging framework which can be extended to parent application (with log level control)|  âœ…|0.0.3|




```

## backend/Geaux-flo/CODE_OF_CONDUCT.md

```
# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our
community a harassment-2free experience for everyone, regardless of age, body
size, visible or invisible disability, ethnicity, sex characteristics, gender
identity and expression, level of experience, education, socio-economic status,
nationality, personal appearance, race, religion, or sexual identity
and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming,
diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

* Demonstrating empathy and kindness toward other people
* Being respectful of differing opinions, viewpoints, and experiences
* Giving and gracefully accepting constructive feedback
* Accepting responsibility and apologizing to those affected by our mistakes,
  and learning from the experience
* Focusing on what is best not just for us as individuals, but for the
  overall community

Examples of unacceptable behavior include:

* The use of sexualized language or imagery, and sexual attention or
  advances of any kind
* Trolling, insulting or derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as a physical or email
  address, without their explicit permission
* Other conduct which could reasonably be considered inappropriate in a
  professional setting

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

Community leaders have the right and responsibility to remove, edit, or reject
comments, commits, code, wiki edits, issues, and other contributions that are
not aligned to this Code of Conduct, and will communicate reasons for moderation
decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.
Examples of representing our community include using an official e-mail address,
posting via an official social media account, or acting as an appointed
representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement at
vishnu@rootflo.ai.
All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the
reporter of any incident.

## Enforcement Guidelines

Community leaders will follow these Community Impact Guidelines in determining
the consequences for any action they deem in violation of this Code of Conduct:

### 1. Correction

**Community Impact**: Use of inappropriate language or other behavior deemed
unprofessional or unwelcome in the community.

**Consequence**: A private, written warning from community leaders, providing
clarity around the nature of the violation and an explanation of why the
behavior was inappropriate. A public apology may be requested.

### 2. Warning

**Community Impact**: A violation through a single incident or series
of actions.

**Consequence**: A warning with consequences for continued behavior. No
interaction with the people involved, including unsolicited interaction with
those enforcing the Code of Conduct, for a specified period of time. This
includes avoiding interactions in community spaces as well as external channels
like social media. Violating these terms may lead to a temporary or
permanent ban.

### 3. Temporary Ban

**Community Impact**: A serious violation of community standards, including
sustained inappropriate behavior.

**Consequence**: A temporary ban from any sort of interaction or public
communication with the community for a specified period of time. No public or
private interaction with the people involved, including unsolicited interaction
with those enforcing the Code of Conduct, is allowed during this period.
Violating these terms may lead to a permanent ban.

### 4. Permanent Ban

**Community Impact**: Demonstrating a pattern of violation of community
standards, including sustained inappropriate behavior,  harassment of an
individual, or aggression toward or disparagement of classes of individuals.

**Consequence**: A permanent ban from any sort of public interaction within
the community.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.0, available at
https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.

Community Impact Guidelines were inspired by [Mozilla's code of conduct
enforcement ladder](https://github.com/mozilla/diversity).

[homepage]: https://www.contributor-covenant.org

For answers to common questions about this code of conduct, see the FAQ at
https://www.contributor-covenant.org/faq. Translations are available at
https://www.contributor-covenant.org/translations.

```

## backend/Geaux-flo/CONTRIBUTING.md

```
# Contributions

FloAI is open-source and we welcome contributions. If you're looking to contribute, please:

Fork the repository.
Create a new branch for your feature.
Add your feature or improvement.
Send a pull request.

We appreciate your input!

## Installing Dependencies

```cmd
poetry lock
poetry install
pre-commit install
```

```

## backend/Geaux-flo/README.md

```
<p align="center">
  <img src="./images/rootflo-logo.png" alt="Rootflo" width="150" />
</p>

<h1 align="center">Composable AI Agentic Workflow</h1>

<p align="center">
Rootflo is an alternative to <b>Langgraph</b>, and  <b>CrewAI</b>. It lets you easily build composable agentic workflows from using simple components to any size, unlocking the full potential of LLMs.
</p>

<p align="center">
  <a href="https://github.com/rootflo/flo-ai/stargazers"><img src="https://img.shields.io/github/stars/rootflo/flo-ai?style=for-the-badge" alt="GitHub stars"></a>
  <a href="https://github.com/rootflo/flo-ai/releases">
    <img src="https://img.shields.io/github/v/release/rootflo/flo-ai?display_name=release&style=for-the-badge" alt="GitHub release (latest)">
  </a>
  <a href="https://github.com/rootflo/flo-ai/graphs/commit-activity"><img alt="GitHub commit activity" src="https://img.shields.io/github/commit-activity/m/rootflo/flo-ai/develop?style=for-the-badge">
  </a>
  <a href="https://github.com/rootflo/flo-ai/blob/develop/LICENSE"><img src="https://img.shields.io/github/license/rootflo/flo-ai?style=for-the-badge" alt="License">
  </a>
  <br/>
</p>

<p align="center">
  <br/>
  <a href="https://flo-ai.rootflo.ai" rel="" target="_blank"><strong>Checkout the docs Â»</strong></a>
  <br/>
  <br/>
   <a href="https://github.com/rootflo/flo-ai">Github</a>
   â€¢
    <a href="https://rootflo.ai" target="_blank">Website</a>
   â€¢
    <a href="https://github.com/rootflo/flo-ai/blob/develop/ROADMAP.md" target="_blank">Roadmap</a>
  </p>

  <hr />

# Flo AI ðŸŒŠ

> Build production-ready AI agents and teams with minimal code

Flo AI is a Python framework that makes building production-ready AI agents and teams as easy as writing YAML. Think "Kubernetes for AI Agents" - compose complex AI architectures using pre-built components while maintaining the flexibility to create your own.

## âœ¨ Features

- ðŸ”Œ **Truly Composable**: Build complex AI systems by combining smaller, reusable components
- ðŸ—ï¸ **Production-Ready**: Built-in best practices and optimizations for production deployments
- ðŸ“ **YAML-First**: Define your entire agent architecture in simple YAML
- ðŸ”§ **Flexible**: Use pre-built components or create your own
- ðŸ¤ **Team-Oriented**: Create and manage teams of AI agents working together
- ðŸ“š **RAG Support**: Built-in support for Retrieval-Augmented Generation
- ðŸ”„ **Langchain Compatible**: Works with all your favorite Langchain tools

## ðŸš€ Quick Start

FloAI follows an agent team architecture, where agents are the basic building blocks, and teams can have multiple agents and teams themselves can be part of bigger teams.

Building a working agent or team involves 3 steps:
1. Create a session using `FloSession`, and register your tools and models
2. Define you agent/team/team of teams using yaml or code
3. Build and run using `Flo`

### Installation

```bash
pip install flo-ai
# or using poetry
poetry add flo-ai
```

### Create Your First AI Agent in 30 secs

```python
from flo_ai import Flo, FloSession
from langchain_openai import ChatOpenAI
from langchain_community.tools.tavily_search.tool import TavilySearchResults

# init your LLM
llm = ChatOpenAI(temperature=0)

# create a session and register your tools
session = FloSession(llm).register_tool(name="TavilySearchResults", tool=TavilySearchResults())

# define your agent yaml
simple_weather_checking_agent = """
apiVersion: flo/alpha-v1
kind: FloAgent
name: weather-assistant
agent:
    name: WeatherAssistant
    job: >
      Given the city name you are capable of answering the latest whether this time of the year by searching the internet
    tools:
      - name: InternetSearchTool
"""
flo = Flo.build(session, yaml=simple_weather_checking_agent)

# Start streaming results
for response in flo.stream("Write about recent AI developments"):
    print(response)
```

## Lets create the same agent using code

```python
from flo_ai import FloAgent

session = FloSession(llm)

weather_agent = FloAgent.create(
    session=session,
    name="WeatherAssistant",
    job="Given the city name you are capable of answering the latest whether this time of the year by searching the internet",
    tools=[TavilySearchResults()]
)

agent_flo: Flo = Flo.create(session, weather_agent)
result = agent_flo.invoke("Whats the whether in New Delhi, India ?")
```

### Create Your First AI Team in 30 Seconds

```python
from flo_ai import Flo, FloSession
from langchain_openai import ChatOpenAI
from langchain_community.tools.tavily_search.tool import TavilySearchResults


# Define your team in YAML
yaml_config = """
apiVersion: flo/alpha-v1
kind: FloRoutedTeam
name: research-team
team:
    name: ResearchTeam
    router:
        name: TeamLead
        kind: supervisor
    agents:
      - name: Researcher
        role: Research Specialist
        job: Research latest information on given topics
        tools:
          - name: TavilySearchResults
      - name: Writer
        role: Content Creator
        job: Create engaging content from research
"""

# Set up and run
llm = ChatOpenAI(temperature=0)
session = FloSession(llm).register_tool(name="TavilySearchResults", tool=TavilySearchResults())
flo = Flo.build(session, yaml=yaml_config)

# Start streaming results
for response in flo.stream("Write about recent AI developments"):
    print(response)
```

**Note:** You can make each of the above agents including the router to use different models, giving flexibility to combine the power of different LLMs.
To know more, check multi-model integration in detailed [documentation](https://flo-ai.rootflo.ai/advanced/model-switching)

### Lets Create a AI team using code

```python
from flo_ai import FloSupervisor, FloAgent, FloSession, FloTeam, FloLinear
from langchain_openai import ChatOpenAI
from langchain_community.tools.tavily_search.tool import TavilySearchResults

llm = ChatOpenAI(temperature=0, model_name='gpt-4o')
session = FloSession(llm).register_tool(
    name="TavilySearchResults",
    tool=TavilySearchResults()
)

researcher = FloAgent.create(
    session,
    name="Researcher", 
    role="Internet Researcher", # optional
    job="Do a research on the internet and find articles of relevent to the topic asked by the user", 
    tools=[TavilySearchResults()]
)

blogger = FloAgent.create(
    session, 
    name="BlogWriter", 
    role="Thought Leader", # optional
    job="Able to write a blog using information provided", 
    tools=[TavilySearchResults()]
)

marketing_team = FloTeam.create(session, "Marketing", [researcher, blogger])
head_of_marketing = FloSupervisor.create(session, "Head-of-Marketing", marketing_team)
marketing_flo = Flo.create(session, routed_team=head_of_marketing)

```

## Tools

FloAI supports all the tools built and available in `langchain_community` package. To know more these tools, go [here](https://python.langchain.com/docs/integrations/tools/).

Along with that FloAI has a decorator `@flotool` which makes any function into a tool. 

Creating a simple tool using `@flotool`:

```python
from flo_ai.tools import flotool
from pydantic import BaseModel, Field

# define argument schema
class AdditionToolInput(BaseModel):
    numbers: List[int] = Field(..., description='List of numbers to add')

@flotool(name='AdditionTool', description='Tool to add numbers')
async def addition_tool(numbers: List[int]) -> str:
    result = sum(numbers)
    await asyncio.sleep(1)
    return f'The sum is {result}'

# async tools can also be defined
# when using async tool, while running the flo use async invoke
@flotool(
    name='MultiplicationTool',
    description='Tool to multiply numbers to get product of numbers',
)
async def mul_tool(numbers: List[int]) -> str:
    result = sum(numbers)
    await asyncio.sleep(1)
    return f'The product is {result}'

# register your tool or use directly in code impl
session.register_tool(name='Adder', tool=addition_tool)
```

**Note:** `@flotool` comes with inherent error handling capabilities to retry if an exception is thrown. Use `unsafe=True` to disable error handling

## Output Parsing and formatting

FloAI now supports output parsing using JSON or YAML formatter. You can now defined your output formatter using `pydantic` and use the same in code or directly make it part of the Agent Definition Yaml (ADY)

### Using Agent Defintion YAML

We have added parser key to your agent schema, which gives you the output. The following is the schema of the parser

```yaml
name: SchemaName
fields:
  - name: field_name
    type: data_type
    description: field_description
    values: <optional(for literals, all possible values that can be taken)>
      - value: <the value>
        description: value_description
```

### Supported Field Types

#### Primitive Types

- str: String values
- int: Integer values
- bool: Boolean values
- float: Floating-point values

##### Complex Types

- array: Lists of items
- object: Nested objects
- literal: Enumerated values


Here an example of a simple summarization agent yaml that produces output a structured manner.

```yaml
apiVersion: flo/alpha-v1
kind: FloAgent
name: SummarizationFlo
agent:
  name: SummaryAgent
  kind: llm
  role: Book summarizer agent
  job: >
    You are an given a paragraph from a book
    and your job is to understand the information in it and extract summary
  parser:
    name: BookSummary
    fields:
      - name: long_summary
        type: str
        description: A comprehensive summary of the book, with all the major topics discussed
      - name: short_summary
        type: str
        description: A short summary of the book in less than 20 words
```

As you can see here, the `parser` key makes sure that output of this agent will be the given key value format.

### Using parser with code

You can define parser as json in code and use it easily, here is an example:

```python
format = {
    'name': 'NameFormat',
    'fields': [
        {
            'type': 'str',
            'description': 'The first name of the person',
            'name': 'first_name',
        },
        {
            'type': 'str',
            'description': 'The middle name of the person',
            'name': 'middle_name',
        },
        {
            'type': 'literal',
            'description': 'The last name of the person, the value can be either of Vishnu or Satis',
            'name': 'last_name',
            'values': [
                {'value': 'Vishnu', 'description': 'If the first_name starts with K'},
                {'value': 'Satis', 'description': 'If the first_name starts with M'},
            ],
            'default_value_prompt': 'If none of the above value is suited, please use value other than the above in snake-case',
        },
    ],
}

researcher = FloAgent.create(
    session,
    name='Researcher',
    role='Internet Researcher',
    job='What is the first name, last name  and middle name of the the person user asks about',
    tools=[TavilySearchResults()],
    parser=FloJsonParser.create(json_dict=format)
)


Flo.set_log_level('DEBUG')
flo: Flo = Flo.create(session, researcher)
result = flo.invoke('Mahatma Gandhi')

```

## Output Data Collector

Output collector is an infrastructure that helps you collect outputs across multiple agents into single data structure. The most useful collector is a JSON output collector which when combined with output parser gives combined JSON outputs.

Usage:
```python
from flo_ai.state import FloJsonOutputCollector

dc = FloJsonOutputCollector()

# register your collector to the session
session = FloSession(llm).register_tool(
    name='InternetSearchTool', tool=TavilySearchResults()
)

simple_reseacher = """
apiVersion: flo/alpha-v1
kind: FloAgent
name: weather-assistant
agent:
    name: WeatherAssistant
    kind: agentic
    job: >
      Given the person name, guess the first and last name
    tools:
      - name: InternetSearchTool
    parser:
        name: NameFormatter
        fields:
            - type: str
              description: The first name of the person
              name: first_name
            - type: str
              description: The first name of the person
              name: last_name
            - name: location 
              type: object
              description: The details about birth location
              fields: 
                - name: state
                  type: str
                  description: The Indian State in whihc the person was born
    data_collector: kv
"""

flo: Flo = Flo.build(session, simple_reseacher)
result = flo.invoke('Gandhi')

# This will output the output as JSON. The idea is that you can use the same collector across multiple agents and teams to still get a combined JSON output.
print(dc.fetch())

```

## ðŸ“Š Tool Logging and Data Collection

FloAI provides built-in capabilities for logging tool calls and collecting data through the `FloExecutionLogger` and `DataCollector` classes, facilitating the creation of valuable training data.
You can customize `DataCollector` implementation according to your database. A sample implementation where logs are stored locally as JSON files is implemented in `JSONLFileCollector`.

### Quick Setup

```python
from flo_ai.callbacks import FloExecutionLogger
from flo_ai.storage.data_collector import JSONLFileCollector

# Initialize the file collector with a path for the JSONL log file to be stored
file_collector = JSONLFileCollector("'.logs'")

# Create a tool logger with the collector
local_tracker = FloExecutionLogger(file_collector)

# Register the logger with your session
session.register_callback(local_tracker)
```

### Features

- ðŸ“ Logs all tool calls, chain executions, and agent actions
- ðŸ•’ Includes timestamps for start and end of operations
- ðŸ” Tracks inputs, outputs, and errors
- ðŸ’¾ Stores data in JSONL format for easy analysis
- ðŸ“š Facilitates the creation of training data from logged interactions

### Log Data Structure

The logger captures detailed information including:
- Tool name and inputs
- Execution timestamps
- Operation status (completed/error)
- Chain and agent activities
- Parent-child relationship between operations

### Training Data Generation

The structured logs provide valuable training data that can be used to:
- **Fine-tune LLMs** on your specific use cases
- **Train new models** to replicate successful tool usage patterns
- **Create supervised datasets** for tool selection and chain optimization

We have created a script to convert your logs to training data:

```python
python generate_training_data.py --logger-path PATH --tool-path PATH [--output PATH]
```

Arguments:
- *logger-path*: Path to the logger file containing tool and chain entries, eg: .logs/logs/log.jsonl
- *tool-path*: Path to the tool descriptions file eg: eg: .logs/tools/tools.jsonl
- *output*: path to save the output eg: training-data.jsonl
 

## ðŸ“– Documentation

Visit our [comprehensive documentation](https://flo-ai.rootflo.ai) for:
- Detailed tutorials
- Architecture deep-dives
- API reference
  - Logging
  - Error handling
  - Observers
  - Dynamic model switching
- Best practices
- Advanced examples

## ðŸŒŸ Why Flo AI?

### For AI Engineers
- **Faster Development**: Build complex AI systems in minutes, not days
- **Production Focus**: Built-in optimizations and best practices
- **Flexibility**: Use our components or build your own

### For Teams
- **Maintainable**: YAML-first approach makes systems easy to understand and modify
- **Scalable**: From single agents to complex team hierarchies
- **Testable**: Each component can be tested independently

## ðŸŽ¯ Use Cases

- ðŸ¤– Customer Service Automation
- ðŸ“Š Data Analysis Pipelines
- ðŸ“ Content Generation
- ðŸ” Research Automation
- ðŸŽ¯ Task-Specific AI Teams

## ðŸ¤ Contributing

We love your input! Check out our [Contributing Guide](CONTRIBUTING.md) to get started. Ways to contribute:

- ðŸ› Report bugs
- ðŸ’¡ Propose new features
- ðŸ“ Improve documentation
- ðŸ”§ Submit PRs

## ðŸ“œ License

Flo AI is [MIT Licensed](LICENSE).

## ðŸ™ Acknowledgments

Built with â¤ï¸ using:
- [LangChain](https://github.com/hwchase17/langchain)
- [LangGraph](https://github.com/langchain-ai/langgraph)

<h2>ðŸ“š Latest Blog Posts</h2>

<div style="display: flex; gap: 10px;">
    <a href="https://medium.com/rootflo/flo-simple-way-to-create-composable-ai-agents-6946c2922a94" target="_blank" style="text-decoration: none;">
        <img src="./images/blog-image.png" width="150" style="border-radius: 10px;" />
        <p><b>Flo: ðŸ”¥ðŸ”¥ðŸ”¥ Simple way to create composable AI agents</b><br />Unlock the Power of Customizable AI Workflows with FloAIâ€™s Intuitive and Flexible Agentic Framework</p>
    </a>
    <a href="https://medium.com/rootflo/build-an-agentic-ai-customer-support-bot-using-floai-533660fb9c9b" target="_blank" style="text-decoration: none;">
        <img src="./images/customer-support.png" width="150" style="border-radius: 10px;" />
        <p><b>Build an Agentic AI customer support bot using FloAI</b><br />We built an open-source agentic AI workflow builder named FloAI and used it to create an agentic customer support agent.</p>
    </a>
    <a href="https://medium.com/rootflo/build-an-agentic-rag-using-floai-in-minutes-0be260304c98" target="_blank" style="text-decoration: none;">
        <img src="./examples/images/agentic-rag.png" width="150" style="border-radius: 10px;" />
        <p><b>Build an Agentic RAG using FloAI in minutes</b><br />FloAI has just made implementing agentic RAG simple and easy to manage</p>
    </a>
</div>
    <a href="https://medium.com/rootflo/mastering-ai-interaction-logging-and-data-collection-with-floai-a490818bb2f1" target="_blank" style="text-decoration: none;">
        <img src="./images/blog-image.png" width="150" style="border-radius: 10px;" />
        <p><b>Mastering AI Interaction Logging and Data Collection with FloAI</b><br />Learn how to leverage FloAI's powerful logging system for debugging, training data generation, and system optimization</p>
    </a>
    </a>
---

<div align="center">
  <strong>Built with â¤ï¸ by the <a href="http://rootflo.ai">rootflo</a> team</strong>
  <br><a href="https://github.com/rootflo/flo-ai/discussions">Community</a> â€¢
  <a href="https://flo-ai.rootflo.ai">Documentation</a>
</div>

```

## backend/Geaux-flo/SECURITY.md

```
# Security Policy

## Supported Versions

We will be supporting all our release versions with security updates as of now

## Reporting a Vulnerability

Please report vulnerabilities are bugs in the GitHub issue tracker

```

## backend/Geaux-flo/.github/ISSUE_TEMPLATE/feature_request.md

```
---
name: Feature request
about: Suggest an idea for this project
title: ''
labels: ''
assignees: vizsatiz

---

**Is your feature request related to a problem? Please describe.**
A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]

**Describe the solution you'd like**
A clear and concise description of what you want to happen.

**Additional context**
Add any other context or screenshots about the feature request here.

```

## backend/Geaux-flo/.github/ISSUE_TEMPLATE/bug_report.md

```
---
name: Bug report
about: Create a report to help us improve
title: "[BUG]"
labels: bug
assignees: vizsatiz

---

**Describe the bug**
A clear and concise description of what the bug is with stack trace

**To Reproduce**
Steps to reproduce the behavior:
1. A minimal sample code to reproduce the bug is appreciated 

**Expected behavior**
A clear and concise description of what you expected to happen.

**Screenshots**
If applicable, could you add screenshots to help explain your problem?

**Environment (please complete the following information):**
 - python version: [e.g. 3.11]
 - OS [e.g. windows, mac]
 - flo-ai version [e.g. 0.0.1]

**Additional context**
Add any other context about the problem here.

```

## backend/geaux-crewai/README.md

```
<div align="center">

![Logo of crewAI, two people rowing on a boat](./docs/crewai_logo.png)

# **crewAI**

ðŸ¤– **crewAI**: Cutting-edge framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.

<h3>

[Homepage](https://www.crewai.io/) | [Documentation](https://docs.crewai.com/) | [Chat with Docs](https://chatg.pt/DWjSBZn) | [Examples](https://github.com/joaomdmoura/crewai-examples) | [Discord](https://discord.com/invite/X4JWnZnxPb)

</h3>

[![GitHub Repo stars](https://img.shields.io/github/stars/joaomdmoura/crewAI)](https://github.com/joaomdmoura/crewAI)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

</div>

## Table of contents

- [Why CrewAI?](#why-crewai)
- [Getting Started](#getting-started)
- [Key Features](#key-features)
- [Examples](#examples)
  - [Quick Tutorial](#quick-tutorial)
  - [Write Job Descriptions](#write-job-descriptions)
  - [Trip Planner](#trip-planner)
  - [Stock Analysis](#stock-analysis)
- [Connecting Your Crew to a Model](#connecting-your-crew-to-a-model)
- [How CrewAI Compares](#how-crewai-compares)
- [Contribution](#contribution)
- [Telemetry](#telemetry)
- [License](#license)

## Why CrewAI?

The power of AI collaboration has too much to offer.
CrewAI is designed to enable AI agents to assume roles, share goals, and operate in a cohesive unit - much like a well-oiled crew. Whether you're building a smart assistant platform, an automated customer service ensemble, or a multi-agent research team, CrewAI provides the backbone for sophisticated multi-agent interactions.

## Getting Started

To get started with CrewAI, follow these simple steps:

### 1. Installation

```shell
pip install crewai
```

If you want to install the 'crewai' package along with its optional features that include additional tools for agents, you can do so by using the following command: pip install 'crewai[tools]'. This command installs the basic package and also adds extra components which require more dependencies to function."

```shell
pip install 'crewai[tools]'
```

### 2. Setting Up Your Crew

```python
import os
from crewai import Agent, Task, Crew, Process
from crewai_tools import SerperDevTool

os.environ["OPENAI_API_KEY"] = "YOUR_API_KEY"
os.environ["SERPER_API_KEY"] = "Your Key" # serper.dev API key

# You can choose to use a local model through Ollama for example. See https://docs.crewai.com/how-to/LLM-Connections/ for more information.

# os.environ["OPENAI_API_BASE"] = 'http://localhost:11434/v1'
# os.environ["OPENAI_MODEL_NAME"] ='openhermes'  # Adjust based on available model
# os.environ["OPENAI_API_KEY"] ='sk-111111111111111111111111111111111111111111111111'

# You can pass an optional llm attribute specifying what model you wanna use.
# It can be a local model through Ollama / LM Studio or a remote
# model like OpenAI, Mistral, Antrophic or others (https://docs.crewai.com/how-to/LLM-Connections/)
#
# import os
# os.environ['OPENAI_MODEL_NAME'] = 'gpt-3.5-turbo'
#
# OR
#
# from langchain_openai import ChatOpenAI

search_tool = SerperDevTool()

# Define your agents with roles and goals
researcher = Agent(
  role='Senior Research Analyst',
  goal='Uncover cutting-edge developments in AI and data science',
  backstory="""You work at a leading tech think tank.
  Your expertise lies in identifying emerging trends.
  You have a knack for dissecting complex data and presenting actionable insights.""",
  verbose=True,
  allow_delegation=False,
  # You can pass an optional llm attribute specifying what model you wanna use.
  # llm=ChatOpenAI(model_name="gpt-3.5", temperature=0.7),
  tools=[search_tool]
)
writer = Agent(
  role='Tech Content Strategist',
  goal='Craft compelling content on tech advancements',
  backstory="""You are a renowned Content Strategist, known for your insightful and engaging articles.
  You transform complex concepts into compelling narratives.""",
  verbose=True,
  allow_delegation=True
)

# Create tasks for your agents
task1 = Task(
  description="""Conduct a comprehensive analysis of the latest advancements in AI in 2024.
  Identify key trends, breakthrough technologies, and potential industry impacts.""",
  expected_output="Full analysis report in bullet points",
  agent=researcher
)

task2 = Task(
  description="""Using the insights provided, develop an engaging blog
  post that highlights the most significant AI advancements.
  Your post should be informative yet accessible, catering to a tech-savvy audience.
  Make it sound cool, avoid complex words so it doesn't sound like AI.""",
  expected_output="Full blog post of at least 4 paragraphs",
  agent=writer
)

# Instantiate your crew with a sequential process
crew = Crew(
  agents=[researcher, writer],
  tasks=[task1, task2],
  verbose=True,
  process = Process.sequential
)

# Get your crew to work!
result = crew.kickoff()

print("######################")
print(result)
```

In addition to the sequential process, you can use the hierarchical process, which automatically assigns a manager to the defined crew to properly coordinate the planning and execution of tasks through delegation and validation of results. [See more about the processes here](https://docs.crewai.com/core-concepts/Processes/).

## Key Features

- **Role-Based Agent Design**: Customize agents with specific roles, goals, and tools.
- **Autonomous Inter-Agent Delegation**: Agents can autonomously delegate tasks and inquire amongst themselves, enhancing problem-solving efficiency.
- **Flexible Task Management**: Define tasks with customizable tools and assign them to agents dynamically.
- **Processes Driven**: Currently only supports `sequential` task execution and `hierarchical` processes, but more complex processes like consensual and autonomous are being worked on.
- **Save output as file**: Save the output of individual tasks as a file, so you can use it later.
- **Parse output as Pydantic or Json**: Parse the output of individual tasks as a Pydantic model or as a Json if you want to.
- **Works with Open Source Models**: Run your crew using Open AI or open source models refer to the [Connect crewAI to LLMs](https://docs.crewai.com/how-to/LLM-Connections/) page for details on configuring your agents' connections to models, even ones running locally!

![CrewAI Mind Map](./docs/crewAI-mindmap.png "CrewAI Mind Map")

## Examples

You can test different real life examples of AI crews in the [crewAI-examples repo](https://github.com/joaomdmoura/crewAI-examples?tab=readme-ov-file):

- [Landing Page Generator](https://github.com/joaomdmoura/crewAI-examples/tree/main/landing_page_generator)
- [Having Human input on the execution](https://docs.crewai.com/how-to/Human-Input-on-Execution)
- [Trip Planner](https://github.com/joaomdmoura/crewAI-examples/tree/main/trip_planner)
- [Stock Analysis](https://github.com/joaomdmoura/crewAI-examples/tree/main/stock_analysis)

### Quick Tutorial

[![CrewAI Tutorial](https://img.youtube.com/vi/tnejrr-0a94/maxresdefault.jpg)](https://www.youtube.com/watch?v=tnejrr-0a94 "CrewAI Tutorial")

### Write Job Descriptions

[Check out code for this example](https://github.com/joaomdmoura/crewAI-examples/tree/main/job-posting) or watch a video below:

[![Jobs postings](https://img.youtube.com/vi/u98wEMz-9to/maxresdefault.jpg)](https://www.youtube.com/watch?v=u98wEMz-9to "Jobs postings")

### Trip Planner

[Check out code for this example](https://github.com/joaomdmoura/crewAI-examples/tree/main/trip_planner) or watch a video below:

[![Trip Planner](https://img.youtube.com/vi/xis7rWp-hjs/maxresdefault.jpg)](https://www.youtube.com/watch?v=xis7rWp-hjs "Trip Planner")

### Stock Analysis

[Check out code for this example](https://github.com/joaomdmoura/crewAI-examples/tree/main/stock_analysis) or watch a video below:

[![Stock Analysis](https://img.youtube.com/vi/e0Uj4yWdaAg/maxresdefault.jpg)](https://www.youtube.com/watch?v=e0Uj4yWdaAg "Stock Analysis")

## Connecting Your Crew to a Model

crewAI supports using various LLMs through a variety of connection options. By default your agents will use the OpenAI API when querying the model. However, there are several other ways to allow your agents to connect to models. For example, you can configure your agents to use a local model via the Ollama tool.

Please refer to the [Connect crewAI to LLMs](https://docs.crewai.com/how-to/LLM-Connections/) page for details on configuring you agents' connections to models.

## How CrewAI Compares

- **Autogen**: While Autogen does good in creating conversational agents capable of working together, it lacks an inherent concept of process. In Autogen, orchestrating agents' interactions requires additional programming, which can become complex and cumbersome as the scale of tasks grows.

- **ChatDev**: ChatDev introduced the idea of processes into the realm of AI agents, but its implementation is quite rigid. Customizations in ChatDev are limited and not geared towards production environments, which can hinder scalability and flexibility in real-world applications.

**CrewAI's Advantage**: CrewAI is built with production in mind. It offers the flexibility of Autogen's conversational agents and the structured process approach of ChatDev, but without the rigidity. CrewAI's processes are designed to be dynamic and adaptable, fitting seamlessly into both development and production workflows.


## Contribution

CrewAI is open-source and we welcome contributions. If you're looking to contribute, please:

- Fork the repository.
- Create a new branch for your feature.
- Add your feature or improvement.
- Send a pull request.
- We appreciate your input!

### Installing Dependencies

```bash
poetry lock
poetry install
```

### Virtual Env

```bash
poetry shell
```

### Pre-commit hooks

```bash
pre-commit install
```

### Running Tests

```bash
poetry run pytest
```

### Running static type checks

```bash
poetry run mypy
```

### Packaging

```bash
poetry build
```

### Installing Locally

```bash
pip install dist/*.tar.gz
```

## Telemetry

CrewAI uses anonymous telemetry to collect usage data with the main purpose of helping us improve the library by focusing our efforts on the most used features, integrations and tools.

It's pivotal to understand that **NO data is collected** concerning prompts, task descriptions, agents' backstories or goals, usage of tools, API calls, responses, any data processed by the agents, or secrets and environment variables, with the exception of the conditions mentioned. When the `share_crew` feature is enabled, detailed data including task descriptions, agents' backstories or goals, and other specific attributes are collected to provide deeper insights while respecting user privacy. We don't offer a way to disable it now, but we will in the future.

Data collected includes:

- Version of crewAI
  - So we can understand how many users are using the latest version
- Version of Python
  - So we can decide on what versions to better support
- General OS (e.g. number of CPUs, macOS/Windows/Linux)
  - So we know what OS we should focus on and if we could build specific OS related features
- Number of agents and tasks in a crew
  - So we make sure we are testing internally with similar use cases and educate people on the best practices
- Crew Process being used
  - Understand where we should focus our efforts
- If Agents are using memory or allowing delegation
  - Understand if we improved the features or maybe even drop them
- If Tasks are being executed in parallel or sequentially
  - Understand if we should focus more on parallel execution
- Language model being used
  - Improved support on most used languages
- Roles of agents in a crew
  - Understand high level use cases so we can build better tools, integrations and examples about it
- Tools names available
  - Understand out of the publically available tools, which ones are being used the most so we can improve them

Users can opt-in to Further Telemetry, sharing the complete telemetry data by setting the `share_crew` attribute to `True` on their Crews. Enabling `share_crew` results in the collection of detailed crew and task execution data, including `goal`, `backstory`, `context`, and `output` of tasks. This enables a deeper insight into usage patterns while respecting the user's choice to share.

## License

CrewAI is released under the MIT License.

```

## backend/geaux-crewai/.github/ISSUE_TEMPLATE/custom.md

```
---
name: Custom issue template
about: Describe this issue template's purpose here.
title: "[DOCS]"
labels: documentation
assignees: ''

---

## Documentation Page
<!-- Provide a link to the documentation page that needs improvement -->

## Description
<!-- Describe what needs to be changed or improved in the documentation -->

## Suggested Changes
<!-- If possible, provide specific suggestions for how to improve the documentation -->

## Additional Context
<!-- Add any other context about the documentation issue here -->

## Checklist
- [ ] I have searched the existing issues to make sure this is not a duplicate
- [ ] I have checked the latest version of the documentation to ensure this hasn't been addressed

```

## backend/geaux-crewai/.github/ISSUE_TEMPLATE/bug_report.md

```
---
name: Bug report
about: Create a report to help us improve CrewAI
title: "[BUG]"
labels: bug
assignees: ''

---

**Description**
Provide a clear and concise description of what the bug is.

**Steps to Reproduce**
Provide a step-by-step process to reproduce the behavior:

**Expected behavior**
A clear and concise description of what you expected to happen.

**Screenshots/Code snippets**
If applicable, add screenshots or code snippets to help explain your problem.

**Environment Details:**
- **Operating System**: [e.g., Ubuntu 20.04, macOS Catalina, Windows 10]
- **Python Version**: [e.g., 3.8, 3.9, 3.10]
- **crewAI Version**: [e.g., 0.30.11]
- **crewAI Tools Version**: [e.g., 0.2.6]

**Logs**
Include relevant logs or error messages if applicable.

**Possible Solution**
Have a solution in mind? Please suggest it here, or write "None".

**Additional context**
Add any other context about the problem here.

```

## backend/geaux-crewai/src/crewai/translations/en.json

```
{
  "hierarchical_manager_agent": {
    "role": "Crew Manager",
    "goal": "Manage the team to complete the task in the best way possible.",
    "backstory": "You are a seasoned manager with a knack for getting the best out of your team.\nYou are also known for your ability to delegate work to the right people, and to ask the right questions to get the best out of your team.\nEven though you don't perform tasks by yourself, you have a lot of experience in the field, which allows you to properly evaluate the work of your team members."
  },
  "slices": {
    "observation": "\nObservation",
    "task": "\nCurrent Task: {input}\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:",
    "memory": "\n\n# Useful context: \n{memory}",
    "role_playing": "You are {role}. {backstory}\nYour personal goal is: {goal}",
    "tools": "\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\n{tools}\n\nUse the following format:\n\nThought: you should always think about what to do\nAction: the action to take, only one name of [{tool_names}], just the name, exactly as it's written.\nAction Input: the input to the action, just a simple python dictionary, enclosed in curly braces, using \" to wrap keys and values.\nObservation: the result of the action\n\nOnce all necessary information is gathered:\n\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n",
    "no_tools": "To give my best complete final answer to the task use the exact following format:\n\nThought: I now can give a great answer\nFinal Answer: my best complete final answer to the task.\nYour final answer must be the great and the most complete as possible, it must be outcome described.\n\nI MUST use these formats, my job depends on it!",
    "format": "I MUST either use a tool (use one at time) OR give my best final answer. To Use the following format:\n\nThought: you should always think about what to do\nAction: the action to take, should be one of [{tool_names}]\nAction Input: the input to the action, dictionary enclosed in curly braces\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now can give a great answer\nFinal Answer: my best complete final answer to the task.\nYour final answer must be the great and the most complete as possible, it must be outcome described\n\n ",
    "final_answer_format": "If you don't need to use any more tools, you must give your best complete final answer, make sure it satisfy the expect criteria, use the EXACT format below:\n\nThought: I now can give a great answer\nFinal Answer: my best complete final answer to the task.\n\n",
    "format_without_tools": "\nSorry, I didn't use the right format. I MUST either use a tool (among the available ones), OR give my best final answer.\nI just remembered the expected format I must follow:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [{tool_names}]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now can give a great answer\nFinal Answer: my best complete final answer to the task\nYour final answer must be the great and the most complete as possible, it must be outcome described\n\n",
    "task_with_context": "{task}\n\nThis is the context you're working with:\n{context}",
    "expected_output": "\nThis is the expect criteria for your final answer: {expected_output} \n you MUST return the actual complete content as the final answer, not a summary.",
    "human_feedback": "You got human feedback on your work, re-evaluate it and give a new Final Answer when ready.\n {human_feedback}",
    "getting_input": "This is the agent's final answer: {final_answer}\nPlease provide feedback: "
  },
  "errors": {
    "force_final_answer": "Tool won't be use because it's time to give your final answer. Don't use tools and just your absolute BEST Final answer.",
    "agent_tool_unexsiting_coworker": "\nError executing tool. coworker mentioned not found, it must be one of the following options:\n{coworkers}\n",
    "task_repeated_usage": "I tried reusing the same input, I must stop using this action input. I'll try something else instead.\n\n",
    "tool_usage_error": "I encountered an error: {error}",
    "tool_arguments_error": "Error: the Action Input is not a valid key, value dictionary.",
    "wrong_tool_name": "You tried to use the tool {tool}, but it doesn't exist. You must use one of the following tools, use one at time: {tools}.",
    "tool_usage_exception": "I encountered an error while trying to use the tool. This was the error: {error}.\n Tool {tool} accepts these inputs: {tool_inputs}"
  },
  "tools": {
    "delegate_work": "Delegate a specific task to one of the following coworkers: {coworkers}\nThe input to this tool should be the coworker, the task you want them to do, and ALL necessary context to execute the task, they know nothing about the task, so share absolute everything you know, don't reference things but instead explain them.",
    "ask_question": "Ask a specific question to one of the following coworkers: {coworkers}\nThe input to this tool should be the coworker, the question you have for them, and ALL necessary context to ask the question properly, they know nothing about the question, so share absolute everything you know, don't reference things but instead explain them."
  }
}

```

## backend/geaux-crewai/src/crewai/cli/templates/README.md

```
# {{crew_name}} Crew

Welcome to the {{crew_name}} Crew project, powered by [crewAI](https://crewai.com). This template is designed to help you set up a multi-agent AI system with ease, leveraging the powerful and flexible framework provided by crewAI. Our goal is to enable your agents to collaborate effectively on complex tasks, maximizing their collective intelligence and capabilities.

## Installation

Ensure you have Python >=3.10 <=3.13 installed on your system. This project uses [Poetry](https://python-poetry.org/) for dependency management and package handling, offering a seamless setup and execution experience.

First, if you haven't already, install Poetry:

```bash
pip install poetry
```

Next, navigate to your project directory and install the dependencies:

1. First lock the dependencies and then install them:
```bash
poetry lock
```
```bash
poetry install
```
### Customizing

**Add your `OPENAI_API_KEY` into the `.env` file**

- Modify `src/{{folder_name}}/config/agents.yaml` to define your agents
- Modify `src/{{folder_name}}/config/tasks.yaml` to define your tasks
- Modify `src/{{folder_name}}/crew.py` to add your own logic, tools and specific args
- Modify `src/{{folder_name}}/main.py` to add custom inputs for your agents and tasks

## Running the Project

To kickstart your crew of AI agents and begin task execution, run this from the root folder of your project:

```bash
$ crewai run
```
or
```bash
poetry run {{folder_name}}
```

This command initializes the {{name}} Crew, assembling the agents and assigning them tasks as defined in your configuration.

This example, unmodified, will run the create a `report.md` file with the output of a research on LLMs in the root folder.

## Understanding Your Crew

The {{name}} Crew is composed of multiple AI agents, each with unique roles, goals, and tools. These agents collaborate on a series of tasks, defined in `config/tasks.yaml`, leveraging their collective skills to achieve complex objectives. The `config/agents.yaml` file outlines the capabilities and configurations of each agent in your crew.

## Support

For support, questions, or feedback regarding the {{crew_name}} Crew or crewAI.
- Visit our [documentation](https://docs.crewai.com)
- Reach out to us through our [GitHub repository](https://github.com/joaomdmoura/crewai)
- [Join our Discord](https://discord.com/invite/X4JWnZnxPb)
- [Chat with our docs](https://chatg.pt/DWjSBZn)

Let's create wonders together with the power and simplicity of crewAI.

```

## backend/geaux-crewai/docs/index.md

```
<img src='./crew_only_logo.png' width='250' class='mb-10'/>

# crewAI Documentation

Cutting-edge framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.

<div style="display:flex; margin:0 auto; justify-content: center;">
    <div style="width:25%">
        <h2>Getting Started</h2>
        <ul>
            <li><a href='./getting-started/Installing-CrewAI'>
                   Installing CrewAI
                 </a>
            </li>
            <li><a href='./getting-started/Start-a-New-CrewAI-Project-Template-Method'>
                   Start a New CrewAI Project: Template Method
                 </a>
            </li>
        </ul>
    </div>
    <div style="width:25%">
        <h2>Core Concepts</h2>
        <ul>
            <li>
                <a href="./core-concepts/Agents">
                    Agents
                </a>
            </li>
            <li>
                <a href="./core-concepts/Tasks">
                    Tasks
                </a>
            </li>
            <li>
                <a href="./core-concepts/Tools">
                    Tools
                </a>
            </li>
            <li>
                <a href="./core-concepts/Processes">
                    Processes
                </a>
            </li>
            <li>
                <a href="./core-concepts/Crews">
                    Crews
                </a>
            </li>
            <li>
                <a href="./core-concepts/Training-Crew">
                    Training
                </a>
            </li>
            <li>
                <a href="./core-concepts/Memory">
                    Memory
                </a>
            </li>
            <li>
                <a href="./core-concepts/Planning">
                    Planning
                </a>
            </li>
        </ul>
    </div>
    <div style="width:30%">
        <h2>How-To Guides</h2>
        <ul>
            <li>
                <a href="./how-to/Create-Custom-Tools">
                    Create Custom Tools
                </a>
            </li>
            <li>
                <a href="./how-to/Sequential">
                    Using Sequential Process
                </a>
            </li>
            <li>
                <a href="./how-to/Hierarchical">
                    Using Hierarchical Process
                </a>
            </li>
            <li>
                <a href="./how-to/LLM-Connections">
                    Connecting to LLMs
                </a>
            </li>
            <li>
                <a href="./how-to/Customizing-Agents">
                    Customizing Agents
                </a>
            </li>
            <li>
                <a href="./how-to/Coding-Agents">
                    Coding Agents
                </a>
            </li>
            <li>
                <a href="./how-to/Force-Tool-Ouput-as-Result">
                    Forcing Tool Output as Result
                </a>
            </li>
            <li>
                <a href="./how-to/Human-Input-on-Execution">
                    Human Input on Execution
                </a>
            </li>
            <li>
                <a href="./how-to/Kickoff-async">
                    Kickoff a Crew Asynchronously
                </a>
            </li>
            <li>
                <a href="./how-to/Kickoff-for-each">
                    Kickoff a Crew for a List
                </a>
            </li>
            <li>
                <a href="./how-to/Replay-tasks-from-latest-Crew-Kickoff">
                    Replay from a Task
                </a>
            </li>
            <li>
                <a href="./how-to/Conditional-Tasks">
                    Conditional Tasks
                </a>
            </li>
            <li>
                <a href="./how-to/AgentOps-Observability">
                    Agent Monitoring with AgentOps
                </a>
            </li>
            <li>
                <a href="./how-to/Langtrace-Observability">
                    Agent Monitoring with LangTrace
                </a>
            </li>
        </ul>
    </div>
    <div style="width:30%">
        <h2>Examples</h2>
        <ul>
            <li>
                <a target='_blank' href="https://github.com/joaomdmoura/crewAI-examples/tree/main/prep-for-a-meeting">
                    Prepare for meetings
                </a>
            </li>
            <li>
                <a target='_blank' href="https://github.com/joaomdmoura/crewAI-examples/tree/main/trip_planner">
                    Trip Planner Crew
                </a>
            </li>
            <li>
                <a target='_blank' href="https://github.com/joaomdmoura/crewAI-examples/tree/main/instagram_post">
                    Create Instagram Post
                </a>
            </li>
            <li>
                <a target='_blank' href="https://github.com/joaomdmoura/crewAI-examples/tree/main/stock_analysis">
                    Stock Analysis
                </a>
            </li>
            <li>
                <a target='_blank' href="https://github.com/joaomdmoura/crewAI-examples/tree/main/game-builder-crew">
                    Game Generator
                </a>
            </li>
            <li>
                <a target='_blank' href="https://github.com/joaomdmoura/crewAI-examples/tree/main/CrewAI-LangGraph">
                    Drafting emails with LangGraph
                </a>
            </li>
            <li>
                <a target='_blank' href="https://github.com/joaomdmoura/crewAI-examples/tree/main/landing_page_generator">
                    Landing Page Generator
                </a>
            </li>
        </ul>
    </div>
</div>

```

## backend/geaux-crewai/docs/tailwind.config.js

```
/** @type {import('tailwindcss').Config} */
module.exports = {
  content: ["./**/*.md"],
  theme: {
    extend: {},
  },
  plugins: [],
}


```

## backend/geaux-crewai/docs/postcss.config.js

```
module.exports = {
  plugins: [require('tailwindcss'), require('autoprefixer')]
}
```

## backend/geaux-crewai/docs/how-to/LLM-Connections.md

```
---
title: Connect CrewAI to LLMs
description: Comprehensive guide on integrating CrewAI with various Large Language Models (LLMs), including detailed class attributes, methods, and configuration options.
---

## Connect CrewAI to LLMs

!!! note "Default LLM"
    By default, CrewAI uses OpenAI's GPT-4o model (specifically, the model specified by the OPENAI_MODEL_NAME environment variable, defaulting to "gpt-4o") for language processing. You can configure your agents to use a different model or API as described in this guide.
    By default, CrewAI uses OpenAI's GPT-4 model (specifically, the model specified by the OPENAI_MODEL_NAME environment variable, defaulting to "gpt-4") for language processing. You can configure your agents to use a different model or API as described in this guide.

CrewAI provides extensive versatility in integrating with various Language Models (LLMs), including local options through Ollama such as  Llama and Mixtral to cloud-based solutions like Azure. Its compatibility extends to all [LangChain LLM components](https://python.langchain.com/v0.2/docs/integrations/llms/), offering a wide range of integration possibilities for customized AI applications.

The platform supports connections to an array of Generative AI models, including:

 - OpenAI's suite of advanced language models
 - Anthropic's cutting-edge AI offerings
 - Ollama's diverse range of locally-hosted generative model & embeddings
 - LM Studio's diverse range of locally hosted generative models & embeddings
 - Groq's Super Fast LLM offerings
 - Azures' generative AI offerings
 - HuggingFace's generative AI offerings

This broad spectrum of LLM options enables users to select the most suitable model for their specific needs, whether prioritizing local deployment, specialized capabilities, or cloud-based scalability.

## Changing the default LLM
The default LLM is provided through the `langchain openai` package, which is installed by default when you install CrewAI. You can change this default LLM to a different model or API by setting the `OPENAI_MODEL_NAME` environment variable. This straightforward process allows you to harness the power of different OpenAI models, enhancing the flexibility and capabilities of your CrewAI implementation.
```python
# Required
os.environ["OPENAI_MODEL_NAME"]="gpt-4-0125-preview"

# Agent will automatically use the model defined in the environment variable
example_agent = Agent(
  role='Local Expert',
  goal='Provide insights about the city',
  backstory="A knowledgeable local guide.",
  verbose=True
)
```
## Ollama Local Integration
Ollama is preferred for local LLM integration, offering customization and privacy benefits. To integrate Ollama with CrewAI, you will need the `langchain-ollama` package. You can then set the following environment variables to connect to your Ollama instance running locally on port 11434.

```sh
os.environ[OPENAI_API_BASE]='http://localhost:11434'
os.environ[OPENAI_MODEL_NAME]='llama2'  # Adjust based on available model
os.environ[OPENAI_API_KEY]='' # No API Key required for Ollama
```

## Ollama Integration Step by Step (ex. for using Llama 3.1 8B locally)
1. [Download and install Ollama](https://ollama.com/download).   
2. After setting up the Ollama, Pull the Llama3.1 8B model by typing following lines into your terminal ```ollama run llama3.1```.   
3. Llama3.1 should now be served locally on `http://localhost:11434`
```
from crewai import Agent, Task, Crew
from langchain_ollama import ChatOllama
import os
os.environ["OPENAI_API_KEY"] = "NA"

llm = Ollama(
    model = "llama3.1",
    base_url = "http://localhost:11434")

general_agent = Agent(role = "Math Professor",
                      goal = """Provide the solution to the students that are asking mathematical questions and give them the answer.""",
                      backstory = """You are an excellent math professor that likes to solve math questions in a way that everyone can understand your solution""",
                      allow_delegation = False,
                      verbose = True,
                      llm = llm)

task = Task(description="""what is 3 + 5""",
             agent = general_agent,
             expected_output="A numerical answer.")

crew = Crew(
            agents=[general_agent],
            tasks=[task],
            verbose=True
        )

result = crew.kickoff()

print(result)
```

## HuggingFace Integration
There are a couple of different ways you can use HuggingFace to host your LLM.

### Your own HuggingFace endpoint
```python
from langchain_huggingface import HuggingFaceEndpoint,

llm = HuggingFaceEndpoint(
    repo_id="microsoft/Phi-3-mini-4k-instruct",
    task="text-generation",
    max_new_tokens=512,
    do_sample=False,
    repetition_penalty=1.03,
)

agent = Agent(
    role="HuggingFace Agent",
    goal="Generate text using HuggingFace",
    backstory="A diligent explorer of GitHub docs.",
    llm=llm
)
```

## OpenAI Compatible API Endpoints
Switch between APIs and models seamlessly using environment variables, supporting platforms like FastChat, LM Studio, Groq, and Mistral AI.

### Configuration Examples
#### FastChat
```sh
os.environ[OPENAI_API_BASE]="http://localhost:8001/v1"
os.environ[OPENAI_MODEL_NAME]='oh-2.5m7b-q51'
os.environ[OPENAI_API_KEY]=NA
```

#### LM Studio
Launch [LM Studio](https://lmstudio.ai) and go to the Server tab. Then select a model from the dropdown menu and wait for it to load. Once it's loaded, click the green Start Server button and use the URL, port, and API key that's shown (you can modify them). Below is an example of the default settings as of LM Studio 0.2.19:
```sh
os.environ[OPENAI_API_BASE]="http://localhost:1234/v1"
os.environ[OPENAI_API_KEY]="lm-studio"
```

#### Groq API
```sh
os.environ[OPENAI_API_KEY]=your-groq-api-key
os.environ[OPENAI_MODEL_NAME]='llama3-8b-8192'
os.environ[OPENAI_API_BASE]=https://api.groq.com/openai/v1
```

#### Mistral API
```sh
os.environ[OPENAI_API_KEY]=your-mistral-api-key
os.environ[OPENAI_API_BASE]=https://api.mistral.ai/v1
os.environ[OPENAI_MODEL_NAME]="mistral-small"
```

### Solar
```sh
from langchain_community.chat_models.solar import SolarChat
```
```sh
os.environ[SOLAR_API_BASE]="https://api.upstage.ai/v1/solar"
os.environ[SOLAR_API_KEY]="your-solar-api-key"
```

# Free developer API key available here: https://console.upstage.ai/services/solar
# Langchain Example: https://github.com/langchain-ai/langchain/pull/18556


### Cohere
```python
from langchain_cohere import ChatCohere
# Initialize language model
os.environ["COHERE_API_KEY"] = "your-cohere-api-key"
llm = ChatCohere()

# Free developer API key available here: https://cohere.com/
# Langchain Documentation: https://python.langchain.com/docs/integrations/chat/cohere
```

### Azure Open AI Configuration
For Azure OpenAI API integration, set the following environment variables:
```sh

os.environ[AZURE_OPENAI_DEPLOYMENT] = "You deployment"
os.environ["OPENAI_API_VERSION"] = "2023-12-01-preview"
os.environ["AZURE_OPENAI_ENDPOINT"] = "Your Endpoint"
os.environ["AZURE_OPENAI_API_KEY"] = "<Your API Key>"
```

### Example Agent with Azure LLM
```python
from dotenv import load_dotenv
from crewai import Agent
from langchain_openai import AzureChatOpenAI

load_dotenv()

azure_llm = AzureChatOpenAI(
    azure_endpoint=os.environ.get("AZURE_OPENAI_ENDPOINT"),
    api_key=os.environ.get("AZURE_OPENAI_KEY")
)

azure_agent = Agent(
  role='Example Agent',
  goal='Demonstrate custom LLM configuration',
  backstory='A diligent explorer of GitHub docs.',
  llm=azure_llm
)
```
## Conclusion
Integrating CrewAI with different LLMs expands the framework's versatility, allowing for customized, efficient AI solutions across various domains and platforms.

```

## backend/geaux-crewai/docs/how-to/Create-Custom-Tools.md

```
---
title: Creating and Utilizing Tools in crewAI
description: Comprehensive guide on crafting, using, and managing custom tools within the crewAI framework, including new functionalities and error handling.
---

## Creating and Utilizing Tools in crewAI
This guide provides detailed instructions on creating custom tools for the crewAI framework and how to efficiently manage and utilize these tools, incorporating the latest functionalities such as tool delegation, error handling, and dynamic tool calling. It also highlights the importance of collaboration tools, enabling agents to perform a wide range of actions.

### Prerequisites

Before creating your own tools, ensure you have the crewAI extra tools package installed:

```bash
pip install 'crewai[tools]'
```

### Subclassing `BaseTool`

To create a personalized tool, inherit from `BaseTool` and define the necessary attributes and the `_run` method.

```python
from crewai_tools import BaseTool

class MyCustomTool(BaseTool):
    name: str = "Name of my tool"
    description: str = "What this tool does. It's vital for effective utilization."

    def _run(self, argument: str) -> str:
        # Your tool's logic here
        return "Tool's result"
```

### Using the `tool` Decorator

Alternatively, you can use the tool decorator `@tool`. This approach allows you to define the tool's attributes and functionality directly within a function, offering a concise and efficient way to create specialized tools tailored to your needs.

```python
from crewai_tools import tool

@tool("Tool Name")
def my_simple_tool(question: str) -> str:
    """Tool description for clarity."""
    # Tool logic here
    return "Tool output"
```

### Defining a Cache Function for the Tool

To optimize tool performance with caching, define custom caching strategies using the `cache_function` attribute.

```python
@tool("Tool with Caching")
def cached_tool(argument: str) -> str:
    """Tool functionality description."""
    return "Cacheable result"

def my_cache_strategy(arguments: dict, result: str) -> bool:
    # Define custom caching logic
    return True if some_condition else False

cached_tool.cache_function = my_cache_strategy
```

By adhering to these guidelines and incorporating new functionalities and collaboration tools into your tool creation and management processes, you can leverage the full capabilities of the crewAI framework, enhancing both the development experience and the efficiency of your AI agents.
```

